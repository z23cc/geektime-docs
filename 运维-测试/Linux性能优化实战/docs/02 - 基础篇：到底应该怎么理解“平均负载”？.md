你好，我是倪朋飞。

每次发现系统变慢时，我们通常做的第一件事，就是执行top或者uptime命令，来了解系统的负载情况。比如像下面这样，我在命令行里输入了uptime命令，系统也随即给出了结果。

```
$ uptime
02:34:03 up 2 days, 20:14,  1 user,  load average: 0.63, 0.83, 0.88
```

但我想问的是，你真的知道这里每列输出的含义吗？

我相信你对前面的几列比较熟悉，它们分别是当前时间、系统运行时间以及正在登录用户数。

```
02:34:03              //当前时间
up 2 days, 20:14      //系统运行时间
1 user                //正在登录用户数
```

而最后三个数字呢，依次则是过去1分钟、5分钟、15分钟的平均负载（Load Average）。

**平均负载**？这个词对很多人来说，可能既熟悉又陌生，我们每天的工作中，也都会提到这个词，但你真正理解它背后的含义吗？如果你们团队来了一个实习生，他揪住你不放，你能给他讲清楚什么是平均负载吗？

其实，6年前，我就遇到过这样的一个场景。公司一个实习生一直追问我，什么是平均负载，我支支吾吾半天，最后也没能解释明白。明明总看到也总会用到，怎么就说不明白呢？后来我静下来想想，其实还是自己的功底不够。

于是，这几年，我遇到问题，特别是基础问题，都会多问自己几个“为什么”，以求能够彻底理解现象背后的本质原理，用起来更灵活，也更有底气。

今天，我就带你来学习下，如何观测和理解这个最常见、也是最重要的系统指标。

我猜一定有人会说，平均负载不就是单位时间内的 CPU 使用率吗？上面的0.63，就代表CPU使用率是63%。其实并不是这样，如果你方便的话，可以通过执行man uptime命令，来了解平均负载的详细解释。

简单来说，平均负载是指单位时间内，系统处于**可运行状态**和**不可中断状态**的平均进程数，也就是**平均活跃进程数**，它和CPU使用率并没有直接关系。这里我先解释下，可运行状态和不可中断状态这俩词儿。

所谓可运行状态的进程，是指正在使用CPU或者正在等待CPU的进程，也就是我们常用ps命令看到的，处于R状态（Running 或 Runnable）的进程。

不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的I/O响应，也就是我们在ps命令中看到的D状态（Uninterruptible Sleep，也称为Disk Sleep）的进程。

比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。

所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。

因此，你可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。这个“指数衰减平均”的详细含义你不用计较，这只是系统的一种更快速的计算方式，你把它直接当成活跃进程数的平均值也没问题。

既然平均的是活跃进程数，那么最理想的，就是每个CPU上都刚好运行着一个进程，这样每个CPU都得到了充分利用。比如当平均负载为2时，意味着什么呢？

- 在只有2个CPU的系统上，意味着所有的CPU都刚好被完全占用。
- 在4个CPU的系统上，意味着CPU有50%的空闲。
- 而在只有1个CPU的系统中，则意味着有一半的进程竞争不到CPU。

## 平均负载为多少时合理

讲完了什么是平均负载，现在我们再回到最开始的例子，不知道你能否判断出，在 uptime 命令的结果里，那三个时间段的平均负载数，多大的时候能说明系统负载高？或是多小的时候就能说明系统负载很低呢？

我们知道，平均负载最理想的情况是等于 CPU个数。所以在评判平均负载时，**首先你要知道系统有几个 CPU**，这可以通过 top 命令或者从文件 /proc/cpuinfo 中读取，比如：

```
# 关于grep和wc的用法请查询它们的手册或者网络搜索
$ grep 'model name' /proc/cpuinfo | wc -l
2
```

有了CPU 个数，我们就可以判断出，当平均负载比 CPU 个数还大的时候，系统已经出现了过载。

不过，且慢，新的问题又来了。我们在例子中可以看到，平均负载有三个数值，到底该参考哪一个呢？

实际上，都要看。三个不同时间间隔的平均值，其实给我们提供了，分析**系统负载趋势**的数据来源，让我们能更全面、更立体地理解目前的负载状况。

打个比方，就像初秋时北京的天气，如果只看中午的温度，你可能以为还在7月份的大夏天呢。但如果你结合了早上、中午、晚上三个时间点的温度来看，基本就可以全方位了解这一天的天气情况了。

同样的，前面说到的CPU的三个负载时间段也是这个道理。

- 如果1分钟、5分钟、15分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。
- 但如果1分钟的值远小于15 分钟的值，就说明系统最近1分钟的负载在减少，而过去15分钟内却有很大的负载。
- 反过来，如果1分钟的值远大于 15 分钟的值，就说明最近1分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦1分钟的平均负载接近或超过了CPU的个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，并要想办法优化了。

这里我再举个例子，假设我们在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698% 的超载，从整体趋势来看，系统的负载在降低。

那么，在实际生产环境中，平均负载多高时，需要我们重点关注呢？

在我看来，**当平均负载高于 CPU 数量70%的时候**，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。

但70%这个数字并不是绝对的，最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。当发现负载有明显升高趋势时，比如说负载翻倍了，你再去做分析和调查。

## 平均负载与CPU使用率

现实工作中，我们经常容易把平均负载和 CPU 使用率混淆，所以在这里，我也做一个区分。

可能你会疑惑，既然平均负载代表的是活跃进程数，那平均负载高了，不就意味着 CPU 使用率高吗？

我们还是要回到平均负载的含义上来，平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了**正在使用 CPU** 的进程，还包括**等待 CPU** 和**等待 I/O** 的进程。

而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：

- CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
- I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；
- 大量等待 CPU 的进程调度也会导致平均负载升高，此时的CPU使用率也会比较高。

## 平均负载案例分析

下面，我们以三个示例分别来看这三种情况，并用 iostat、mpstat、pidstat 等工具，找出平均负载升高的根源。

因为案例分析都是基于机器上的操作，所以不要只是听听、看看就够了，最好还是跟着我实际操作一下。

### 你的准备

下面的案例都是基于 Ubuntu 18.04，当然，同样适用于其他 Linux 系统。我使用的案例环境如下所示。

- 机器配置：2 CPU，8GB 内存。
- 预先安装 stress 和 sysstat 包，如 apt install stress sysstat。

在这里，我先简单介绍一下 stress 和 sysstat。

stress 是一个 Linux 系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。

而 sysstat 包含了常用的 Linux 性能工具，用来监控和分析系统的性能。我们的案例会用到这个包的两个命令 mpstat 和 pidstat。

- mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有CPU的平均指标。
- pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。

此外，每个场景都需要你开三个终端，登录到同一台 Linux 机器中。

实验之前，你先做好上面的准备。如果包的安装有问题，可以先在Google一下自行解决，如果还是解决不了，再来留言区找我，这事儿应该不难。

另外要注意，下面的所有命令，我们都是默认以 root 用户运行。所以，如果你是用普通用户登陆的系统，一定要先运行 sudo su root 命令切换到 root 用户。

如果上面的要求都已经完成了，你可以先用 uptime 命令，看一下测试前的平均负载情况：

```
$ uptime
...,  load average: 0.11, 0.15, 0.09
```

### 场景一：CPU 密集型进程

首先，我们在第一个终端运行 stress 命令，模拟一个 CPU 使用率 100% 的场景：

```
$ stress --cpu 1 --timeout 600
```

接着，在第二个终端运行uptime查看平均负载的变化情况：

```
# -d 参数表示高亮显示变化的区域
$ watch -d uptime
...,  load average: 1.00, 0.75, 0.39
```

最后，在第三个终端运行mpstat查看 CPU 使用率的变化情况：

```
# -P ALL 表示监控所有CPU，后面数字5表示间隔5秒后输出一组数据
$ mpstat -P ALL 5
Linux 4.15.0 (ubuntu) 09/22/18 _x86_64_ (2 CPU)
13:30:06     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
13:30:11     all   50.05    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   49.95
13:30:11       0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
13:30:11       1  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
```

从终端二中可以看到，1 分钟的平均负载会慢慢增加到 1.00，而从终端三中还可以看到，正好有一个 CPU 的使用率为 100%，但它的 iowait 只有 0。这说明，平均负载的升高正是由于 CPU 使用率为 100% 。

那么，到底是哪个进程导致了 CPU 使用率为 100% 呢？你可以使用 pidstat 来查询：

```
# 间隔5秒后输出一组数据
$ pidstat -u 5 1
13:37:07      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
13:37:12        0      2962  100.00    0.00    0.00    0.00  100.00     1  stress
```

从这里可以明显看到，stress进程的CPU使用率为100%。

### 场景二：I/O 密集型进程

首先还是运行 stress 命令，但这次模拟 I/O 压力，即不停地执行 sync：

```
$ stress -i 1 --timeout 600
```

还是在第二个终端运行uptime查看平均负载的变化情况：

```
$ watch -d uptime
...,  load average: 1.06, 0.58, 0.37
```

然后，第三个终端运行mpstat查看 CPU 使用率的变化情况：

```
# 显示所有CPU的指标，并在间隔5秒输出一组数据
$ mpstat -P ALL 5 1
Linux 4.15.0 (ubuntu)     09/22/18     _x86_64_    (2 CPU)
13:41:28     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
13:41:33     all    0.21    0.00   12.07   32.67    0.00    0.21    0.00    0.00    0.00   54.84
13:41:33       0    0.43    0.00   23.87   67.53    0.00    0.43    0.00    0.00    0.00    7.74
13:41:33       1    0.00    0.00    0.81    0.20    0.00    0.00    0.00    0.00    0.00   98.99
```

从这里可以看到，1 分钟的平均负载会慢慢增加到 1.06，其中一个 CPU 的系统CPU使用率升高到了 23.87，而 iowait 高达 67.53%。这说明，平均负载的升高是由于 iowait 的升高。

那么到底是哪个进程，导致 iowait 这么高呢？我们还是用 pidstat 来查询：

```
# 间隔5秒后输出一组数据，-u表示CPU指标
$ pidstat -u 5 1
Linux 4.15.0 (ubuntu)     09/22/18     _x86_64_    (2 CPU)
13:42:08      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
13:42:13        0       104    0.00    3.39    0.00    0.00    3.39     1  kworker/1:1H
13:42:13        0       109    0.00    0.40    0.00    0.00    0.40     0  kworker/0:1H
13:42:13        0      2997    2.00   35.53    0.00    3.99   37.52     1  stress
13:42:13        0      3057    0.00    0.40    0.00    0.00    0.40     0  pidstat
```

可以发现，还是 stress 进程导致的。

### 场景三：大量进程的场景

当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程。

比如，我们还是使用 stress，但这次模拟的是 8 个进程：

```
$ stress -c 8 --timeout 600
```

由于系统只有 2 个CPU，明显比 8 个进程要少得多，因而，系统的 CPU 处于严重过载状态，平均负载高达7.97：

```
$ uptime
...,  load average: 7.97, 5.93, 3.02
```

接着再运行pidstat来看一下进程的情况：

```
# 间隔5秒后输出一组数据
$ pidstat -u 5 1
14:23:25      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
14:23:30        0      3190   25.00    0.00    0.00   74.80   25.00     0  stress
14:23:30        0      3191   25.00    0.00    0.00   75.20   25.00     0  stress
14:23:30        0      3192   25.00    0.00    0.00   74.80   25.00     1  stress
14:23:30        0      3193   25.00    0.00    0.00   75.00   25.00     1  stress
14:23:30        0      3194   24.80    0.00    0.00   74.60   24.80     0  stress
14:23:30        0      3195   24.80    0.00    0.00   75.00   24.80     0  stress
14:23:30        0      3196   24.80    0.00    0.00   74.60   24.80     1  stress
14:23:30        0      3197   24.80    0.00    0.00   74.80   24.80     1  stress
14:23:30        0      3200    0.00    0.20    0.00    0.20    0.20     0  pidstat
```

可以看出，8 个进程在争抢 2 个 CPU，每个进程等待 CPU 的时间（也就是代码块中的 %wait 列）高达 75%。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。

## 小结

分析完这三个案例，我再来归纳一下平均负载的理解。

平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：

- 平均负载高有可能是 CPU 密集型进程导致的；
- 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了；
- 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。

## 思考

最后，我想邀请你一起来聊聊你所理解的平均负载，当你发现平均负载升高后，又是怎么分析排查的呢？你可以结合我前面的讲解，来总结自己的思考。欢迎在留言区和我讨论。

[![unpreview](https://static001.geekbang.org/resource/image/00/f2/00f868b7654dcb50ae2c91fd7688d2f2.jpg?wh=1242%2A526)](time://mall?url=https%3A%2F%2Fj.youzan.com%2F7_vgDi)  
限量发售中，仅限5000份，3大体系，22个模块，定位工作中80%的高频问题。
<div><strong>精选留言（15）</strong></div><ul>
<li><span>倪朋飞</span> 👍（411） 💬（25）<p>没想到大家的热情这么高，太激动了。统一回复一下案例中的几个问题：

1. iowait无法升高的问题，是因为案例中stress使用的是 sync() 系统调用，它的作用是刷新缓冲区内存到磁盘中。对于新安装的虚拟机，缓冲区可能比较小，无法产生大的IO压力，这样大部分就都是系统调用的消耗了。所以，你会看到只有系统CPU使用率升高。解决方法是使用stress的下一代stress-ng，它支持更丰富的选项，比如 stress-ng -i 1 --hdd 1 --timeout 600（--hdd表示读写临时文件）。
2. pidstat输出中没有%wait的问题，是因为CentOS默认的sysstat稍微有点老，源码或者RPM升级到11.5.5版本以后就可以看到了。而Ubuntu的包一般都比较新，没有这个问题。
3. mpstat无法观测的问题，案例中是等待5秒后输出1次结果就停止了，更好的做法是持续监控一段时间，比如持续观测20次：mpstat -P ALL 5 20。</p>2018-11-25</li><br/><li><span>longhaiqwe</span> 👍（23） 💬（4）<p> 倪老师提到的软件，最好都用源码安装吧，版本比较新，尤其是centos的同学们。</p>2018-11-23</li><br/><li><span>南北少卿</span> 👍（18） 💬（4）<p>老师,在跟着操作场景三的时候,使用命令pidstat -u 5 1,并没有出%wait的值,我用的是阿里云centos(CentOS Linux release 7.5.1804 (Core) 
),Linux 3.10.0-693.2.2.el7.x86_64 (izbp13056tlb7huifh6gm3z) 	11&#47;23&#47;2018 	_x86_64_	(1 CPU)
Average:      UID       PID    %usr %system  %guest    %CPU   CPU  Command
Average:        0       252     0.00    2.02          0.00    2.02     -  kworker&#47;0:1H
Average:        0       257     0.00    0.20          0.00    0.20     -  jbd2&#47;vda1-8
Average:        0      1079    0.20    0.00          0.00    0.20     -  AliYunDun
Average:        0     20256    0.20    0.00         0.00    0.20     -  java
Average:        0     24482    0.00    0.61         0.00    0.61     -  kworker&#47;u2:1
Average:        0     31305    0.20   60.00        0.00   60.20    -  stress
Average:        0     31306    0.20    0.00    0.00    0.20     -  watch
</p>2018-11-23</li><br/><li><span>冯宇</span> 👍（200） 💬（1）<p>我一直用htop看负载，因为它更直接（在F2配置中勾选所有开关项，打开颜色区分功能），不同的负载会用不同的颜色标识。比如cpu密集型的应用，它的负载颜色是绿色偏高，iowait的操作，它的负载颜色是红色偏高等等，根据这些指标再用htop的sort就很容易定位到有问题的进程。还有个更好用的atop命令，好像是基于sar的统计生成的报告，直接就把有问题的进程标红了，更直观</p>2018-11-23</li><br/><li><span>slam</span> 👍（102） 💬（3）<p>io高的例子 ，为何还是通过pidstat 看cpu？不应该是看哪个进程io高吗？只看sys占比就可以确认了？这里不是很理解</p>2018-11-23</li><br/><li><span>Ray</span> 👍（85） 💬（2）<p>在 sched&#47;loadavg.c 中计算平均值的算法为EMA，这种算法的目的主要是“距离目标预测窗口越近，则数据的价值越高，对未来影响越大”

如果说“更快的计算”应该只有里面的 fixed_power_int 函数用 O(log n) 的时间来算 x^n

所以内核中用 EMA 来算 loadavg 本质上并不是增加计算性能，而是让 loadavg 的趋势化更明显
</p>2018-11-23</li><br/><li><span>孤岛</span> 👍（80） 💬（2）<p>我有一点自己的理解，请老师指正。CPU比喻成一辆地铁，正在使用CPU的进程就是在地铁上的人；等待CPU的进程就是在下一站等地铁来的人；等待I&#47;O的进程就是在下一站要上车和下车的人，虽然现在对CPU没影响，可未来会影响，所以也要考虑到平均负载上。</p>2018-11-23</li><br/><li><span>DJH</span> 👍（69） 💬（5）<p>老师你好，请教一个问题，现在大多数CPU有超线程能力，在计算和评估平均负载的时候，CPU的核数是指物理核数，还是超线程功能的逻辑核数？</p>2018-11-23</li><br/><li><span>每天晒白牙</span> 👍（37） 💬（8）<p>Centos7系统

安装stress（Linux系统压力测试工具）和sysstat（Linux性能工具）

yum install stress 一直找不到镜像处理方式   所以用了rpm方式安装
用rpm方式安装，先从下面的地址下载rpm包
http:&#47;&#47;ftp.tu-chemnitz.de&#47;pub&#47;linux&#47;dag&#47;redhat&#47;el7&#47;en&#47;x86_64&#47;rpmforge&#47;RPMS&#47;stress-1.0.2-1.el7.rf.x86_64.rpm
然后 rpm -Uvh stress-1.0.2-1.el7.rf.x86_64.rpm 安装
sysstat使用yum安装 yum install sysstat

</p>2018-11-24</li><br/><li><span>朱雯</span> 👍（35） 💬（4）<p>1:uptime查看系统负载的命令
2：watch -d uptime 查看cpu负载变化的命令
3:mpstat 查看cpu使用率的命令
4:pidstat 查看关于pid的一些使用情况的命令



1：cpu密集型实验：为了说明负载和cpu使用密集有关系，同时四个窗口查看信息，窗口1:stress --cpu 1 --timeout 600 打开cpu压力测试 窗口2:watch -d uptime 查看平均负载的变化 窗口3:mpstat -P ALL 5 查看cpu状态变化 窗口4:pidstat -u 5 1 了解一下谁
预期值： 老师讲的是如下预期：
1:负载慢慢变为1
2:某一个cpu的使用率达到100%，
3:pidstat可以查看到 stress占用了100%
4:iowait为0ps:这一点是为了说明cpu密集型的进程完全和iowait没有关系的
结果：
完全符合老师预期

结论:cpu密集型的程序可以导致负载增高和cpu使用率变高


2:io密集型测试。说明负载和io密集使用关系，同时开四个窗口查看信息，其中三个查看状态的窗口和cpu密集型查看基本一致，压力测试窗口改为stress -i 1 --timeout 600 
老师预期如下
1:负载慢慢变成1多一点
2:cpu使用率低于iowait
3:来源可以查到来自于stress
实际结果
1:负载确实开始变高到1多一点
2:iowait一直没有变高，但是cpu使用率边高了
3:能看出来stress 的cpu使用率高了

通过留言发现：stress 使用sync的系统调用导致效果失效，当我慢慢的等待一段时间以后，我发现iowait增高一点了。解决方案是：安装stress-ng以及源码安装stress ps:通过留言看到htop和atop命令

改进：通过stress-ng测试以后，iowait确实在飙升,也可以通过源码安装的sysstat中的pidstat查看到stress-ng的使用率变高的情况发生


3:大量进程的场景 压力测试窗口改为 stress -c 8 --timeout 600,其他一致
老师预期如下：
1:负载变高，而且情况很严重
2:stress启动的进程很多，导致cpu过载
结果：基本符合预期

结论：负载增高的三种可能性：1:cpu密集型导致负载高，状况时cpu使用率和负载同时变高 2:io密集型：iowait很高同时负载很高3:进程多类型，如名字所示





ps:源码安装sysstat 
git clone --depth=50 --branch=master https:&#47;&#47;github.com&#47;sysstat&#47;sysstat.git sysstat&#47;sysstat
cd sysstat&#47;sysstat
git checkout -qf 6886152fb3af82376318c35eda416c3ce611121d
export TRAVIS_COMPILER=gcc
export CC=gcc
export CC_FOR_BUILD=gcc
 .&#47;configure --disable-nls --prefix=&#47;usr&#47;local&#47;
 make &amp;&amp;make install</p>2018-12-05</li><br/><li><span>萬萬沒想到</span> 👍（26） 💬（1）<p>解开了我多年来对平均负载的疑问，就凭这点，花的钱也值了！！</p>2018-11-23</li><br/><li><span>glinuxer</span> 👍（21） 💬（1）<p>“不可中断状态的进程则是正在等待 I&#47;O 的进程。”——这句话不严谨。
应该说等待I&#47;O的进程一般是不可中断的。但反过来说是不正确的。不可中断状态不一定是等待I&#47;O。</p>2018-11-23</li><br/><li><span>冰凌</span> 👍（16） 💬（4）<p>1. 平均负载和CPU使用率的区别：
平均负载：系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数
可运行状态：正在使用CPU或者正在等待CPU的进程，也就是我们常用ps命令看到的，处于R状态的进程
不可中断状态：正处于内核态关键流程中的进程，并且这些流程是不可打断的。比如最常见的是等待硬件设备的I&#47;O响应，也就是我们在ps命令当中看到的D状态的进程。
（不可中断状态实际上是系统对进程和硬件设备的一种保护机制。）

CPU使用率：单位时间内CPU繁忙情况的统计，跟平均负载并不完全对应。

2.平均负载和CPU使用率的关系
例如：
1. CPU密集型进程，使用大量的CPU会导致平均负载升高，此时两者是一致的
2. I&#47;O密集型进程，等待I&#47;O也会导致平均负载升高，但是CPU使用率并不一定很高
3. 大量等待CPU进程调度也会导致平均负载升高，此时的CPU使用率也会比较高

3 工具使用
理解了原理的基础上，总结下相关的工具和排查步骤
如果发生系统负载过高响应比较慢应该如何排查
step1: 通过uptime／top看系统负载
Step2: 通过top命令中的%CPU 或者mpstat中的%idle %iowait %wait区分是cpu密集型还是io密集型任务还是大量进程等待调度导致
Step3: 通过pidstat辅助分析具体是哪个进程导致的

评论区：
还是建议用top和ps或者lsof来分析，因为一般线上的机器不会额外安装这之外的工具，而且很多公司用堡垒机登录上去之后其他的基本上都用不了，用其自带的最保险

我一直用htop看负载，因为它更直接（在F2配置中勾选所有开关项，打开颜色区分功能），不同的负载会用不同的颜色标识。比如cpu密集型的应用，它的负载颜色是绿色偏高，iowait的操作，它的负载颜色是红色偏高等等，根据这些指标再用htop的sort就很容易定位到有问题的进程。还有个更好用的atop命令，好像是基于sar的统计生成的报告，直接就把有问题的进程标红了，更直观</p>2019-03-13</li><br/><li><span>C J J</span> 👍（15） 💬（3）<p>来自一名后端开发人员的实验笔记。http:&#47;&#47;note.youdao.com&#47;noteshare?id=7f3c0445f1828c8cd2094de4b59a331b
</p>2019-01-14</li><br/><li><span>踏雪无痕恋</span> 👍（15） 💬（6）<p>讲解的真好，拿着这个问题问了一下身边阿里云P8的性能优化的架构师，居然把他问住了，通过这样的专栏来学习，真的是事半功倍，一定要亲自动手去实验，注意总结。</p>2018-12-10</li><br/>
</ul>