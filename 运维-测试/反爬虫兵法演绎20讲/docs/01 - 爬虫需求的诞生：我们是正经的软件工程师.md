你好，我是DS Hunter，反爬虫专家。

也许你是一个爬虫工程师，也许是反爬虫工程师，甚至，也许你只是一个业务方的普通研发，被授予了反爬的重任。但是，不论你的身份是什么，“什么是爬虫”这个问题都是你必须要了解的。

为什么这么说呢？

可能你常把爬虫挂在嘴边，觉得自己已经很熟悉爬虫了，但当你尝试自己做一个爬虫或者完成一个反爬虫动作时，却发现无从下手。其实，很大的一个原因就是你对于“什么是爬虫”这个问题了解得并不透彻。

从历史的视角来了解爬虫从哪里来、能做什么，以及从诞生到现在的这段时间里都发生了什么样的变化，可以让你对“什么是爬虫”这个问题产生更深度的思考，这也是我要在课程里特地为你设置一个“历史背景篇”的主要原因。咱们接下来正式开始吧。

## **什么是爬虫？**

爬虫是一个历史悠久的需求，严格来说，它甚至比网络出现得还早。或者你也可以理解为，网络出现之后，网络和爬虫才结合成了我们所熟知的网络爬虫。因为互联网大部分的功能其实并没有什么新意，只不过是把线下的场景搬到线上来了。

而爬虫，其实就起源于线下。再聚焦一些，爬虫，起源于再平常不过的——菜市场。

### 买菜和爬虫？买菜也爬虫？

前几天我听了一首很喜欢的歌，叫《说走就走》。里面有一段话，说的是：“走世界，看精彩，从18岁讲到现在，最后到巷口去买菜。”

本意是说，年少充满理想，长大后被生活压垮，每天沉迷于菜场买菜这种小事，再也没有了理想。但是实际上，**买菜并不是小事，它充满了技术含量。**

菜场买菜的大妈们砍价非常厉害——我感觉我这辈子都学不来。对她们来说，即使只差一毛钱，也可能会让她们选择去别的摊位买菜。也许你不太理解这种行为，觉得，我都在这问了价了，就因为隔壁少一毛钱，就去隔壁，这多不好意思啊。但是对于菜场的顾客来说，这很正常啊，“同样的东西， 哪里便宜我就去哪呗”，这是再正常不过的“**博弈**”了。

说回喜欢在网上买东西的你。一个小东西，A网站比B网站便宜一毛钱，你是不是就果断抛弃了B网站？或者A说，价格一样，我包邮。你是不是就直接去A网站买了？这个时候，因为没有面对面的交流，你就没什么不好意思的了。所以说，趋利避害这是人性使然，自古如此，与年代性格都无关。**只要有人的地方，就会有“博弈”。**

最后，在买菜或者买东西的故事里，除了“你”这个主角，商贩们其实也没闲着。他们也会做一些操作，比如让自己的家人去四处转转，看看别的摊位卖多少钱、有没有偷偷降价。如果有顾客来自己的摊位买菜，也会顺便问问，“哎你这个菜多少钱买的啊”，只要不低于成本，他就敢降到一样的价格，甚至更低。

实际上，大妈们获取价格的方法、你对比价格的过程以及商贩们相互获取价格的方法，都可以理解为“爬虫”行为，和网络爬虫其实也没有什么区别。只是人工问价效率低，爬虫效率高。价格，就是在这样不断博弈的过程中，慢慢均衡下来的。而博弈的第一步，就是“问价”——**获取数据**。

### 不止买菜：我只是要数据

为什么获取数据这么重要？其实《孙子兵法》就提到过：知彼知己者，百战不殆。商场如战场，获取数据自古就是胜负的关键。

至于获取数据的需求是怎么产生的，我给你举个例子吧。获取数据的手段——爬虫，很难学的一个主要原因就是描述它的词汇太多了。你可以看下网络上对爬虫的定义，有几个常用的词：爬虫、抓取、spider、crawler……可能我也说不全。日常使用的话，这些词你随便挑哪一个都行。但是搜索对应知识的时候，为了更全面一些，就要全搜一遍。那如果你不想连搜四次，怎样操作才能**一次性拿到所有的结果**呢？

这个时候，聪明的你可能已经想到了，我要不要写个爬虫全拿下来呢？恭喜你，你为了获取爬虫的知识，已经自发地产生了一个爬虫的需求。

因此你会发现，**爬虫需求的产生是自然而然的，**而你的需求不一定是一个坏的需求——你看，我们多正经。是的，技术只是工具，与善恶无关。

最早的Google工程师就是这么想的，或者再早的Yahoo。我们无从得知当时具体发生了什么、第一个爬虫是如何被写出来的。但可以想象的是，**因为当时的互联网数据越来越多，获取信息变得越来越难，于是他们就写了一个网络爬虫来获取数据。**从此，潘多拉的魔盒就被打开，后面的事情就不再可控了。

## 搜索引擎和爬虫

既然提到了Google和Yahoo，我们就紧接着从历史视角，审视一下搜索引擎和爬虫的关系，看看爬虫的早期历史和相关的技术变迁。

### 美好的上古田园时代

搜索引擎可以认为是爬虫的集大成者了。它本质上就是用爬虫**爬取天下数据**，汇聚在自己的网站上，让大家可以在自己的网站上直接**搜索到全天下的知识。**这个操作对于搜索引擎和站点两方都是有利的，搜索引擎自己能够获得稳定客户，甚至商业利益；站点本身可以获得流量，未来也可以获得商业价值。

为了这个双赢的局面，还引发了一个叫robots.txt（也叫robots协议）的君子协定，里面会约定，哪些可以爬，哪些不可以爬。但是因为大家很依赖搜索引擎，所以除非是用户信息，否则一般都是开放的。甚至有些站点不写robots.txt，默认对搜索引擎全部开放。除此之外，还可以写sitemap来指定自己网站都有什么，欢迎搜索引擎来赶紧爬走，给自己打个好评，引导用户过来。大家主动交流，相互沟通，真的是一个美好的上古田园时代。

### 春秋时期

但是美好的上古田园时代由于网络的不断发展，注定不会持久，很快，爬虫就发展到了春秋时期。

- **春秋前期**

在春秋前期，爬虫已经不是新技术了。你的那个不懂技术的老板，可能都已经知道了：想要寻找大量数据，可以用爬虫去爬别人。所以，你就接受了这样的需求，开始学习相关的知识。

但是你也知道，网络历史从 TCP 到 HTTP，现在又回到了 TCP。随着历史的变化，爬虫本身的技术也会随之变化。毕竟，**服务器使用了什么类型的网络，爬虫就要被迫使用什么类型的网络。**

- **春秋中期**

当爬虫开始受网络发展的影响，就注定也会被其它因素影响。在春秋前期，大家逐渐产生“爬取数据”的需求，到了春秋中期，这些需求逐渐演变成了一个业务的雏形。也就是说，在这个时候，**不同的业务开始对爬虫技术产生影响**了。

咱们先说**扒站**这件事。最初爬虫都是一些大公司的特权，小公司自己的业务都做不完，哪有时间去搞爬虫。但是出于业务的需要，一个新的行为就诞生了——站点复制，俗称扒站。

也就是说，别人网站做得好，我刚创业，追赶别人根本来不及。怎么办呢？答案很简单，我写个爬虫把整个网站抓下来不就好了。然后把数据放在我的服务器上，就可以瞬间追上别人的进度，站在同一起跑线。

还有就是**浏览量**的需求了。站长很想让搜索引擎来爬自己的数据，因为有了搜索引擎的爬取，就会有排名，就会有业绩。而为了提高搜索引擎的分数，他们十分渴望搜索引擎来抓取自己所有的数据。

关于搜索引擎爬取自己数据的这件事，我们可以回顾一下历史。

早年的网站结构其实很简单，就是一个服务器，上面挂了一些静态的文件。有的站点甚至会打开目录遍历权限，也就是说你去找一个目录看一下，能直接看到目录下面有什么文件，这种站点扒起来简直太舒服了。 但是如果没有开目录遍历权限，就要麻烦很多了，似乎抓起来就没有前面说得那么容易。

好了，从历史回顾里跳出来，春秋中期的站长，为了给搜索引擎抓取数据提供便利，通常会有两种操作：一种是**sitemap**，也就是给整个站点建一个地图，给对方使用；还一种就是**内链**，通过自己不断引用自己，来实现引导爬虫爬取完整站。

这样一来，爬虫工程师的爬虫思路就显而易见了：既然站长提供了sitemap和内链两种便利，我只要声称自己是搜索引擎就好了。这样对方不但不会拒绝，还会引导我去爬取整个站点。这样，想扒整个站就变得非常容易。

你可能会觉得，这里有点引狼入室的感觉了——难道站长已经有准备了？没有。等狼真的来了也没有什么办法——撑死就是封一封明显太过分的IP。

最后我来给你总结一下这个时期爬虫的爬取思路吧。春秋中期，爬虫基本上就两个爬取思路，一个是**深度优先遍历**， 一个是**广度优先遍历，**它们的最终目的都是抓完整站。所以爬虫会有一个“spider”的名字，蜘蛛能结网，指的就是这个遍历方式。如果你以后面试的时候，面试官着重考查这两个知识点，你要理解，他已经很久不做爬虫了。这是远古时代的基本技能，现在大家已经不太关注这个了。

- **春秋后期**

后来两件事情改变了这个行业的格局。一个是**电子商务的出现和普及**，一个是**站点的动态化和伪静态化**，我们也就随着这两件事从春秋中期进入到了春秋后期。

先看第一件事：电子商务的出现和普及。你还记不记得我在开头提到的一句话：互联网大部分功能其实并没有什么新意，只不过是把线下场景搬到线上来了。

**电子商务其实就是把菜场搬到了线上。** 菜场有爬虫，电子商务就会有爬虫。与搜索引擎不同的是，商场如战场，战场上的较量，有时候就没有那么强调道德了。爬虫也就渐渐**为所欲为**了起来。

另一件事就是站点的动态化和伪静态化，动态化页面导致站点内容变得十分丰富，甚至可以认为近乎无穷无尽，通过改变参数就可以不断改变站点内容，这一点对搜索引擎非常不友好。但是好消息是，这一点对其它爬虫，一样很不友好。

因此，站点开始进行伪静态化。假装自己依然是个静态站点后，爬虫的需求开始变得复杂，单纯的深度优先和广度优先满足不了大家的要求了。尤其是随着Web 2.0的诞生，站点更加复杂，本身也开始了分层，界面是界面，数据是数据。那么我们的爬虫最关注的是什么？是数据。那就是说，爬虫甚至可以只抓数据，跳过界面。这个时候，爬虫就变得**十分高效。**

不过，当爬虫变高效之后，服务器的噩梦就诞生了。由于前后端分离， 静态资源放置于CDN，通常并不是很怕爬虫。但是数据位于服务层，服务层比CDN脆弱得多，爬虫一来，可能**打爆链接数**，甚至可能**击穿数据库**、**拖慢站点性能，**各种诡异的情况都可能发生。

总的来说，**电子商务的出现和普及**以及**站点的动态化和伪静态化**这两件事出现之后，爬虫就很容易不小心惹事。很多文章都会教你，尽量控制频率，不要把站点爬挂。而我们被爬的站长那一方，他欢迎搜索引擎，但是不喜欢爬虫，不过依旧没有太好的办法区分彼此。

如果说爬虫是一场战争，那么现在的春秋时代，大家打仗还是讲究一个“礼”字的。截止到目前，还没有彻底崩坏。但是，根据历史我们可以知道，这样的事情不会持续多久，战国，很快就要来了。

## 小结

好了，最后我来给你小结一下。今天和你聊了爬虫的产生、早期历史以及一些相关的技术变迁。

可以说，“爬虫”是竞争的必然产物，而网络的出现，赋予了爬虫在互联网领域的生命。再次强调，这项技术只是工具，与善恶无关。

![](https://static001.geekbang.org/resource/image/fb/c4/fb75017928052748b4d88267e86565c4.jpg?wh=1920x869)

在美好的上古田园时代，爬虫彬彬有礼，用技术不断辅助大家，让整个互联网变得更好。搜索引擎自己能够获得稳定客户，甚至商业利益。而站点本身可以获得流量，未来也可以获得商业价值。你看，**需求正经，做的也是正经事**。

截止到这个时候，爬虫还没有任何过错，还没有到现在这种人人喊打的地步。如果人类的爬虫技术止步于此，那么这个世界将非常美好。遗憾的是，人性自古不变，行业建设到一定程度就会产生内卷。

在春秋时期，随着不同业务需求的诞生，爬虫技术也随之发展。春秋前期，我们发现爬虫开始不停地迭代，适应网络环境。后来，春秋中期的扒站行为，本身已经是一种轻度内卷了。同时，站长出于对浏览量的需求，提供了sitemap这张地图以及内链的方式，助长了爬虫疯狂爬取的气焰。而到了春秋后期，电子商务更为爬虫增添了不少的商业气息，商人逐利，爬虫也逐渐为所欲为。站点的动态化和伪静态化，让爬虫直接爬取数据层，站点无法承受攻击……

下一讲，我们会进入到战国时期，看下礼乐制度彻底崩溃、内卷到血流成河的时候，整个行业会成为什么样子。而这，也是你我共同面临的环境。

## 思考题

好了，这次是我第一次给你留思考题。下面有三个方向，你可以选择一个来和我分享：

1. 站长在喜欢搜索引擎的同时痛恨爬虫，不过搜索引擎本身也是一种爬虫。那么，假如一个爬虫冒充搜索引擎，怎么办？
2. 爬虫为这个世界做出了什么贡献？
3. 你的爬虫或者反爬虫经历是什么？有什么奇葩的经历吗？

期待你在评论区的分享，我会及时回复，不过要记得注意保密脱敏。

![](https://static001.geekbang.org/resource/image/4c/5e/4c46d50182f789041ef81ef206fdcb5e.jpg?wh=1500x1615)
<div><strong>精选留言（14）</strong></div><ul>
<li><span>程序员二师兄</span> 👍（8） 💬（1）<p>本人刚接触爬虫这一块不久，看到思考题留的作业，按照自己对爬虫浅薄的理解回答一下：

1. 假如爬虫冒充搜索引擎，怎么办？

以百度搜索引擎的爬虫为例、爬虫会带有标识，如 baiduspider，可以初步判断为搜索引擎。

假如其他爬虫此时也加上了baiduspider的标识，那么可以根据robots.txt 协议来进行处理。

爬虫所抓取的链接在robots.txt协议中，进一步可以认为搜索引擎。

而往往其他爬虫不像搜索引擎，它是不遵守robots.txt协议的，它抓取的链接以及数据可能也不在约定的协议中，那么可以认为爬虫冒充了搜索引擎。

此时对这类爬虫进行拦截，识别到这类爬虫后，接口可以返回非正常数据，还见过虚假数据，让竞争对手拿到的是虚假数据。

2. 爬虫为这个世界做了什么贡献？

个人认为，爬虫对这个世界最大的贡献是数据的聚合。

没有爬虫之前，每个站点的数据都犹如一座孤岛，很难在众多孤岛找到所需要的数据，解决待满足的需求。

搜索引擎的爬虫很好的解决这个问题，只需要一个输入框，输入想问的问题，搜索引擎将爬虫抓取到的数据进行优化，将更相关的资料优先展示在网页上。

3. 你的爬虫或者反爬虫的经历是什么？有什么奇葩的经历吗？

爬虫经历：
一、
为了找到某些关键词在搜索引擎的需求以及权重。
将某一个关键词，通过爬虫的方式从各大搜索引擎获取前10条返回结果。
搜索引擎能够返回的数据，说明需求量是比较大的。

二、
通过爬虫抓取第三方数据平台，获取文章以及短视频的各方面的数据。
比如通过爬虫对短视频平台的视频去水印、视频文案提取。

反爬虫经历：

接口防刷。

简单介绍一下背景，所在的公司有电商业务，当品牌做一些活动时，参与人数会比较多，而其中有小部分人会利用爬虫来刷接口。

处理方法：
针对用户的请求及频率，如果是爬虫，频率会比较高，增加图形验证码，通过图形验证码才能后续的操作。

自己的奇葩经历：
自从了解一些爬虫知识后，看到有意思的网站或者app，总是忍不住想抓包看一下它们的接口。

经常魔怔，比如看到一些加密的请求，虽然不知道有什么意义，总是想研究一番，常常研究半天还是没能琢磨透。
</p>2022-01-20</li><br/><li><span>ll</span> 👍（5） 💬（1）<p>我的经历：
1、 16年开始做爬虫，那个时候什么58、美团、淘宝什么的，数据都是免费爬，当时我们的一个目标就是怎么重复利用cpu，带宽，让我们的爬虫采集效率最快。那个时候淘宝的数据都是没有反爬的，我们的工作就是疯狂写爬虫，很少有反爬的，那个时候我记得我3个月写了快100跟网站的爬虫，所有爬虫一键爬起来的时候，那个壮观，现在想想都觉得我疯了；
2、后来发现有些小的障碍了，比如下一页的连接是js生成的，网站要开始限制cookie了，某些登录验证需要梳理他的js逻辑了，比如微博和百度贴吧，不过那个时候捋下逻辑，还是可以搞定的，从那个时候开始，爬虫的速度，就再也不是面试的考点了，都是问怎么安全、稳定；
3、 后来就发现了一些特别恶心的，比如请求的参数就一个很大的字符串，所有请求体的都是加密成一个字符串，验证header里也是加密的，每此请求header里的auth都是一次性的；完了js还没法逆向回去，或者说我没法逆向回去，你调试的时候还会定位到你，把你封ip，之前就被这么搞过，不过后来还是搞定了，我记得是瑞数科技的专门做的，都过去好多些年了，希望不要针对我；
4、再后来就越来越觉得，几乎每个网站都有反爬虫，但是也不是突破不了，然而突破了好像对我们来说也意义不大，因为有些硬性的指标，比如你的账户、跟ip绑定后，限制了你的行为，只能有那么多次的访问上限，基本上限制死了单个账号的数据访问量，爬虫已经不是一个人可以做的事情了，背后需要很多账号、ip这样的资源，有时候感觉就是财力的比拼；甚至后来发现天眼查充了会员后，同样的接口，没充钱的数据你拿到是假数据，还需要研究他的js再处理一下，而会员就可以爬到真数据，我发现后震惊了，立马冲了个会员，工作量一下就降低了不少，才感觉到别人产品经理已经把挣钱放到我们爬虫开发人员身上了，再后来越来越发现，爬虫已经告别了西部牛仔--一个人闯荡的、单靠技术就能过得不错的时代了，以后的数据也会越来越难获取，爬虫也不再是一个人的武林了；
5、 逐渐疏远爬虫，一想到破解后维护也是个大问题，就没有动力；

现在想想，奇葩的经历，肯定要算天眼查要挣我们爬虫开发人员的钱，我是被震惊了</p>2022-02-11</li><br/><li><span>lidashuang</span> 👍（3） 💬（2）<p>爬过最难爬的是美团，各种给你下毒</p>2022-01-26</li><br/><li><span>demo123567</span> 👍（2） 💬（1）<p>第一个问题应该是user-agent，虽然可以模拟；然后大型搜索引擎爬虫一般都是有固定的IP段，所以应该也可以识别</p>2022-01-26</li><br/><li><span>fsc2016</span> 👍（2） 💬（1）<p>感觉现在爬虫对抗，慢慢从web转战到移动端了</p>2022-01-20</li><br/><li><span>peter</span> 👍（2） 💬（1）<p>写得太好啦，牛啊，文采真好，通顺，有趣，也没有错别字！！！！  我还有很多课程没有看，这个课程和自己目前的关系并不是很大，犹豫再三才买的。真庆幸自己没有错过这么好的文章。理工男能写这么好，不容易，不多见啊。</p>2022-01-20</li><br/><li><span>GAC·DU</span> 👍（2） 💬（1）<p>一次经历见证了一家公司技术的成长，甚至把后端由15人加到了30。从携cookie能登录到手机验证码再到扫脸登录，api加了token，后来把限流和熔断也加上了。</p>2022-01-19</li><br/><li><span>圆桌π</span> 👍（1） 💬（1）<p>没接触过爬虫，觉得新奇，买课来看看。
第一次听说爬虫，是数据库老师说找数据，然后又半开玩笑的说最好不要。极客时间App的一门法律课里也有提及。

期待课程老师，继续加油！💪</p>2022-02-26</li><br/><li><span>ZeroIce</span> 👍（1） 💬（1）<p>虽然说作者没有说出真实名字，但说话风格特别像一个大佬（上一篇文章有那个大佬评论：你是个有故事的人？）</p>2022-02-05</li><br/><li><span>Blue</span> 👍（1） 💬（1）<p>2. 爬虫从技术的角度上来讲，我觉得一方面提升了一些专业人员获取信息的效率，我们可以脱离浏览器，通过爬虫程序来获取我们期望得到的数据（不影响服务性能且不违规违法的前提下），这样就有更多的时间与精力去专注于解决更难更有意义的问题，这也是我当初做爬虫的一个初衷；另一方面我认为爬虫与反爬是存在良性竞争的，互相博弈可以提升各自的技术能力与认知边界，同时也让服务提供方有的放矢地设计出更具容错性，安全性的系统。</p>2022-01-26</li><br/><li><span>leslie</span> 👍（1） 💬（1）<p>爬虫其实是变形为其中的内容再推广，这就像搜索引擎；同样像作者所说；爬取对被爬者的服务器带宽造成了很大压力，持续消耗对方资源这个就有点恶意攻击了。</p>2022-01-21</li><br/><li><span>默默</span> 👍（0） 💬（1）<p>加密的爬虫改怎么破解？该怎么分析js代码等？</p>2022-01-23</li><br/><li><span>ll</span> 👍（11） 💬（0）<p>我的经历：
1、 16年开始做爬虫，那个时候什么58、美团、淘宝什么的，数据都是免费爬，当时我们的一个目标就是怎么重复利用cpu，带宽，让我们的爬虫采集效率最快。那个时候淘宝的数据都是没有反爬的，我们的工作就是疯狂写爬虫，很少有反爬的，那个时候我记得我3个月写了快100跟网站的爬虫，所有爬虫一键爬起来的时候，那个壮观，现在想想都觉得我疯了；
2、后来发现有些小的障碍了，比如下一页的连接是js生成的，网站要开始限制cookie了，某些登录验证需要梳理他的js逻辑了，比如微博和百度贴吧，不过那个时候捋下逻辑，还是可以搞定的，从那个时候开始，爬虫的速度，就再也不是面试的考点了，都是问怎么安全、稳定；
3、 后来就发现了一些特别恶心的，比如请求的参数就一个很大的字符串，所有请求体的都是加密成一个字符串，验证header里也是加密的，每此请求header里的auth都是一次性的；完了js还没法逆向回去，或者说我没法逆向回去，你调试的时候还会定位到你，把你封ip，之前就被这么搞过，不过后来还是搞定了，我记得是瑞数科技的专门做的，都过去好多些年了，希望不要针对我；
4、再后来就越来越觉得，几乎每个网站都有反爬虫，但是也不是突破不了，然而突破了好像对我们来说也意义不大，因为有些硬性的指标，比如你的账户、跟ip绑定后，限制了你的行为，只能有那么多次的访问上限，基本上限制死了单个账号的数据访问量，爬虫已经不是一个人可以做的事情了，背后需要很多账号、ip这样的资源，有时候感觉就是财力的比拼；甚至后来发现天眼查充了会员后，同样的接口，没充钱的数据你拿到是假数据，还需要研究他的js再处理一下，而会员就可以爬到真数据，我发现后震惊了，立马冲了个会员，工作量一下就降低了不少，才感觉到别人产品经理已经把挣钱放到我们爬虫开发人员身上了，再后来越来越发现，爬虫已经告别了西部牛仔--一个人闯荡的、单靠技术就能过得不错的时代了，以后的数据也会越来越难获取，爬虫也不再是一个人的武林了；
5、 逐渐疏远爬虫，一想到破解后维护也是个大问题，就没有动力；

现在想想，奇葩的经历，肯定要算天眼查要挣我们爬虫开发人员的钱，我是被震惊了</p>2022-02-11</li><br/><li><span>默默</span> 👍（0） 💬（0）<p>加密的爬虫随机header相关的，该怎么去破解爬虫呢？</p>2022-01-23</li><br/>
</ul>