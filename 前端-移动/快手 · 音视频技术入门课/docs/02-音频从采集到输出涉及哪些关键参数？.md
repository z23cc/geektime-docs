你好，我是刘歧。

上一节课我们学习了视频与图像相关的基础知识，相信你对视频/图像中的色彩表示方式、色域、帧率等相关概念已经有了一定的了解。在音视频技术开发与应用领域，除了视频与图像的知识外，我们还会接触到一些音频相关的知识，所以这节课我们会聚焦音频基础知识，为之后FFmpeg 音频相关内容的学习做好铺垫。

我们平常听到的自然界的声音，比如说鸟鸣、水流，其实是一种模拟信号，声音是振动产生的一种声波，通过气态、液态、固态的物理介质传播并能被人或动物感知的波动现象。声音的频率一般会以赫兹（Hz）表示，指每秒钟周期性振动的次数。而声音的强度单位则用分贝（dB）来表示。现如今我们在电脑上、Pad上、手机上听到的音乐、声音等音频信号，均为数字信号。

## 音频采样数据格式

介绍音频采样数据格式之前，我们需要先了解音频从采集一直到我们耳朵听到声音这个过程中都发生了什么，我们先看一下下面这张流程图：

![图片](https://static001.geekbang.org/resource/image/ae/f2/aec34f3bc25b0ffcca2718eaa0b5b1f2.png?wh=1331x352)

首先我们说的话或者在自然界中听到的一些声音，比如鸟鸣，水流等，都是通过空气振动来传输的模拟信号，我们可以通过麦克风或者拾音器采集到声音的模拟信号，然后将模拟信号转换成数字信号，这个过程可以通过麦克风来做，也可以通过音频的转换器来做，转换成数字信号之后将数字信息存储起来，或者输出到扬声器，扬声器会根据数字信号产生一定频率的振动，然后通过空气传播模拟信号到我们的耳朵里面，我们就听到了对应的声音。

在这个流程里我们需要了解一个基本的操作，就是**先采集到模拟信号，然后通过ADC（模数转换）将模拟信号转换成数字信号以后，再通过 PCM（Pulse Code Modulation）脉冲编码调制对连续变化的模拟信号进行采样、量化和编码转换成离散的数字信号，**从而实现音频信号的采集。另外，也可以将采集的音频信号输出到扬声器、耳机之类的设备。

我们上面说的PCM文件就是未经封装的音频原始文件，或者叫做音频“裸数据”。不同的扬声器、耳机设备，甚至是声卡输出设备，对音频的裸数据支持的情况不一样，有的设备支持单精度浮点型数据、有的设备支持双精度浮点型数据、有的设备支持无符号型数据、有的设备支持有符号型数据。因为输出的数据类型的支持不同，所以PCM采样数据的格式在输出之前，需要转换一下。这些数据的格式我们通常称之为采样数据格式。

## 音频采样频率

音频PCM数据的输入和输出是需要有一个频率的，频率通常在我们听觉可接受的范围内，太高或者太低我们都听不见，通常我们人耳能够听到的频率范围是在20Hz～20kHz之间，为了保证音频不失真，音频的采样频率通常应该在40kHz以上，而理论上采样率大于40kHz的音频格式都可以称之为无损格式。现在一般的专业设备的采样频率为44100Hz（也称之为44.1kHz）。并且44.1kHz是专业音频中的最低采样率。当然要听到更高采样率，比如96kHz、192kHz采样频率中的细节的话，就取决于耳朵和对应的设备了。

下面我简单地介绍一下，在数字音频领域常用的采样率与对应的使用场景：

- 8000 Hz 主要是电话通信时用的采样率，对于传达人们说话时的声音已经足够了；
- 11025 Hz、22050 Hz 主要是无线电广播用的采样率；
- 44100 Hz 常用于音频 CD，MP3 音乐播放等场景；
- 48000 Hz 常用于 miniDV、数字电视、DVD、电影和专业音频等设备中。

## 音频声道及其布局

当我们戴着耳机看电视剧、电影、听音乐、开会的时候，会发现左右耳朵听到的声音有时候会有一些差别，尤其是当我们看TVB港剧的时候，一只耳朵听到的是粤语，另一只耳朵听到的是普通话。因为视频里面的音频支持左声道右声道内容不同，所以有些时候我们看电影可以切换左声道右声道模式。

采集不同方位的声源，然后通过不同方位的扬声器播放出来就产生了不同的声道。其实我们常见的声道内容除了左声道、右声道，还有立体声等，当我们听到的音频声道比较多，比如听交响乐的时候，立体感会尤为明显，示意图如下：

![图片](https://static001.geekbang.org/resource/image/26/d0/2633eb025d3243359794929b518f76d0.png?wh=1249x850)

实际上，音频的声道布局不仅仅是上图这么简单。音频技术发展至今，声道布局远比图片显示的复杂得多，在后面课程中我们会看到更多、更复杂的声道布局。

## 音频采样位深度

采样的位深度，也叫采样位深，它决定了声音的动态范围。平时，我们常见的16位（16bit）可以记录大概 96 分贝（96dB）的动态范围。也可以理解为每一个比特大约可以记录6dB的声音。同理，20bit可记录的动态范围大概是120dB，24bit就大概是144dB。

计算公式如下：

$$20 \\times math.log10(65535)$$

举个例子，我们假定0dB为峰值，那么音频的振动幅度就需要以向下延伸计算，所以音频可记录的动态范围就是“-96dB～0dB”。而24bit的高清音频的动态范围就是“-144dB～0dB”。由此可见，位深度较高时，有更大的动态范围可利用，可以记录更低电平的细节。

**但位深度并不是越大越好，也不是越小越好，不同的场景有不同的应用。**

44dB 属于人类可以接受的程度，55dB 会使人感觉到烦躁，60dB 会让人没有睡意，70dB 会令人精神紧张，85dB 长时间听会让人感觉刺耳，100dB 会使人暂时失去听觉，120dB 可以瞬间刺穿你的耳膜，160dB 会通过空气振波震碎玻璃，200dB 可以使人死亡。也就是说，其实如果真的能够让自己的声音达到一定分贝的话，武侠片里面的狮吼功是有可能成为现实的。

通常为了高保真，我们会选择使用32bit，甚至64bit来表示音频。而常规音频通话使用16bit来表示即可，当然条件有限的话，8bit也可以，但它是底线。因为8bit的音频表示，听起来有时候会比较模糊。

## 音频的码率

接下来我们看一下音频的码率。所谓码率，我们通常可以理解为按照某种频率计算一定数据量的单位，重点体现在“率”上面，我们常用的码率统计时间单位为秒，所以码率也就是一秒钟的数据量，通常我们用bps（bits per second）来表示，也就是每秒钟有多少位数据。而我们平时所说的码率，可以简单理解为每秒钟存储或传输的编码压缩后的数据量。

我们在很多音乐播放器软件中能看到音乐的格式，比如腾讯音乐里面的SQ、HQ、无损等，这些音乐的音频码率、采样率都是很高的。

那这个音频码率是怎么算出来的呢？其实这里有一个公式，可以帮助我们算出音频的码率。例如我们有一个双声道立体声、采样率是48000、采样位深是16位、时长为1分钟的音频，它的存储空间占用计算应该是：

$$声道数\\times采样率\\times采样位深\\times时长 = 2\\times48000\\times16\\times60 = 92160000 b = 11520000 B = 11.52 MB$$

码率应该是 ：

$$\`92160000b\\div60s=1536000bps=1536kbps=1.536Mbps\`$$

音频的码率可以间接地表示音频的质量，一般高清格式的码率更高。

## 音频的编解码

我们在传输音频文件的时候经常会看到文件名后面有MP3、AAC这样的后缀，其实这些都是音频编码的格式。因为音频在传输和存储时，如果直接存储PCM音频数据的话，消耗的带宽或者存储空间会比较多，所以我们为了节省传输带宽或者存储，通常会选择对音频数据做编码压缩处理。

我们在互联网上常见的音频编码有AAC、MP3、AC-3、OPUS，个别地方还可能会使用WMA，但是从兼容性来看，AAC和OPUS更出众一些。目前AAC应用于众多音乐播放器和音乐格式封装中，OPUS常见于语音通信中。当然还有很多其他的音频编码压缩的方法，这里我就不一一列举了。在后面课程中我们会接触到更多的音频压缩技术与方法。

不知道你有没有发现，现在使用AAC编码格式的次数越来越多了，为什么大家突然都开始用AAC做音频编码了，以前很火的MP3呢？其实MP3也还在用，只不过MP3的音频编码压缩方式相对于AAC来说，性价比低了一些。对比二者的高音质，AAC HEv2无论是从码率、清晰度还是音频的还原度来说，都比MP3更优秀。详细的对比数据，我们会在后面讲FFmpeg具体操作音频编码与解码的时候介绍到，这里你稍加了解即可。

## 小结

到这里，音频基础内容就讲完了，我们了解了音频的采样格式、音频采样率、音频声道及其布局、采样位深度，最后学会了计算音频码率，这些内容在后面我们都会频繁地用到，尤其是当我们做音频编码与解码的时候，需要考虑到这些参数的兼容情况。

![图片](https://static001.geekbang.org/resource/image/6f/a1/6fc968efe49636c453c7e5ff83837aa1.png?wh=1920x1237)

而在我们做音频压缩的时候，也需要考虑自己的音频用于哪些场景，比如做音频通话的话可以考虑使用OPUS，因为基于OPUS的音频，处理语音更方便一些，例如回声消除，降噪等。如果是做音乐压缩，我们可以考虑AAC，因为AAC支持的音质与硬件兼容性更好一些。如果还要效果更好，但不太要求兼容性的话，AC-3是一个不错的选择，因为杜比之类的音频，尤其是在全景声音乐压缩的场景下，使用AC-3做音频压缩效果更好，能够听到的细节会比AAC压缩的音频更多一些。

## 思考题

好了，这就是今天的全部内容，最后我给你留一道思考题吧！当我们播放一段PCM音频的时候，声音听上去比正常声音显得更尖更细，但是速度是正常的，是什么原因呢？

希望你能开动脑筋，欢迎你在评论区留下你的答案和我讨论，也欢迎你把这节课分享给需要的朋友，我们下节课再见！
<div><strong>精选留言（7）</strong></div><ul>
<li><span>最初的印象</span> 👍（0） 💬（1）<p>播放pcm需要指定正确的采样率ar，声道数ac，位深度合适才能正常不播放。比如：ffplay -ar 44100 -ac 2 -f s16le out.pcm</p>2022-09-15</li><br/><li><span>keepgoing</span> 👍（0） 💬（2）<p>老师能揭晓下思考题的答案吗，除了采样率，请问采样位深也会影响音色吗，不知道是不是从这个方向去思考，感谢</p>2022-08-20</li><br/><li><span>大土豆</span> 👍（3） 💬（2）<p>有些PCM数据比如是 单声道 16位  44100的格式，播放的时候设置错了，按双声道来播放，就自带的快进效果，变速的时候会附加变调的效果。</p>2022-07-27</li><br/><li><span>Loken</span> 👍（2） 💬（0）<p>讲得很好</p>2022-07-27</li><br/><li><span>MADAO</span> 👍（1） 💬（0）<p>通俗易懂</p>2022-09-02</li><br/><li><span>ifelse</span> 👍（0） 💬（0）<p>学习打卡</p>2023-12-20</li><br/><li><span>破绽</span> 👍（0） 💬（0）<p>期待更新</p>2022-07-29</li><br/>
</ul>