你好，我是李智慧。

我们知道，“高并发”是现在系统架构设计的核心关键词。一个架构师如果设计、开发的系统不支持高并发，那简直不好意思跟同行讨论。但事实上，在架构设计领域，高并发的历史非常短暂，这一架构特性是随着互联网，特别是移动互联网的发展才逐渐变得重要起来的。

现在有很多大型互联网应用系统，其用户是面向全球的普通大众，用户体量动辄十几亿。这些用户即使只有万分之一同时访问系统，也会产生十几万的并发访问量。

因此，高并发是现在的大型互联网系统必须面对的挑战，当同时访问系统的用户不断增加时，要消耗的系统计算资源也不断增加。所以系统需要**更多的CPU和内存**去处理用户的计算请求，需要**更多的网络带宽**去传输用户的数据，也需要**更多的硬盘空间**去存储用户的数据。而当消耗的资源超过了服务器资源极限的时候，服务器就会崩溃，整个系统将无法正常使用。

今天我将基于高并发系统的技术挑战，来为你介绍典型的分布式解决方案。这节课的内容，会被应用到后面的大部分实战案例中。所以我希望通过这节课，带你做个简单的预习，同时你也能对自己学过的高并发技术做个简单回顾。

我要先说明一点，今天的高并发系统架构方法比较多，但它们是殊途同归的，都要遵循一个相同的高并发应对思路。所以我们今天的首要目标就是明确这个思路到底是什么，也就是要搞清楚高并发系统架构的方法论。

### 高并发系统架构的方法论

高并发的技术挑战，核心就是为了满足用户的高并发访问，系统需要提供更多的计算资源。那么如何提供这些计算资源，也就是说，如何使系统的计算资源随着并发的增加而增加？

对此，人们提出各种技术解决方案，这些解决方案大致可以分成两类，一类是传统大型软件系统的技术方案，被称作垂直伸缩方案。**所谓的垂直伸缩就是提升单台服务器的处理能力**，比如用更快频率的CPU、更多核的CPU、更大的内存、更快的网卡、更多的磁盘组成一台服务器，从普通服务器升级到小型机，从小型机提升到中型机，从中型机提升到大型机，从而使单台服务器的处理能力得到提升。通过这种手段提升系统的处理能力。

当业务增长，用户增多，服务器计算能力无法满足要求的时候，就会用更强大的计算机。计算机越强大，处理能力越强大，当然价格也越昂贵，技术越复杂，运维越困难。

由于垂直伸缩固有的这些问题，人们又提出另一类解决方案，被称作**水平伸缩方案**。所谓的水平伸缩，指的是不去提升单机的处理能力，不使用更昂贵更快更厉害的硬件，而是使用**更多的服务器**，将这些服务器构成一个**分布式集群**，通过这个集群，对外统一提供服务，以此来提高系统整体的处理能力。

水平伸缩除了可以解决垂直伸缩的各种问题，还有一个天然的好处，那就是随着系统并发的增加，可以一台服务器一台服务器地添加资源，也就是说，具有更好的弹性。而这种弹性是大多数互联网应用场景所必须的。因为我们很难正确估计一个互联网应用系统究竟会有多少用户来访问，以及这些用户会在什么时候来访问。而水平伸缩的弹性可以保证不管有多少用户，不管用户什么时候来访问，只要随时添加服务器就可以了。

因此现在的大型互联网系统多采取水平伸缩方案，来应对用户的高并发访问。

### 高并发系统架构的方法

我们知道了分布式集群优势明显，但是将一堆服务器放在一起，用网线连起来，并不能天然地使它们构成一个系统。要想让很多台服务器构成一个整体，就需要在架构上进行设计，使用各种技术，让这些服务器成为整体系统的一个部分，将这些服务器有效地组织起来，统一提升系统的处理能力。

这些相关的技术就是高并发系统架构的主要技术方法，其核心是各种**分布式技术**。

#### 分布式应用

应用服务器是处理用户请求的主要服务器，工程师开发的代码就部署在这些服务器上。在系统运行期间，每个用户请求都需要分配一个线程去处理，而每个线程又需要占用一定的CPU和内存资源。所以当高并发的用户请求到达的时候，应用服务器需要创建大量线程，消耗大量计算机资源，当这些资源不足的时候，系统就会崩溃。

解决这个问题的主要手段就是使用**负载均衡服务器**，将多台应用服务器构成一个分布式集群，用户请求首先到达负载均衡服务器，然后由负载均衡服务器将请求分发到不同的应用服务器上。当高并发的用户请求到达时，请求将被分摊到不同的服务器上。这样一来，每台服务器创建的线程都不会太多，占用的资源也在合理范围内，系统就会保持正常运行。

通过负载均衡服务器构建分布式应用集群如下图。

![图片](https://static001.geekbang.org/resource/image/9d/b2/9d52974c88c9141f13d278222fe9a0b2.jpg?wh=1920x1068)

#### 分布式缓存

系统在运行期需要获取很多数据，而这些数据主要存储在数据库中，如果每次获取数据都要到数据库访问，会给数据库造成极大的负载压力。同时数据库的数据存储在硬盘中，每次查询数据都要进行多次硬盘访问，性能也比较差。

目前常用的解决办法就是使用**缓存**。我们可以将数据缓存起来，每次访问数据的时候先从缓存中读取，如果缓存中没有需要的数据，才去数据库中查找。这样可以极大降低数据库的负载压力，也有效提高了获取数据的速度。同样，缓存可以通过将多台服务器够构成一个分布式集群，提升数据处理能力，如下图。

![图片](https://static001.geekbang.org/resource/image/e8/6b/e8095a7b1ae1bfe0b942ff071a343f6b.jpg?wh=1920x372)

首先应用程序调用分布式缓存的客户端SDK，SDK会根据应用程序传入的key进行路由选择，从分布式缓存集群中选择一台缓存服务器进行访问。如果分布式缓存中不存在要访问的数据，应用程序就直接访问数据库，从数据库中获取数据，然后将该数据写入到缓存中。这样，下次再需要访问该数据的时候，就可以直接从缓存中得到了。

#### 分布式消息队列

分布式消息队列是**解决突发的高并发写操作问题和实现更简单的集群伸缩**的一种常用技术方案。消息队列架构主要包含三个角色：消息生产者、消息队列、消息消费者，如下图。

![图片](https://static001.geekbang.org/resource/image/c2/4e/c24377a57d8a107f936aaedf22eb2a4e.jpg?wh=1920x645)

比如我们要写数据库，可以直接由应用程序写入数据库，但是如果有突发的高并发写入请求，就会导致数据库瞬间负载压力过大，响应超时甚至数据库崩溃。

但是如果我们使用消息队列，应用程序（消息生产者）就可以将写数据库的操作，写入到消息队列中，然后由消息消费者服务器从消息队列中消费消息，根据取出来的消息将数据写入到数据库中。当有突发的高并发写入的时候，只要控制消息消费者的消费速度，就可以保证数据库的负载压力不会太大。

同时，由于消息生产者和消息消费者没有调用耦合，当我们需要增强系统的处理能力，只需要增加消息生产者或者消息消费者服务器就可以了，不需要改动任何代码，实现伸缩更加简单。

#### 分布式关系数据库

关系数据库本身并不支持伸缩性，但是关系数据库又是存储数据最传统的手段。为了**解决关系数据库存储海量数据以及提供高并发读写的问题**，人们提出了将数据进行分片，再将不同分片写入到不同数据库服务器的方法。

通过这种方法，我们可以将多台服务器构建成一个分布式的关系数据库集群，从而实现数据库的伸缩性，如下图。

![图片](https://static001.geekbang.org/resource/image/f4/ac/f46f243c02677e4042a7a3c8653f8bac.jpg?wh=1920x1068)

#### 分布式微服务

我们前面提到的分布式应用，是**在一个应用程序内部完成大部分的业务逻辑处理**，然后将这个应用程序部署到一个分布式服务器集群中对外提供服务，这种架构方案被称作单体架构。与此相对应的是分布式微服务架构，这是一种目前更广为使用的架构方案，如下图。

![图片](https://static001.geekbang.org/resource/image/fd/7e/fd161ed1325d874c537a4bcf670a977e.jpg?wh=1920x645)

微服务的核心思想是**将单体架构中庞大的业务逻辑拆分成一些更小、更低耦合的服务，然后通过服务间的调用完成业务的处理。**

具体处理过程是：用户请求通过负载均衡服务器分发给一个微服务网关集群，在网关内开发一个简单的微服务客户端，客户端调用一个或多个微服务完成业务处理，并将处理结果构造成最后的响应结果返回给用户。

微服务架构的实现需要依赖一个微服务框架，这个框架包括一个微服务注册中心和一个RPC远程调用框架。微服务客户端通过注册中心得到要调用的微服务具体的地址列表，然后通过一个软负载均衡算法选择其中一个服务器地址，再通过PRC进行远程调用。

此外，除了以上这些分布式技术，高并发系统中常用的还有大数据、分布式文件、区块链、搜索引擎、NoSQL、CDN、反向代理等技术，也都是一些非常经典的分布式技术。如果你对这些技术感兴趣，想要更详细地了解它们，那么你可以阅读我在极客时间的另两个专栏，分别是[《从0开始学大数据》](https://time.geekbang.org/column/intro/100020201?tab=intro)和[《后端技术面试38讲》](https://time.geekbang.org/column/intro/100040201?tab=intro)。

### 系统并发指标

我们这个专栏大部分案例都是关于高并发系统的，那么和并发相关的指标有哪些？并发量又该如何估算？首先，我们来看和并发相关的指标，主要有以下这些。

**目标用户数**

目标用户数是所有可能访问我们系统的潜在用户的总和，比如微信的目标用户是所有中国人，那么微信的目标用户数就是13亿。目标用户数可以反映潜在的市场规模。

**系统用户数**

并不是所有的目标用户都会来访问我们的系统，只有那些真正访问过我们系统的用户才被称作系统用户。越是成功的系统，系统用户数和目标用户数越接近。

**活跃用户数**

同样地，访问过我们系统的用户可能只是偶尔过来访问一下，甚至只访问一次就永不再来。所以我们还需要关注用户的活跃度，也就是经常来访问的用户规模有多大。如果以一个月为单位，那么一个月内只要来访问过一次，就会被统计为活跃用户，这个数目被称为月活用户数。同样地，一天内访问过的总用户数被称为日活用户数。

**在线用户数**

当活跃用户登录我们的系统的时候，就成为在线用户了。在线用户数就是正在使用我们系统的用户总数。

**并发用户数**

但在线用户也并不总是在点击App，请求我们的系统服务，他可能搜索得到一个页面，然后就在自己的手机端浏览。只有发起请求，在服务器正在处理这个请求的用户才是并发用户。事实上，高并发架构主要关注的就是用户发起请求，服务器处理请求时需要消耗的计算资源。所以并发用户数是架构设计时主要关注的指标。

在我们后续的案例分析中，我都是根据市场规模估计一个目标用户数，然后再根据产品特点、竞品数据等，逐步估算其他的用户数指标。

有了上面这些用户数指标，我们就可以进一步估算架构设计需要考虑的其他一些技术指标，比如每天需要新增的**文件存储空间**，存储总系统用户需要的**数据库规模**，**总网络带宽**，**每秒处理的请求数**等等。

技术指标估算能力是架构师的一个重要能力，有了这个能力，你才有信心用技术解决未来的问题，也会因此对未来充满信心。这个估算过程，我们会在后面的案例课中不断重复，你也可以根据你的判断，分析这些估算是否合理，还有哪些没有考虑到的、影响架构设计的指标。

### 小结

高并发架构的主要挑战就是**大量用户请求需要使用大量的计算资源**。至于如何增加计算资源，互联网应用走出了一条水平伸缩的发展道路，也就是通过**构建分布式集群架构**，不断向集群中添加服务器，以此来增加集群的计算资源。

那如何增加服务器呢？对此，又诞生了各种各样的分布式技术方案。我们掌握了这些分布式技术，就算是掌握了高并发系统架构设计的核心。具体这些技术如何应用在高并发系统的架构实践中，我们在后面的案例中会不断进行展示。

### 思考题

我们在前面提到过，分布式缓存客户端SDK会根据应用程序传入的key，从分布式缓存集群中选择一台服务器进行访问，那么这个客户端SDK如何选择服务器呢？它怎么知道自己要访问的key在哪台服务器上？你可以尝试说说自己知道几种方法（算法），它们各有什么优缺点。

欢迎在评论区分享你的思考，也欢迎把这节课分享给更多对高并发架构设计感兴趣的朋友，我们共同进步。
<div><strong>精选留言（15）</strong></div><ul>
<li><span>👽</span> 👍（17） 💬（2）<p>hash和分段

hash，根据key的hash值定位目标所在地址。hash值1结尾的key在node1，2结尾的在node2等。
数据分布比较平均，但是不方便扩容。因为扩容的话，就要重新编辑hash到node的映射逻辑。

分段，每个node值存储一个范围内的数据。id 100万到101万，在node1，101-102万在node2。
方便扩容，但是数据热点分布可能不均匀。
比如现在分配到node11了id值是111万，数据增加1万增加一个node就好。不需要重新处理映射逻辑。 但问题是，数据热点可能不均匀。比如101-110万都是老用户，现在已经不活跃了。热点用户都在最新的1万个用户。带来的结果就是，处理前10万个用户的node饿死了，而最新的node11可能都已经撑死了。

还是要根据实际业务来决定方案。

另外，以上数据只是随便列一下，实际node存储的数据量肯定远超这个数据量。不要太较真。</p>2022-02-21</li><br/><li><span>国大霞</span> 👍（8） 💬（1）<p>一致性Hash算法 + 虚拟节点
还有Redis集群用的哈希槽的方式</p>2022-04-03</li><br/><li><span>潘政宇</span> 👍（8） 💬（7）<p>由于数据库的性能瓶颈，会不会造成消息队列的消费速度远低于生产速度，导致消息队列崩溃？</p>2022-02-18</li><br/><li><span>Mark C. Mu</span> 👍（5） 💬（2）<p>首先，我想到的是通过计算key的hash值并取余来找到缓存集群的位置，这个办法简单粗暴，但带来的问题就是当缓存集群进行扩缩容的时候需要将缓存中的所有数据的key重新计算hash值并根据结果迁移数据，这带来了很高的迁移成本。
Redis集群应该是使用一致性哈希算法，将服务器和缓存key全放在一个哈希环上，缓存保存在顺时针找到的最近的服务器上，当扩容时只会损失一台服务器中大约一半的缓存数据，扩展性好很多，哈希不均匀也可以通过虚拟节点的方式得到很大程度的解决。</p>2022-02-19</li><br/><li><span>peter</span> 👍（2） 💬（1）<p>请教老师几个问题：
Q1：Nginx可以认为是一个负载均衡服务器吗？
Nginx一般的用途是“反向代理服务器”，但它也有负载均衡功能，那么，Nginx也可以认为是一个负载均衡服务器吗？
Q2：消息队列可以用在请求和应用服务器之间吗？
文中消息队列是用在应用服务器和数据库之间，但是，如果请求过多，应用服务器也会处理不过来。请问：消息队列可以用在请求和应用服务器之间吗？比如请求先到外部网关Nginx，那么，Nginx和应用服务器之间，如果请求太多，会引入消息队列吗？
Q3：Mysql是分布式数据库吗？
Q4：微服务网关中怎么会有微服务客户端呢？
A 在“分布式微服务”章节中，微服务网关中有“微服务客户端”。现在流行的SpringCloud体系中，微服务网关是Spring Gateway。Spring Gateway是个独立的组件，它的内部怎么会有各个具体微服务的客户端呢？
B “并将处理结果构造成最后的响应结果返回给用户”，响应结果会是在微服务网关内完成的吗？应该是微服务构造响应，然后微服务网关转发吧。
Q5：微服务架构中不一定是RPC吧。
SpringCloud是用Rest API，不是用RPC吧。</p>2022-02-19</li><br/><li><span>Eric</span> 👍（1） 💬（1）<p>用多个消息队列消费者去消费队列里面的信息时候保存至数据库时，该如何保证消息先后顺序</p>2022-03-13</li><br/><li><span>叔辉 Shuhey</span> 👍（1） 💬（2）<p>一般用什么消息队列来接api数据？我想先保存 。其它程序慢慢来获取，然后保存到数据库。 可能有少部分高峰api数据情况</p>2022-02-18</li><br/><li><span>Broce</span> 👍（0） 💬（1）<p>期待后面的精彩课程</p>2022-02-21</li><br/><li><span>Alex</span> 👍（3） 💬（0）<p>期待后面精彩的课程</p>2022-02-18</li><br/><li><span>黄小咸</span> 👍（2） 💬（0）<p>key 的分片算法：常用两种，range或hash</p>2022-03-28</li><br/><li><span>LRG-</span> 👍（2） 💬（0）<p>我只想到用hash，或者分段</p>2022-02-18</li><br/><li><span>Geek_892aa5</span> 👍（1） 💬（0）<p>希望可以开一篇详细分析 xx流量下 使用 xx机器x台 xx中间件 的系统架构选择</p>2022-08-16</li><br/><li><span>再见理想</span> 👍（1） 💬（0）<p>渐进式演化的应对高并发系统
1.服务器垂直伸缩，提升单机的硬件性能以提高单机处理效率。
2.服务器水平伸缩，通过负载均衡技术将请求分散到多台服务器处理，使用keepalive+nginx
3.使用分布式缓存做数据库的前置缓存，提示系统读性能，同时防止高并发读对数据库引发的宕机风险。redis 
4.使用消息队列减轻写操作对数据库的风险，服务解耦，削峰填谷。
5.服务拆分，应用程序按业务区分为多个领域，领域之间高内聚低耦合。服务之间通过接口或rpc调用。
6.数据库分库分表。</p>2022-04-17</li><br/><li><span>_#</span> 👍（1） 💬（1）<p>比较常见的应该是hash吧，还可以从key上去表达最终指向哪里吧，也可以做一个映射吧我猜</p>2022-02-18</li><br/><li><span>小杨</span> 👍（0） 💬（0）<p>cluster集群是在客户端对key % 16384得到槽，在通话槽和节点映射找到对应的节点。
codis客户端直接与代理服务器连接，代理服务器对key%1024得到槽，在找到对应的节点。</p>2022-10-08</li><br/>
</ul>