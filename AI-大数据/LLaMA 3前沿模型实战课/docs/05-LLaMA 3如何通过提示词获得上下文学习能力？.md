你好，我是Tyler。

在前几节课中，我们探讨了如何使大模型具备指令跟随能力和思维链能力，这些都是提示词工程的重要技巧。今天，我们将深入研究提示词工程的源头——上下文学习。

## 上下文学习能力是什么？

上下文学习能力是指模型通过理解和利用上下文信息来提高生成内容的准确性和相关性。简单来说，**上下文学习通过设计提示词，引导模型生成更准确和相关的输出。**例如，当我们希望自然语言生成模型撰写关于气候变化的文章时，可以使用提示词：“撰写一篇详细的关于气候变化的分析文章。”这个提示词帮助模型理解具体需求，进而生成与气候变化相关的内容。

在问答系统中，如果有人问“什么是深度学习？”我们可以提供更详细的提示词：“请解释深度学习的基本概念及其应用领域。”这样，模型能够更好地理解问题，提供更加全面和准确的回答。通过优化提示词的设计，可以提升上下文学习的效果，从而显著提高模型的表现和输出质量。

### 上下文学习与迁移学习

上下文学习实际上是一种迁移学习方法，其目标是将一个领域的知识迁移到另一个领域。在迁移学习中，源域是指模型最初训练的领域，而目标域是模型在实际应用中遇到的新领域。

举个例子，假设一个语言模型在医疗领域（源域）和一些通用语料上训练过，我们希望将其应用于法律领域（目标域）。如果我们使用提示词：“请用医疗领域的专业知识解释这个法律术语”，即使模型主要是在医疗领域训练的，提示词也能帮助它将医疗知识迁移到法律术语的解释上，这就是迁移学习的核心思想。

### 少样本学习

少样本学习（Few-shot Learning）在上下文学习中解决了多任务学习和模型微调的一些难题。传统的多任务学习通常需要很多特定任务的数据，才能让模型学会不同任务间的知识转移。但是，少样本学习只需要少量示例数据，就能让模型快速适应多个任务，完全不需要大规模的微调。

以LLaMA 3为例，当你给它几个示例句子时，它能很好地理解并生成合适的回复，而不需要为每个任务单独调整。这不仅节省了大量的训练资源，还让模型在处理不同任务时更灵活。

少样本提示词主要包括两个重要部分。

1. **通过指令确认任务**：明确任务要求是成功实现少样本学习的关键。在上下文学习中，指令（prompts）就像是给模型发的任务说明，帮助它理解目标，从而生成想要的结果。例如，如果你想让模型生成文章摘要，可以给它一个指令：“请总结下面的文章内容”。同样地，在文本分类任务中，像“请判断下面评论的情感倾向，并将其分为‘积极’或‘消极’”的指令可以帮助模型更准确地完成任务。通过这种方式确认任务，模型能在少样本学习中表现得更好。
2. **通过示例代替微调**：少样本学习还通过具体示例来替代传统的微调过程。传统微调需要很多标注数据和计算资源来调整模型的参数，而少样本学习只需要提供几个示例。例如，如果想让模型生成医疗领域的技术文档，可以给它几个示例片段，而不需要全盘微调。模型通过这些示例学会生成类似的内容，这样不仅大大减少了对训练数据和计算资源的需求，还提升了应用效率。在客户服务的聊天机器人中，提供几个对话示例也能让模型快速学会处理用户提问，而不需要复杂的训练过程。

以下代码展示了如何使用 LLaMA 3 模型进行少样本学习。

```python
import ollama

# 定义少样本提示词
few_shot_prompt = (
    "以下是关于电影评论的示例：\n"
    "输入：这部电影真是太棒了！\n"
    "输出：积极\n"
    "输入：我觉得这部电影很无聊。\n"
    "输出：消极\n"
    "请根据下面的评论判断其情感倾向：\n"
    "输入：我对这部电影感到失望。"
)

# 使用 Ollama 模型 'llama3' 进行对话
response = ollama.chat(model='llama3:text', messages=[
    {
        'role': 'user',
        'content': few_shot_prompt,
    },
])

# 输出模型生成的响应
print("模型生成的响应：", response['message']['content'])
```

大语言模型是如何获得上下文学习能力的呢？这要追溯到GPT-2。在其训练过程中，大量的多任务训练数据是通过示例和指令组织的：每个任务都有一个任务指令以及一组示例数据，以帮助模型理解如何完成特定的任务。这种提示词形式的成功经验被延续到后续的大语言模型中，例如ChatGPT和Llama系列等模型都继承了这一方法。因此，在提示词设计中，**明确区分“指令”和“示例”是最基础且最重要的工作。**

### 零样本学习

经历了大规模预训练之后，指令微调（Instruction Tuning）成为了提升模型能力的重要手段。这一步骤的目标是让模型更好地理解和执行人类的具体指令。比如，LLaMA 3通过指令微调，能够不断提高在处理人类提问时的表现。在这个过程中，训练数据中加入了很多“零样本学习样本”，这些样本只包含指令，没有任何示例。

为了让模型能够和没有任何背景知识的用户顺畅对话，训练数据中的指令也变得更像人类的说话方式。像“帮我写一封感谢信”或者“解释一下量子力学的基本概念”这样的指令变得更加自然。通过这种精细调整，即使没有具体的示例，LLaMA 3依然可以在给出指令的基础上，生成连贯的文本或准确回答问题。

以下是使用 LLaMA 3 模型进行零样本学习的代码示例：

```python
import ollama

# 定义零样本学习的提示词
zero_shot_prompt = "请解释量子力学的基本概念。"

# 使用 Ollama 模型 'llama3' 进行对话
response = ollama.chat(model='llama3', messages=[
    {
        'role': 'user',
        'content': zero_shot_prompt,
    },
])

# 输出模型生成的响应
print("生成的输出：", response['message']['content'])
```

这种进步使得模型能根据用户的自然表达生成更符合期望的内容，提高了对特定指令的响应准确性，从而在与人类对话时表现得更加流畅。

不过，值得注意的是，准备这些微调数据的成本非常高，需要标注人员进行大量的标注，涉及到很高的人力成本。而且，零样本学习还有一个局限性，就是模型的训练时效性。因为模型的预训练是一次性的，它无法处理训练结束后发生的新事件。为了解决这个问题，通常需要用到迁移学习的方法来补充学习。在这种情况下，少样本学习依然是一种高性价比的迁移学习方法。

许多人是在体验ChatGPT发布后（2022年末）开始接触大语言模型的，可能会把上下文学习和零样本学习搞混，认为只需对大语言模型下达指令就能完成各种任务。但实际上，**真正的上下文学习是隐藏在零样本学习背后的少样本学习**。这一点常常被刚入门NLP领域的学习者所忽视。

## LLaMA 3的上下文学习能力

在LLaMA 3的技术报告中，强调了该模型在上下文学习能力方面的训练过程。LLaMA 3采用了SFT（Supervised Fine-Tuning，监督微调）、PPO（Proximal Policy Optimization，近端策略优化）和DPO（Differentiable Prompt Optimization，可微分提示优化）的组合方法进行后训练（Post-training）。Meta团队在这一过程中精心筛选提示词、示例和任务指令，最终有效提升了LLaMA 3的上下文学习能力。尤其是针对多轮对话、开放式问答和对复杂指令的理解，LLaMA 3展现了更强的适应能力。

Meta的研究发现，模型有时能够生成正确答案，但却不知道如何选择最佳答案。通过引入PPO和DPO，LLaMA 3的选择能力得到了显著提高。这种提升使得模型在推理和编码任务中的表现更加出色。

在上下文学习的框架下，LLaMA 3的训练过程进一步强化了模型的指令跟随能力和思维链能力。SFT为模型提供了监督学习的基础，使其能够在特定任务上进行精细调整，而PPO和DPO则通过优化策略，提升了模型在实际应用中对提示词的理解与反应能力。

这种综合训练方法使得LLaMA 3不仅在广泛的领域中具备良好的知识迁移能力，还能在面对复杂任务时，迅速选择出最佳的答案，显著提升了其在实际应用中的可靠性和准确性。这一进步为大规模语言模型在多个行业中的应用奠定了坚实的基础。

### 提示语工程的本质是什么？

提示语工程的本质是上下文学习，目的是激活预训练模型的迁移学习能力。因此，提示语工程的核心目标是提高上下文学习的效率，使预训练模型能够根据提示语的指示，在特定的语境或背景下进行学习和推理。

通过前面的学习，我们了解到上下文学习强调利用提示语中的指令和示例来帮助模型在多任务场景下进行高效的学习和推理。结合指令和示例的提示语能够帮助模型更准确地理解任务需求，并在执行过程中参考示范案例。所以，当我们提到提示语工程时，我们关注的也是两个方面，分别是模型如何根据指令执行任务，以及如何利用少量的上下文示例来增强模型的学习能力，也就是我们所说的指令学习和示例学习。

- 指令学习：指令学习为模型提供了明确的任务框架，帮助它在不同任务之间高效切换。为了成功完成这些任务，模型通常需要进行多步推理。
- 示例学习：相较于指令，示例作为提示语的一部分，提供了模型可以参考的具体案例，使其能够在没有额外微调的情况下，也能够很好地完成任务。

针对指令学习的优化，主要集中在复杂任务的规划和推理，是多轮对话的核心内容，在此不做展开讨论。这里我们将重点放在示例学习，这种方法也被称为“知识注入”，即通过将实例中蕴含的知识直接注入到提示语中，使模型可以在任务执行过程中直接参考这些知识。这样，模型无需经过复杂的微调过程，也能够获得相应的能力提升，有效地补充了传统的模型微调方法。

## 总结

作为第一章总结性的一课，我为你梳理了提示语工程能力的来源。提示语工程的核心在于通过上下文学习来激发预训练模型的迁移学习能力。我们深入探讨了少样本学习和零样本学习在提示语工程中的重要性，以及它们如何通过指令和示例来帮助模型更高效地理解和执行任务。

在少样本学习中，我们了解了如何通过提供少量的示例来增强模型的适应性，而无需进行全面的微调。这种方法不仅节省了时间和资源，还提高了模型在面对不同任务时的灵活性。而在零样本学习中，我们探讨了通过指令微调，使模型能够更好地理解和响应用户的自然语言指令，从而在对话和任务执行中表现出色。

总结来说，提示语工程不仅仅是设计提示词，它的本质是通过巧妙的指令和示例引导模型，实现高效的上下文学习和知识迁移。掌握了这些技巧后，我们可以更好地利用大语言模型的能力，在各种任务中取得更好的效果。

## 思考题

1. 在什么情况下，你会选择使用零样本学习而不是少样本学习？请解释原因。
2. 如何在实际应用中平衡提示语的简洁性和信息量，以达到最佳效果？

欢迎你把思考后的结果分享到留言区，也欢迎你把这节课分享给需要的朋友，我们下节课再见！
<div><strong>精选留言（2）</strong></div><ul>
<li><span>小虎子11🐯</span> 👍（0） 💬（0）<p>课程代码地址：https:&#47;&#47;github.com&#47;tylerelyt&#47;LLaMa-in-Action</p>2024-11-25</li><br/><li><span>🌞</span> 👍（1） 💬（1）<p>应该是源域吧</p>2024-10-25</li><br/>
</ul>