你好，我是独行。

前面我们讲了这么多，真正要落地的时候，肯定是需要平台来支撑的，不论是传统小模型还是大模型，需要一个工程化的技术平台来支持才能方便使用，就拿前面讲的RAG举例，知识库肯定要管理的，向量数据库维护也需要界面等等，不可能全部交给开发人员调接口处理，所以我们要设计一个统一的技术平台来做这个事情，而这个平台是下沉到业务下面的，可以是通用的与业务无关的，支撑企业AI转型的平台，所以我们管它叫做AI中台。

在AI大模型爆发之前，很多大厂已经有比较成熟的小模型开发平台了，比如百度基于飞桨的EasyDL平台、阿里云的PAI平台等等。大模型火爆之后，各个大厂又推出了专门针对大模型的开发平台，比如百度的BML、阿里云的百炼以及灵积等，当然也少不了专门做大语言模型开源技术平台的dify，以及我们前面学习过的LangChain。

对于一部分企业完全可以使用各个云计算大厂的AI平台服务，无需自己开发，按需使用付费，又快又省钱，但是对于那些对数据安全有较高要求的企业，只能要么选择私有化部署这些平台，要么完全自己开发。

私有化部署的主要问题是企业无法按照自己的需求定制开发，当然，你如果能持续支付大笔费用，完全定制也是OK的，所以，很多企业就会选择自己开发，这样灵活度最高。这节课我会向你介绍企业如何自主搭建AI中台，以及过程中有哪些需要考虑的事项。

## 技术架构

根据实际落地情况，我整理了一个AI中台的技术架构图，除了最底层的开发框架和运维管理外，上层实际上表示的是一个模型完整的训练和使用过程。我认为大模型和小模型其实是可以放在一起看的，各个大厂把二者分开的原因，我猜测是小模型诞生得比较早，相关平台已经成熟，所以没有必要为了兼容大模型而再去更改原有逻辑，如果我们完全重头设计，那么完全可以把二者放一起考虑。

![图片](https://static001.geekbang.org/resource/image/40/dc/40cd3ef3189d1e7ea0f6868d5d249bdc.jpg?wh=2218x1323)

接下来我分别向你介绍一下每个模块，主要讲讲这里面的一些关键点，有些内容其实行业里已经使用很久了，并不是新东西，我挑重点介绍。

## 数据管理

在数据管理模块，目前比较重要的几个点是数据收集、少样本标注以及数据标注。

### 数据收集

在训练计算机视觉，也就是传统CV小模型时，数据收集面临的主要问题包括数据质量、数据多样性和数据量。首先，高质量的数据对于训练有效的模型至关重要，低质量的数据，如模糊、不清晰图像，可能会导致模型性能下降。其次，训练数据需要涵盖目标任务的所有可能场景和变体，缺乏多样性的数据可能导致模型在实际应用中表现不佳。最后，尽管是小模型，仍然需要足够的数据量来有效地训练和验证模型，一般至少3000～5000张，因此，收集足够的数据也会耗费大量时间和资源。

在实际操作中，几千张照片虽然看似数据量不算大，但是要收集这么多高质量照片，很多时候还是有一定的难度的，我们之前在某次收集过程中，因为所需图片量较大，超过10000张，所以当时动员了很多人，找客户收集相关的图片，甚至还为此设计了一套奖励方案，比如每张图片5块钱等。

对于这个问题，其实有一个办法是有效的可行的，那就是在产品里设计一个图片收集入口，让客户主动将图片上传上来，这样经过一段时间的积累，样本就丰富起来了，不仅仅数量大，而且覆盖不同客户，场景也多，唯一要做的就是怎么设计产品能让客户自愿上传图片，以及保障图片的质量，产品方面有的是办法，至于图片质量可以采用审核的方式，也可以通过脚本去判断。那有没有更好的办法呢？你可以试试少样本训练。

### 少样本训练

少样本训练，也叫做Few-Shot Learning。首先，我们可以想办法增加训练数据，假设原始训练数据只有几张或者几十张，通过一些方法，自动生成成千上万张训练图片。比较初级的方法就是人工制定规则，包括对图片样本进行旋转、翻转、裁剪、增加噪音等操作，但这类方法不足以有效提升模型的泛化能力，规则的制定也依赖领域知识，通常难以做到在多个数据集之间通用。除此之外，我们也可以通过生成对抗网络（GAN），生成逼真的样本数据。

其次，我们还可以优化模型，比如缩小模型需要搜索的空间，这属于元学习的一种，不过这种方法会有一定的复杂度，我们在实际操作过程中，往往还是想办法增加训练数据，元学习这种方式用得比较少，感兴趣的话，你可以去研究一下。

当数据收集的问题解决后，接下来就是数据标注了。

### 数据标注

数据标注也是一个很耗时的操作过程，传统标准就是人工操作，一张一张图片挨个标注，说白了就是在我们关注的地方画个框，或者使用特定的格式如XML，来描述图片信息，包含标注框坐标等等。一旦涉及人工操作，那就自然会产生人力消耗，如果在数据量比较大的情况下，这部分工作也很消耗资源，目前行业里就有很多专门做数据标注的公司，说白了就是人力外包，和外包写代码外包算考勤一个道理。

目前**这个领域人们关注的重点是，可否进行智能标注，也就是通过脚本去自动识别目标对象的位置，进行框选**，虽然有一定的效果，但是我发现很多人依然使用人工进行标注，可能还是准确度的问题，毕竟模型本身训练就存在准确度的问题，再在训练素材标注准确性上打个折扣，那么最终的性能可能会受更大的影响。

## 训练管理

模型训练，思路上比较简单，就是把训练数据喂给模型，设置好训练参数，比如轮数、批次等，观察每轮的损失，然后对checkpoint进行验证，观察效果。

1. 集成工具，小模型相对而言更简单一些，大模型复杂的地方在于，其训练任务比较多，最基础的是预训练，需要的训练数据比较多，也比较耗时，除此之外，还有指令微调、SFT等，这就需要我们内置不同的微调工具，既然是AI中台，那就要尽可能适配各种模型，各种微调方式。
2. 准备充足的机器资源，在训练数据量很大的情况下，除了训练，其他也有很耗时间的操作，比如分词，数据存储等等。如果该平台要满足同时能进行多个任务的需求，那么机器配置也要跟得上，内存、CPU、硬盘以及显卡都要能满足需求才行。
3. 分布式训练，如果你机器充足，且模型参数规模较大的话，比如超过1B，那么你可以考虑使用分布式训练，来提高训练效率，可以参考我们前面 [19｜深入理解DeepSpeed，提高大模型训练效率](https://shimo.im/docs/g3WGMxi5278PCRKW)。
4. 可视化操作，这一点至关重要，作为平台，使用体验很关键。如果能将数据集的指定、网络结构代码的上传、网络结构框架的选择、模型权重的保存、训练日志观测等全部通过可视化训练任务进行串联，那么体验一定会很好。  
   当模型训练完，就要进行模型的管理了。

## 模型管理

同样，我挑选几条重点讲讲。

### 模型仓库

第一部分需要考虑的就是模型的存储问题，也就是模型仓库，如果是企业内部使用的模型，一般来说不可能直接放到公开的模型仓库，比如Hugging Face和国内的魔搭，那就要考虑是否自己搭建一个企业内部的模型仓库，类似于代码仓库gitlab。这一块可简单可复杂，简单来看就是一个文件管理系统，复杂的可以参考Hugging Face，你可以根据需求自己选择方案。

### 模型优化

你听没听说过，以前有人把机器学习工程师叫做“调参工程师”，就是说，机器学习就是不断调整参数来取得最佳效果的过程，当然，这个步骤在模型训练过程中，也一直在做。当模型某次训练完成（达标）后，我们后续依然可以进行迭代优化。

### Agent管理

把Agent放在这一块稍微有点牵强，但是如果要实现和大模型的结合，那这一步必不可少，作为一个新一代AI中台，Agent一定是重要的一环。Agent管理是个长期的过程，因为适用范围广，绝大部分操作都可以抽象出来交给Agent去实现。对我们而言，有挑战的点在于能否设计一个通用的逻辑，比如HTTP调用，能否实现不写代码就能实现80%以上的接口对接，对于大部分Agent场景，如果80%以上都能通过配置实现，那就非常了不起了。

## 模型服务

我们自己训练好的模型，之前的课程已经讲解过如何暴露API提供服务，你可以参考 [07｜大模型API封装：自建大模型如何对外服务](https://time.geekbang.org/column/article/783310)。对于第三方的服务，比如大厂的模型API调用，我们需要考虑两点：一是计费，这个很容易理解，不论出于什么考虑，调用三方付费API，起码要把成本考虑进来，所以平台要提供这种能力，可以统计出来每个调用者对不同API的调用量以及花费金额。二是三方API调用速率的控制，比如各种维度（按分钟/按秒/按调用者/按API等）的限速以及必要时能够阻断调用，防止出现恶意调用等等。

## 应用服务

应用服务层，是整个平台对外服务的入口。应用提供服务的基本资源，包含API调用所需的AppKey、AppSecret等，同时针对不同调用方进行API流控、权限的划分也都是通过应用来实现。此外这一层还需要提供服务编排能力，可以把数据集、模型训练、模型管理以及API等一系列服务串联起来，通过可视化的、拖拽式的交互方式，实现服务的编排能力。

其他细分模块我就不进行一一讲解。构建完的AI中台既可以企业内部使用，也可以SaaS化部署，提供公有云服务，当然如果客户有这方面的需求，当做产品卖给客户进行私有化部署也是没问题的。

## 小结

这节课我向你讲解了企业构建AI中台需要注意的事项，整体看这一块实现起来还是比较复杂的，有些更加深入的逻辑没有讲，比如分布式训练的稳定性如何保障等，之所以没有讲是因为很有可能你用不到，一旦上升到这个规模，那需要注意的事情就非常多了，一节课也讲不完。这节课我们的重点还是讲解AI中台的构建思路及包含的核心模块，学完这节课的内容，相信你会对AI中台形成基本的认识，如果有实操的机会，你可以参照着这节课的内容进行实践。

另外关于平台工程化相关的内容，比如平台本身的可用性保障、部署问题、监控及报警等等，相信你已经比较熟悉了，这里就不再讲解，如果有疑问，你可以在评论区留言讨论。

## 思考题

有一个细节你可以思考一下，假设你们公司已经采购了100台服务器，包含显卡资源，然后让你来构建AI中台，你将如何将训练任务和相关机器绑定？可以把你的思路简单写一下放到评论区，我们一起讨论，如果你觉得这节课的内容对你有帮助的话，也欢迎你分享给需要的朋友，我们下节课再见！
<div><strong>精选留言（6）</strong></div><ul>
<li><span>风轻扬</span> 👍（2） 💬（1）<p>课后题，训练任务和机器绑定。发布任务到机器时。是不是可以根据任务做一个hash，hash到指定机器，但是这样做，机器数量不能变化。还可以采用一致性hash算法</p>2024-10-25</li><br/><li><span>石云升</span> 👍（1） 💬（1）<p>难的内容终于学完咯。接下来更多是把学到的知识实践使用了。</p>2024-09-08</li><br/><li><span>兵戈</span> 👍（1） 💬（1）<p>独行老师讲的很好，受益良多！</p>2024-07-24</li><br/><li><span>Geek_00728a</span> 👍（0） 💬（1）<p>终于学完了，说实话收获很大，和公司里面的一些基建也建立起了联系，谢谢老师</p>2024-08-31</li><br/><li><span>大宽</span> 👍（0） 💬（1）<p>老师，每种大模型对外暴露的接口定义是不一样的吗，也就是我们需要针对不同的模型分别做适配，然后封装成统一的 api，这样下游应用就不会感受到每种模型的不同了 对不？huggingface 的 transformer 库会统一进行封装吗</p>2024-07-27</li><br/><li><span>金龟</span> 👍（0） 💬（0）<p>不绑定，算力池概念，不用超就行</p>2024-12-21</li><br/>
</ul>