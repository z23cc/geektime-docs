你好，我是Tyler。

从今天开始的两节课，我们不但会回顾总结前面学到的内容，还会带你完成人工智能服务系统的实际架构。

你可能在想，我们[第5节课](https://time.geekbang.org/column/article/688311)学习策略建模的时候，不是已经给 AIRC 系统建模了吗。当时还分成了召回、排序、控制博弈和风控这几个模块，为什么还要再提系统构建呢？

这是一个很好的问题，其实第5节课我们更侧重学习业务建模方法，而学完了特征工程、模型工程和数据算法之后，我会带你从零开始，从真实应用的角度来构建一个AIRC的离线和在线系统。这个架构既可以满足搜索、广告、推荐这类经典内容分发场景的需求，也同样能兼容内容生成系统，也就是AIGC的需要。

这节课我们先来学习离线系统。离线系统是你的后勤总管，决定了你在线服务的上限。你能想象到的几乎所有对数据和算法的调优，都是在离线系统中完成的，所以**离线系统是构建AI系统的第一颗扣子**。

## 模型工程

设计一个离线系统的第一步，就是理清我们系统的数据流走向。下面我将带你一步步梳理模型训练的数据链路。

### 全量模型训练

![](https://static001.geekbang.org/resource/image/75/51/75e3bayy7569b1c0c729ab7fa2808351.jpg?wh=3900x1831 "全量模型训练流程")

首先是模型训练的数据流程。

因为业务应用（如APP，网站，客户端等）是用户行为和数据最丰富的地方，所以AI系统通常会在用户发生某些行为时，将日志上报到服务端，获取足够多的数据，供给模型训练使用。

因此，你首先需要一个类似 Flume 的在线的日志服务来实时接收日志。这里需要注意的是，如果在数据收集时数据被篡改，将会导致AI系统学习到错误的知识。所以工业级的AI系统会通过日志加密的方式，降低日志被篡改的风险。

不过，现在的黑灰产流量，大部分来自类似手机墙的真实设备操作，所以即使加密，我们也不能假设所有的日志反馈都是安全的，必须进行后续的反作弊处理。

正如第5节课学习的那样，根据时效性的区别，反作弊处理可以分成在线和离线两部分。

在线反作弊通常会基于某些特征制定规则，例如某个设备上两次用户动作间隔小于100毫秒——这是典型的非人类操作特征，就会被判定为作弊流量。

而离线反作弊则使用更加复杂的模型，通过寻找与作弊者行为模式相似的设备，来发现更多的作弊流量，并将其从训练数据中剔除。比如我们在之前学习到的 lookalike 算法就可以用在这里。

经过反作弊处理后，你将获得相对真实的用户反馈，随后，我们就可以开始用它制备模型训练所要使用的样本了。

#### 样本生成

样本制备过程一般分为两步。第一步是数据拼接，第二步是特征投影。

先看第一步数据拼接，拼接的过程因模型而异，例如CTR模型需要将内容曝光和内容点击的日志拼接起来，生成是否点击的预测样本；而向量召回算法则需要基于用户、物品以及它们之间的交互数据进行建图，供给后续的算法生成空间投影模型。

在完成了数据拼接之后，第二步则是针对模型的特点来进行特征投影，我们可以选择[第6节课](https://time.geekbang.org/column/article/689434)学到的特征处理方法。

#### 模型发布

在完成了样本制作之后，你可以继续应用我们[第7节课](https://time.geekbang.org/column/article/689859)中学到的模型制备方法，使用样本数据开始进行模型训练。这里可以使用常见的模型训练框架，如PyTorch和TensorFlow来训练得到模型文件。

在得到模型文件之后，则要完成模型的离线验证，这也是模型上线前的最后一步。我们通常会选择最近N天的真实样本数据来评估模型的各项指标（N的大小取决于模型的重要程度），判断是否达到准入门槛。如果达到要求，则进行上线。

最终上线时，我们只需要更换并重新加载模型服务，比如 TensorFlow Serving 中用到的在线模型文件即可。

### 增量模型训练

刚刚我们学习了全量模型的训练方法，不过全量模型训练只是一个开始，为了追求极致的性能，AI系统通常还会进行在线增量的模型训练，它的原理和AI大模型的微调大同小异，流程图如下所示。  
![](https://static001.geekbang.org/resource/image/d8/9c/d8299536085d171f089a0094d6991c9c.jpg?wh=3900x1097 "增量模型训练流程")

在线模型的增量训练，通常需要考虑数据的时效性和算力的限制，会对样本进行多级分类，通过“三级火箭”的方式发布上线。

第一级火箭使用全量（例如过去一年）的样本，进行前面提到的完整模型的训练流程。由于这个过程需要大量数据，训练的算力开销特别大，因此我们应该尽量减少全量模型的训练频率，例如一周训练一次就可以了，这也是许多大公司的惯例。

第二级火箭是模型的短期增量训练，使用第一级训练出的模型和最近一天的样本数据，训练一个最新的二级模型。二级模型通常每天训练一次，来更新前一天的二级模型，当然如果刚好赶上一级模型更新，则可以停更一天，这是为了确保每天的增量都得到更新。

第三级火箭指的是，把在二级模型部署到线上后，24小时内产生的增量数据，实时地喂给在线模型进行训练和更新，来确保在线模型的实效性。不过，因为**在线增量训练中缺少离线反作弊的参与，所以不能用增量训练替代全量训练，需要另外两级火箭做安全性和实时性的平衡。**

同时，第三级火箭需要与在线模型指标监控系统配合。一旦关键指标出现大幅波动，就需要回滚模型，并降级到非增量训练模式，在排除问题的根因并确认无误后再重新开启三级火箭。

至此，我们已经完成了在线模型制备的全部流程。你可以看看下面的图，这种全量加增量的方式你需要尽快熟悉，因为几乎所有涉及实时数据需求的AI系统都会经常使用这种方法。

![](https://static001.geekbang.org/resource/image/01/7e/01ddd3738e4799fab203602633020b7e.jpg?wh=3900x2194 "全量&增量 模型训练全流程")

## 存储索引

在学完了模型工程后，我们再来看看另一项十分重要的内容——数据相关的工作。数据是我们业务的基础，没有数据，后面的工作都无从展开。接下来，我们来学习数据存储和索引过程里一些重要的知识。

这里所用到的技术，远远比 Langchain 所使用的向量引擎要强得多，是 AIGC 提示语工程的重要组成部分。

### 倒排索引服务

![](https://static001.geekbang.org/resource/image/1e/c3/1ee0b3d85725e599a5e6b4d002075fc3.jpg?wh=3900x995)

不同的业务场景往往会使用不同的内容数据来源，例如搜索引擎的数据来自爬虫，短视频应用的数据来自UP主，广告系统的数据则来自广告主。

由于内容数据很宝贵，是你产品业务的主要载体，也是 AIRC 和 AIGC 中的那个最重要的 C。所以AI系统通常将内容数据，存储在诸如MySQL这类，可用性较高的数据库中进行持久存储。

完成持久化存储以后，我们就可以根据业务查询性能的需要，建立在线的全量倒排索引了。这个过程也很直观，只需要将数据库中的内容数据全量导出，把一些属性（例如商品的分类、颜色和仓库城市位置等属性）作为倒排索引的查询键，建立倒排索引即可。

目前开源组件中，综合表现最好的在线倒排索引服务就是我们经常用到的ElasticSearch，它的构建逻辑我们[第4节课](https://time.geekbang.org/column/article/686563)学过（如下图所示），你可以再看看后面的图片加深理解。

![](https://static001.geekbang.org/resource/image/ce/ca/ce591dae4d12c742b0a5b0caf5db86ca.jpg?wh=3900x2194 "倒排索引原理")

在索引构建过程中，增量索引是一个技术难点。通常需要通过对诸如MySQL的增量二进制日志进行繁琐地解析和处理才能完成。此外，还需要进行一些额外的工作来确保数据的一致性和服务的可用性。

幸运的是，一些开源工具已经帮助我们解决了这个问题，例如阿里巴巴开源的canal可以很好地完成这一任务。

![](https://static001.geekbang.org/resource/image/46/fa/46a8d8fff51b132568692da19b60d1fa.jpg?wh=4000x2156 "增量倒排索引构建工具")

### 向量索引服务

![](https://static001.geekbang.org/resource/image/9f/c4/9fb8eab1d0a0806ba20d9429d7cc9fc4.jpg?wh=4000x1048)

完成了基础内容索引的构建后，让我们回想一下基于规则的数据召回存在的一些问题。之前我们学到了，基于规则的方式很可能会误杀大量的候选内容。因此，目前最先进的方法是基于语义相关性的向量召回（embedding based retrieval）。

在这里，你可以运用前几节课学到的知识，将用户和物品进行联合建模，得到高维投影函数，然后将用户和物品投影到高维空间，获得它们在高维空间的坐标，也就是Embedding。

![](https://static001.geekbang.org/resource/image/1c/14/1c5b0cd739b86edce02db9c3a62bf114.jpg?wh=4000x2250 "基于向量的召回流程")

为了满足在线服务的效率要求，我们通常会预先计算物品和已知用户的向量，并将它们存储在向量引擎中。这样，当用户发起请求时，只需读取用户的向量，并通过向量引擎找到与用户最接近的物品即可。

这里也给你留一道思考题，之前Langchain所使用的文档片段Embedding和这里的 Embedding区别是什么？哪个效果更好，为什么？

现在我们已经拥有了先进的数据召回系统。理论上，你只需要从用户向量召回的物品中随机选择前十名进行推荐，就能够获得很好的效果。下图展示了按照这种思路构建的一整套存储索引系统。

![](https://static001.geekbang.org/resource/image/bd/1f/bd2cda8f47c9cf899yy33fc97efe651f.jpg?wh=4000x2250 "向量索引构建流程")

除了刚刚提到的一些数据存储和索引之外，从下图中你还可以看到其他重要的内容。

![](https://static001.geekbang.org/resource/image/06/37/06959673a58aedc653b503c3a78f2337.jpg?wh=3900x2194)

例如在线特征的制备流程。这些特征包括[上节课](https://time.geekbang.org/column/article/690464)中提到的关键场景特征，例如“某用户在24小时内的点击数”、“某物品从零点到现在的曝光总数”（你不妨猜猜这个特征会用在哪里）等实时特征。这类数据通常存储在像Redis这样的内存键值存储中。

此外，图中还显示了知识图谱的生成过程。一般而言，知识图谱会存储在类似neo4j的图数据库中，以便更好地表达图谱中丰富的关系。当然在线的图谱还是会配合一些 Embedding 和内存图数据库，来提高查询的效率。

图中的深色部分都是非常重要的数据和索引，在下一节课要讲在线AIRC系统，还有后续的在线AIGC系统中都会经常使用。

现在回顾一下我们的战果：我们已经成功准备了数据、索引和模型。实际上，现在你已经可以利用这些离线素材构建一个相当不错的内容推荐引擎了。

通过使用前两节课学到的图神经网络，即可对用户和物品进行高维映射，并将它们存入向量引擎中。只要投影模型质量良好，当收到客户端请求时，你完全可以使用用户向量来召回空间距离相近的物品，然后从中选择其中之一返回，以获得良好的推荐效果。

你可以参考后面的示意图，来理解这个过程。

![](https://static001.geekbang.org/resource/image/09/88/0920253fbdfdb16ae86ffbaa1ac18188.jpg?wh=4000x1580)

## 小结

今天的内容告一段落，我们来做个总结。

在今天的课程中，我们学习了存储索引（Memory&amp;Index）和模型工程，这是AI大模型中的关键的前置知识，对于提示语工程和大模型训练非常重要。

我们首先了解了在线AI系统中的模型是如何被制备和推送到线上服务的。在这个过程中，我们需要重点关注所收集日志的清洗，还有如何通过全量和增量模型训练，在保证实时性的前提下，控制训练成本。

随后，我带你梳理了AI系统中关键数据的收集、存储和索引的整个流程，为接下来的在线内容推荐引擎和提示语工程的学习做了充分的准备。建议你多花点时间仔细查看后面这张表格，其中对比了AI大模型系统中各个组件与这一章我们所学内容的关系。

![](https://static001.geekbang.org/resource/image/7b/90/7ba034f0f979acbd7864a3fc0ef99f90.jpg?wh=3900x1927 "架构基础篇内容与后续内容的对照关系表")

如果没有模型工程，后面的生成式AI大模型服务将无从谈起。如果没有存储索引，你的模型将成为一个刚愎自用的学者，不去了解外来的最新信息。如果没有风控服务，你的模型将变成一本正经胡说八道的江湖骗子。

在后面的课程中，我会一步一步地带你完成各项内容的学习。下节课中，我会带你了解左边的全部内容，敬请期待！

## 思考题

在线增量模型的训练为什么要用三级火箭，直接用增量模型不可以吗？

恭喜你完成我们第 9 次打卡学习，期待你在留言区和我交流互动。也欢迎你把这节课分享给身边朋友，和 TA 一起学习进步。
<div><strong>精选留言（8）</strong></div><ul>
<li><span>林清扬</span> 👍（4） 💬（3）<p>直接使用增量模型可能会在实效性上有所提升，但存在3个潜在问题。
1. 增量模型可能因为缺少全量数据的综合训练而容易受到噪声影响，导致模型性能下降。
2. 增量模型可能无法涵盖全量数据的多样性，特别是新出现的情况，影响模型的泛化能力。
3. 缺少全量数据的参与可能使得模型无法进行全面的反做弊训练，降低模型的鲁棒性。</p>2023-08-30</li><br/><li><span>一只豆</span> 👍（3） 💬（1）<p>课程日益深入，再次感谢老师～试着回答一下
langchain 中使用的文档片段 Embedding 和 将用户和物品在高维空间的坐标的 Embedding 相比，有很大差别：后者使用真实的业务数据而且嵌入在一整套存储索引系统中，这远远不是文档这种载体能够媲美的。本质来说，是原型系统设计和工业级系统设计的差别吧。</p>2023-08-31</li><br/><li><span>顾琪瑶</span> 👍（3） 💬（1）<p>唯一能想到的是时效性的问题，假如是时效性的话延迟一天真的会这么重要吗？
有个问题想问下投影模型具体是怎么做的，是否有其他的文章详解呢？比如物品和客户具体是怎么关联起来的等等</p>2023-08-30</li><br/><li><span>baron</span> 👍（2） 💬（1）<p>推荐系统的三要素是用户、产品、场景； 对用户与产品的embedding其实就是将用户与产品之间的关系在高维空间的表征；而文本的embedding则没有这种三要素的逻辑，是单要素逻辑，是通过模型通过学习大量文本数据种词与词之间的序列关系，而生成的词与词的高维空间表征； 这样的表征应该比用户产品这样的关系数据要更稀疏，维度更高；必然GPT的embedding向量维度到底12288维。 </p>2023-09-02</li><br/><li><span>InfoQ_6792a017d8d3</span> 👍（1） 💬（1）<p>看到这里已经忍不住分享给朋友，要是23年看了这个课程，23年H2牵头的一个AI应用重要项目，可能效果会好很多
</p>2024-02-28</li><br/><li><span>peter</span> 👍（1） 💬（1）<p>是否有安卓手机上可以使用的chatGPT？</p>2023-08-31</li><br/><li><span>周晓英</span> 👍（3） 💬（0）<p>补充说明：
模型遗忘问题:

在连续的增量训练中，模型可能会遗忘早期学到的知识，尤其是如果新的数据与旧的数据有很大差异时。全量训练可以保证模型能够维持对整个数据分布的理解。
模型评估和验证的困难:

增量训练可能会使模型评估和验证变得更为困难，因为不同时间点的模型可能会有不同的性能表现。全量训练可以为模型提供一个稳定的评估和验证环境。
超参数优化的困难:

在增量训练的过程中，由于数据分布可能会发生变化，原有的超参数可能不再适用，而对超参数的调整和优化变得困难。全量训练提供了一个相对稳定的环境，有助于超参数的选择和优化。</p>2023-10-02</li><br/><li><span>Seachal</span> 👍（0） 💬（0）<p>课程讲了AI离线系统构建，重点在模型工程和存储索引。模型工程那块，说了全量模型训练怎么从日志收集到发布，还有增量模型的流程，强调了在线模型的实效安全。存储索引呢，就是倒排索引服务很重要，ElasticSearch能建在线全量倒排索引，还讲了在线特征制备和知识图谱生成。</p>2024-11-23</li><br/>
</ul>