你好，我是Tyler。

在上节课中我们学习了特征工程相关的知识，你对这部分内容掌握得如何呢？

今天我们开始学习模型工程。你是否还记得，我在开篇词中说过，AI系统是一个极其复杂的系统，我们需要自顶向下地学习，而不要一开始就陷入技术细节，要先明确各个算法的定位和作用。

在这节课里，我也会为你介绍现在人工智能在学术上的三大学派，它们分别是符号主义学派、连接主义学派和行为主义学派，其中的代表分别是知识图谱、深度学习和强化学习。

目前，以深度学习模型为代表的连接主义派表现出色。然而，在许多情况下，AI系统仍然需要结合其他两个学派的算法，才能发挥最大的功效。所以我们要学习各个学派的算法，博采众长，才能形成对AI系统模型工程的全面认识。

## 监督学习（Supervised Learning）

先来看监督学习，它意味着在正确答案的指导下进行学习，这和你在考试前通过习题和答案来对照学习是一样的。

为了让机器和你一样，也能学习问答之间的关系，我们需要使用函数 Y = F(X) 来表示它们之间的映射关系。

- X是问题的描述，比如“世界上最高的山是哪座山？”
- Y是问题的答案，即“珠穆朗玛峰”。

所以只要你得到 Y = F(X) 的具体表达式，就能够算出所有问题的答案。

接下来，问题就变成了——你该如何获得函数 F 的表达式。其实这个过程和你在学校时求解多元方程没有太大区别，就是根据已知条件，得到未知数的解析解。

只不过在真实世界中，你无法获取全部的已知条件，甚至不知道方程的具体形式，几乎无法获得解析解。因此，你只能使用统计的方式，来拟合X和Y之间的关系，得到函数 F 的近似解 F’。

拟合的过程分为两步。首先建立模型，选择一个适合的 F’ 的表达式（比如 F(X) = AX + B）来对你的场景建模。然后，我们需要将已知数据作为条件，来求解参数 F’ 中的未知参数（也就是 A 和 B）。

### 点击率模型（CTR）

为了让你更好地理解这个过程，我们沿用之前点击率预测的例子。预测用户“是否点击”是一个经典的监督学习问题。其中的 X 包括用户年龄和商品价格等各类特征，标签Y则表示 “是否点击”，一般用 0 来代表未点击，1 代表点击。

现在，你已经清楚数据的情况了，如果需要你设计一个模型来预测点击率，你会怎么做呢？你可以先自己暂停思考一下。

接下来我们就揭晓答案。其实很简单，刚才已经教给你了。第一件事是建立数学模型，也就是设计方程，第二件事是求解方程未知数。

但是由于你之前没有做过类似的任务，所以可能不知道该选什么样的方程。其实很简单，你甚至可以直接用刚才例子中的 Y = AX + B。X 就是你的特征，A 和 B 是你的未知参数，Y 则是是否点击的标签。

当然了，真实的工业场景中，会选择更复杂一些的函数表达式，因为这类表达式的拟合能力更强，可以更好地刻画复杂数据的分布，这里我为你选择了Google的Wide&amp;Deep模型，这是点击率预测的经典模型。你可以看到，在论文中，它的数学表达式是后面这样。

![](https://static001.geekbang.org/resource/image/94/bc/94595748ee426eb0d8404325ae4904bc.png?wh=1982x210)

第一眼看到这个表达式，你可能会有点懵。这里和你分享一个经验，那就是拿到一个模型之后，不要死磕公式，而是先理解它的设计思路。

论文中提到，该模型由宽度和深度两部分组成。宽度部分用于处理与“是否点击”有直接联系的特征，原理与传统的逻辑回归相同。深度部分则可以更好地利用那些看似与标签无关，但组合起来会很有用的特征，是一个多层的神经网络（MLP）。本质上，它是将宽度和深度两个模型融合成了一个模型，来发挥各自的优势。

理解了这个背景之后，就算你不懂前面的公式，也可以搭建好这个模型了。你只需要按照下面的图示来“搭乐高”就好了，这个乐高的“示意图说明书”和对应搭好的代码如下所示。

![](https://static001.geekbang.org/resource/image/d9/db/d99fc7bced653572e7b6f7464e2219db.jpg?wh=3900x1959 " Wide & Deep 模型示意图")

接下来，你只需要按照前面的图示来“搭乐高”，也就是按照前面的模型图构建你的模型，不需要理前面复杂的函数表达式。

建模示意代码如下。

```python
import torch.nn as nn
class WideAndDeepModel(nn.Module):
    def __init__(self, wide_features, deep_features):
        super(WideAndDeepModel, self).__init__()
        self.wide = nn.Linear(len(wide_features), 128) # 宽度分支
        self.deep = nn.Sequential( # 深度分支
            nn.Linear(len(deep_features), 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU()
        )
        self.output_layer = nn.Linear(128 + 128, 1) # 输出层
```

现在你已经用搭乐高的方式，建立好了上面那个复杂的方程。下一步只需要求解方程的参数就好了。

具体求解前，你需要先理解“损失函数”是什么。简言之，损失函数 L 是模型给出的“预测”和标准“答案”之间的差距，损失越小则说明模型效果越好。所以“解方程”的过程就是要“试”出损失最小的“解”。

所以你需要用你的数据（X，Y）和你的近似解 W 带入损失函数，去试 W 是不是最优的解。

![](https://static001.geekbang.org/resource/image/8d/72/8d7e157061d88f90051cec9396e61372.png?wh=1550x192)

比如你可以用简单直接的损失函数（比如均方误差），求出各个样本预测误差平方的平均值即可。

$$L(\\hat{y},y)=\\frac{1}{n}\\sum{(y\_i-\\hat{y}\_i)^2}$$

当然，在真实工业场景中我们会使用更复杂的损失函数，比如交叉熵，它可以对预测值和真实值之间的分布做相似性的预估。

$$L(\\hat{y},y)=y\_ilog(\\hat{y}\_i)+(1-y\_i)log(1-\\hat{y}\_i)$$

看到这里，你会说，我悟了！只要将所有可能的“解” W 都带入损失函数试一遍，然后记录下让损失函数最小的“解”不就好了？

非常好，能提出这个方法说明你已经理解了。这个方法没有错，但是“都试一遍”这件事不太可能做到，因为参数的个数是海量的，而且参数是连续的，而不是离散的，所以没法“都试一遍”。

所以你还是需要一个策略来提高“试”的效率，比如使用梯度下降法，它是一种**投石问路、步步逼近**的策略。

用梯度下降来求解的整个过程是这样的。

首先，我们从需要拟合的已知数据中取一小批数据（X，Y），并将它们带入损失函数。然后，随机给损失函数赋予一个解 W。接下来，计算梯度，梯度会指向这批数据上将损失函数减小的最小解的方向。之后，沿着这个方向迈出一步，也就是调整你的模型参数 W。最后，我们再取一批数据，基于更新后的解重复这个过程，直到用完所有已知数据。

最终，你将得到一个针对你的已知数据拟合后的点击率模型。这个模型可以用来预测未知数据的点击率。

你是不是觉得模型训练没什么神秘的了？你所要做的工作只是定义方程和解方程而已。你可以对照下面的示意图和代码再好好理解一下。

![](https://static001.geekbang.org/resource/image/ef/cb/efc86b93cbba0a54997dc9a9a0b1cdcb.jpg?wh=1867x1050 "梯度下降示意图")

```python
# Training loop
model.train()
num_epochs = 10
for epoch in range(num_epochs):
    for batch_data, batch_labels in train_loader:
        optimizer.zero_grad() # 初始化清零梯度
        outputs = model(batch_data) # 取一撮数据，用模型算输出
        loss = criterion(outputs, batch_labels.unsqueeze(1)) # 损失落差
        loss.backward() # 算梯度 (目标方向)
        optimizer.step() # 走一步，更新模型
```

## 对比学习（Contrastive Learning）

接下来，我们进入对比学习的部分。区别于监督学习，对比学习只需要得到样本之间的“相似度”就能完成训练，之前我们学习的 Word2Vec 就是对比学习的一个典型例子。

这里再举个推荐系统的例子，推荐系统的本质是寻找用户和物品之间的关系。所以如果你能得到用户和物品之间的“相关性”，就可以直接用它们之间的“距离”，实现第5节课中提到的数据召回。

具体的过程是这样，你可以用图结构来表示用户和物品的关系，构建它们之间的关系图，**用户和物品是图的节点，它们之间的交互行为是图的边，边的权重则是它们交互行为的频率**。

那么，如何得到它们之间的距离呢？其实你可以用 Word2Vec 来实现，因为它能找到词与词之间的距离，自然也能用来找“人”与“物”之间的关系，只不过你需要一个办法把节点之间的图结构转化成 Word2Vec 中的序列结构。

这其实也是 DeepWalk 算法的核心思想，我们来看看具体的建模过程。

首先随机选择一个初始节点，根据与它相连边的权重分配概率，进行节点之间的随机跳转，也就是所谓的随机游走。随机游走的过程中会生成许多路径，这个路径则是你想要的序列。得到序列后，自然可以使用 Word2Vec 建模，唯一不同的是对象由单词变成了用户和商品。

通过这样的处理，你就能得到用户和物品的空间投影（Embedding）并计算它们的空间距离。

![](https://static001.geekbang.org/resource/image/d8/4b/d8feb94c1b499c08357c28081459f74b.jpg?wh=1867x1050)

你可能注意到了，刚才我们通过将复杂问题分解为多个简单问题，快速得到了解决方案。这种方法在各类算法中经常会用到，比如计算机视觉中的目标检测就用了类似的方法。

但一般而言，这往往只是一种权宜之计，最终还是会发展成端到端的模型，因为分阶段的方法通常会导致信息的丢失。所以，下节课我还会带你学习一种端到端的图神经网络算法——GraphSAGE。

这里你先重点理解对比学习的思想，因为这是大语言模型技术的核心方法。

## 强化学习（Reinforcement learning）

我们都知道，人工智能有三个主要派别，它们分别是行为主义派、连接主义派和符号主义派。

接下来，我来带你学习一下行为主义派，也就是控制论学派的学习框架。如下图所示，该学派采用了一种基于“感知 + 行动”的行为方法。

![](https://static001.geekbang.org/resource/image/6d/e3/6d89684da29f56e12f7633c45022c1e3.jpg?wh=3900x1735)

早期常见的思路是运用控制论中的经典算法，比如 PID 控制器，该控制器由比例、积分和微分这三个部分构成。

- 比例部分反映了偏差与目标之间的比例关系，能在偏差产生时立即提供反馈，实现有效的控制。
- 积分部分表示偏差随时间的累积情况，主要用于消除静态误差，例如在误差积累较长时间时，逐渐增加修正幅度。
- 微分部分则捕捉偏差信号的变化趋势，特别用于快速扩大偏差时，可以及时抑制其进一步放大的趋势。

如下图所示，只要对上述三个模块的输出加权求和，即可得到系统的综合偏差。这个综合偏差可以用来控制系统的校正力度。

![](https://static001.geekbang.org/resource/image/e3/90/e32c075547f8cd2df686cab4ae931490.jpg?wh=3900x1940)

这个算法很擅长解决控制动作存在延迟响应场景的问题。最初是用在通过调节空调风量来控制室温，通过控制方向盘来保持车道这样的场景。

后来该算法广泛应用在AI系统中的控流场景，这里我们以短视频应用为例。

短视频的AI系统，通常会限制每个视频在24小时内的流量，以避免某些视频过度占据流量，挤压中小创作者的发展空间。因此，当某个视频的曝光量达到一定值后，就会被限制流量。

不过，短视频 AI 系统还有一个目标——让各种使用习惯的人都能接触到优质内容。所以，平台还需要确保内容在一天中各时刻的流量均匀分布。这样就能避免在某个时段，比如下午使用产品的用户看不到优质内容。在这种场景下，就很适合使用 PID 控制器来控制流量。

![](https://static001.geekbang.org/resource/image/6a/71/6a1193bf4292bab08303bee7ee648d71.jpg?wh=1867x1050)

具体来说，当收到流量请求的时候，我们要先算出实际曝光量和预期曝光量的差距值，把这个差距值和之前几个时刻的差距一起传给 PID 控制器，并将计算出输出值作为对当前视频的调控反馈。

如果输出值越高，那该视频在这次请求中，被限制的概率就越大。通过这个机制可以动态地调整当前视频的曝光量，因为这完美地利用了 PID 控制器的特点——**“风浪越大，控流越强烈”。**

翻译一下就是真实流量和预期流量间的误差越大，误差增长越快，误差积累时间越长，AI 系统就会越强力地限制流量。这样即使面对突然出现的流量洪峰，也能做到动态控制。

当然，PID 算法也存在一些局限性，比如调整加权参数通常需要高昂的实验成本，尤其是在在线商业系统中。因此，目前各大厂正在逐渐切换到强化学习的方案上来。

强化学习不依赖于预先标记的数据，而是通过与环境的交互来进行自主学习，根据奖励信号的反馈进行实时的策略更新，同样是行为主义派的经典方法。

这里你只需要先对强化学习的控制反馈能力和它所属的学派，建立一个直观的了解。后面课程里我再和你详细探讨这项技术，敬请期待！

![](https://static001.geekbang.org/resource/image/d5/c1/d5306a565d1d87f524d69d0f829b62c1.jpg?wh=3900x2194)

## 小结

好了，学到这里，我帮你总结一下今天学到的内容。

你不仅掌握了AI内容推荐系统中各类算法的核心原理，还理解了监督学习、对比学习和强化学习这些AI大模型中最关键的核心技术。你可以通过课后思考题看出它们之间的联系。下面我们再回顾一下这几个概念。

1.监督学习是在正确答案的指导下进行学习。这和你在考试前通过习题和答案来对照学习是一样的。  
2.对比学习的目标是通过样本之间的相似度，来学习它们之间的距离，进而表示它们的关系。  
3.强化学习的核心思想，是利用感知和行动的闭环进行学习。

这节课我们学习了人工智能的三个主要派别分别是什么，目前你已经掌握了两个派别的方法，下节课我会教你符号主义学派的工具。还有一些重要的观点，我将它留作课后思考，相信经过这节课的学习，你一定能想出答案。我们下节课见！

## 思考题

为了更好地巩固今天所学的内容，请你尝试回答后面的问题。

请你设计一个对话系统，让它在行为学派的学习框架下，自动优化自己的对话能力，给出大致流程即可。

恭喜你完成我们第 7 次打卡学习，期待你在留言区和我交流互动。也欢迎你把这节课分享给身边朋友，和 TA 一起学习进步。
<div><strong>精选留言（14）</strong></div><ul>
<li><span>Lucky+</span> 👍（5） 💬（1）<p>1. 定义奖励函数：在行为学派的学习框架中，奖励函数是关键。我们可以根据对话的质量，如用户满意度、对话的连贯性和适当性等来定义奖励函数。
2. 收集对话数据：系统需要收集大量的对话数据，以便学习如何进行有效的对话。这些数据可以来自于过去的对话记录，也可以通过模拟对话来生成。
3. 训练模型：使用强化学习算法（如Q-learning、Deep Q-Networks等）训练模型。模型的输入是对话的当前状态，输出是每个可能的响应的预期奖励。
4. 策略优化：根据模型的预测结果，选择预期奖励最高的响应作为系统的回复。然后根据用户的反馈（如评分、点击等）更新奖励函数，进一步优化模型的策略。
5. 持续迭代：不断重复上述过程，系统会逐渐学习如何进行更有效的对话。
6. 模型更新：定期使用最新的对话数据更新模型，以保持其对话能力的最新性。
7. 评估和调整：定期评估系统的性能，如通过用户满意度调查、对话质量评估等。根据评估结果调整奖励函数和学习策略。</p>2023-09-04</li><br/><li><span>极客雷</span> 👍（4） 💬（1）<p>作者推荐背景过于强大，以至于带入过多</p>2023-12-11</li><br/><li><span>peter</span> 👍（3） 💬（1）<p>老师今天的课非常好，基本听明白了，感谢！
顺便一个小问题：本课所讲的监督学习和对比学习都是属于连接主义学派吗？</p>2023-08-26</li><br/><li><span>顾琪瑶</span> 👍（2） 💬（1）<p>等一手优质留言, 想不出来.</p>2023-08-25</li><br/><li><span>jfdghb</span> 👍（1） 💬（1）<p>老师，请问课程里讲的每一个算法都要学透么</p>2024-01-16</li><br/><li><span>Geek_798202</span> 👍（1） 💬（1）<p>理论真的好多，越学习越感觉自己的无知，想问一下，这种情况该怎么办？</p>2023-09-27</li><br/><li><span>阿甘</span> 👍（0） 💬（1）<p>三种学习方式：监督学习、对比学习、强化学习。那么无监督学习又是什么呢？跟对比学习是什么关系啊？</p>2025-02-14</li><br/><li><span>摩崖堂主</span> 👍（0） 💬（1）<p>收货很大，感谢作者</p>2023-09-09</li><br/><li><span>Lee</span> 👍（0） 💬（1）<p>老师，咱们有学习交流群吗？</p>2023-08-29</li><br/><li><span>糖糖丸</span> 👍（0） 💬（1）<p>诶，文中给出的交叉熵损失函数，怎么纯粹是y和y^的函数，是不是少了i下标？</p>2023-08-26</li><br/><li><span>周晓英</span> 👍（1） 💬（1）<p>对话系统构建流程：
1. 需求分析和目标设定:
定义系统的学习目标：例如，提高用户满意度、减少对话中的错误率、提高对话效率等。
确定评价指标：例如，用户满意度评分、错误率、对话长度、对话完成率等。
2. 数据收集和预处理:
收集大量的对话数据，包括人机对话和人人对话数据。
对数据进行预处理，例如，分词、实体识别、去噪等。
3. 基线模型设计:
设计一个基线对话模型，例如，基于序列到序列（Seq2Seq）模型。
使用收集的数据对基线模型进行训练，获得一个初步的对话系统。
4. 强化学习框架设计:
在行为学派的框架下，设计强化学习环境，其中，状态可以是对话历史，动作可以是回复的生成，奖励可以是基于评价指标的得分。
设计一个适用于对话场景的奖励函数，以引导系统优化对话能力。
5. 在线学习和优化:
通过与用户的实时交互，收集在线对话数据和用户反馈。
实现在线学习算法，例如，使用深度Q学习（DQL）或者优势行动者评论家（A2C）算法，不断更新模型的参数，以优化对话能力。
6. 评估和调优:
定期离线评估模型的性能，通过AB测试等方法，比较不同模型或算法的效果。
根据评估结果，调整模型结构、奖励函数、学习算法等，以进一步提升系统的对话能力。
7. 持续迭代和优化:
持续收集新的数据，更新模型，以应对新的对话场景和用户需求。
迭代优化模型结构、学习算法、奖励函数等，以实现持续的自我优化。</p>2023-10-02</li><br/><li><span>Seachal</span> 👍（0） 💬（0）<p>学了这一课，对监督、对比和强化学习有了点新认识。监督学习，就像考试前做习题对答案，得有个正确答案指引着。对比学习呢，是看样本间像不像，学它们之间的距离，明白它们啥关系。强化学习，则是边感知边行动，闭环里学东西。

讲点击率模型时，从监督学习开始，说到用函数找问题和答案的对应，再到点击率预测，一步步建模型、解方程。损失函数、梯度下降法，这些求解参数的手段也都提到了。

还有对比学习和强化学习，简单介绍了下，对比学习看相似度，强化学习重闭环。这些内容对理解模型工程挺有帮助。</p>2024-11-23</li><br/><li><span>Clying Deng</span> 👍（0） 💬（0）<p>概念不懂可以观看这个视频：https:&#47;&#47;www.bilibili.com&#47;video&#47;BV1AP4y1r7Pz&#47;?spm_id_from=333.337.search-card.all.click&amp;vd_source=6cf494dceeeccc03815dd6aba32372cb 更详细</p>2024-10-26</li><br/><li><span>InfoQ_6792a017d8d3</span> 👍（0） 💬（0）<p>看大家的留言就能学到很多
</p>2024-02-28</li><br/>
</ul>