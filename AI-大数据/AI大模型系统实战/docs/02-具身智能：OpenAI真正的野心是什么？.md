你好，我是 Tyler。

说起 ChatGPT，你对它的印象是什么呢？

据我观察，不同人有不同的看法。有些人不太高兴，因为担心它的代码能力会对工程师的工作造成威胁。另一些人的态度是不屑一顾，认为它只会说些不切实际的东西。还有一些人正在学习一些易上手、但欠缺深度的教程，用它建立知识库，自动化日常工作，觉得“小小GPT不过如此”，很容易就能“拿捏”它了。

不过，这一轮技术革命并不是冲着这“仨瓜俩枣”来的，未来所有数字化工作都可能被大模型技术颠覆。所以今天我会带你正本清源，看看这一轮技术革命的真正“终局”是什么样子。

好大的口气，你可能会这么想。的确，在一个技术快速发展的阶段下断言，确实有些“冒险”，但我非常有信心与你分享我的判断，因为这已几乎成为了全球大模型工作者的共识。

![](https://static001.geekbang.org/resource/image/dd/7b/ddd8dd2581f008d04372e590c15fd07b.jpg?wh=3800x2138 "大语言模型驱动的智能体")

如上图所示，我们未来所面临的终局形态，不只是一个能说会道的聊天机器人，而是“具身智能”的通用人工智能。所谓具身智能，就是像人一样能与环境交互感知，自主规划、决策、行动的机器人。

## ChatGPT 的发展简史

像人一样？你可能有点半信半疑，但别以为这是科幻小说虚构的故事。如果你足够细心，完全可以在 OpenAI 的发展过程中发现一些端倪。我现在就带你回顾一下GPT发展的过程当中有哪些重要历史节点，看看它是怎样一步步进化的。

GPT的诞生要归功于NLP的快速发展。从2018年到2021年，是第一代大语言模型（LLM）的“技术爆炸”期。人们逐渐学会了，如何使用海量的无标签数据，来训练这些“涌现”智能的大模型。随后，OpenAI采用强化学习技术，点亮了LLM的智能，ChatGPT由此横空出世。

如果你对前面的故事已经非常熟悉了，那说明你已超过95%侃侃而谈大模型技术的人了。

但实际上，真正的故事才刚刚开始。我画了一张OpenAI产品发展的示意图，你可以猜测一下他们之间的关系，接下来，我将会为你道出其中的逻辑。

![](https://static001.geekbang.org/resource/image/d0/f3/d0f1fc84f15d0c572bdcb84c0ec11bf3.jpg?wh=3800x2138 "OpenAI 产品发展过程")

## 猩球崛起（使用工具）

人类之所以在地球上显得独特，一个重要原因是我们更擅长使用工具。对于已经掌握语言能力的大型语言模型（LLM）来说，学会使用工具只是一个时间问题，而且它们的学习速度比我们想象的还要快。

从OpenAI产品的各种迹象来看，**他们正在教导LLM使用甚至创造工具**。

首先，OpenAI推出了插件和联网功能，弥补了大型语言模型自身记忆的不足。这标志着LLM正式开始学习使用工具。

随后推出的函数功能，意味着LLM已经学会使用API来完成复杂任务，在此之前这可是后端工程师的主要工作。最后推出的代码编辑器，让LLM直接学会制造工具，**这几乎动摇了所有工程师的饭碗**。

虽然人类可以掌控使用工具的大模型，但令人既兴奋又担心的是，研究人员还找到了**让LLM “思考”的方法**。我们这就来看看这人造的思维能力是怎样的！

## 西部世界（自我思考）

在美剧《西部世界》中，机器人乐园的创始人偷偷地为机器人植入了“意识”代码，导致机器人自我对话，从而产生了自我意识。在真实世界中，类似的事情正在发生。各大机构正在制造能够自我对话的“智能体”，从而彻底解放人类的脑力工作。

你可以回想一下，当人类面临一个任务的时候，会怎么做？

首先，我们会思考任务的主要步骤有哪些，然后调取相关的资料，形成可行的方案，接着通过分工去执行具体的事项，最后汇总完成任务。对于智能体来说也是一样，只不过要将之前人类大脑的工作交给大语言模型（LLM）完成。

## 技术要点

在这里，我为你准备了一张智能体的结构图。为了让智能体具备“自治”的能力，一般需要将计划、记忆和工具这三部分组合起来。

![](https://static001.geekbang.org/resource/image/ce/d8/ce92102a8b7a9a0dcb1yy59cdf1636d8.jpg?wh=3800x1884 "大语言模型驱动的智能体")

接下来，我们就沿着这三个部分看看有哪些重点工作，当你把它们背后的逻辑弄清楚之后，后面课程里学习具体细节时，才能做到心中有数。

### 任务规划（Planning）

教大型语言模型（LLM）思考的过程，有点像苏格拉底的“产婆术”。苏格拉底认为，他不能代替别人思考，但他可以通过提问引导别人思考，就好像产婆引导孕妇一样。

这种方法可以让LLM对自己的想法进行调整和反思，最经典的方法是ReAct，他有三个概念：

- **Thought：**表示让大语言模型思考，目前需要做哪些行为，行为的对象是谁，它要采取的行为是不是合理的。
- **Act：**也就是针对目标对象，执行具体的动作，比如调用API这样的动作，然后收集环境反馈的信息。
- **Obs：**它代表把外界观察的反馈信息，同步给大语言模型，协助它做出进一步的分析或者决策。

你可以看看文稿后面的这张截图，图里展示的是ReAct的一个示例，它可以帮你加深理解。

![](https://static001.geekbang.org/resource/image/78/65/7888b2f8e9213e3eb01c47a3ee27f765.jpg?wh=2313x1876 "ReAct 问答示例")

我们可以用这种方法来启发LLM工作，比如让它帮你制定工作方案，并持续向它提问，例如：你的执行步骤有哪些潜在隐患和风险、有哪些方法可以降低风险、能否帮助我制定一些安全风险预案等等问题，以确保它生成的内容安全可靠。

在这个过程中，你要尽量唤醒LLM的相关知识，生成合理的计划，此时**思维链技术（CoT）**就非常重要了，它可以让LLM将任务分解为可解释的步骤。更多关于这些技术的细节，我们将在第三、第四章展开讨论。在此阶段，你只需掌握LLM在任务规划里如何使用即可。

### 记忆唤醒（Memory）

无论是在制定计划、使用工具或执行任务的过程中，LLM 都需要外部信息的帮助来辅助进行思考。为了更好地让 LLM 拥有记忆力，我们不妨先参考一下人类是如何记忆的。

在神经科学研究中，人类的记忆可分为感觉记忆、短期记忆和长期记忆三种类型。

- 感觉记忆，是人体接收到外部信号以后，瞬间保留的视觉、听觉、触觉的记忆片段，在AI系统中类似于高维嵌入表示，也就是我们常说的 “Embedding”。
- 短期记忆，是你**当前意识中的信息**，在LLM中类似于提示词（Prompt）中的所有信息。
- 长期记忆，包含了**你能回忆的所有信息**，在LLM中类似于外部向量存储。

LLM 能“消化”的，只有提示词（Prompt）中的短时记忆，所以你只需要在长期记忆中选择最重要的内容放入提示词，这里我给出一张图方便你理解这个过程。

- 首先，LLM 在得到任务后，会帮助你制定记忆唤醒方案。
- 然后，AI系统执行该方案，生成相关的查询指令，从外部数据中查询数据。
- 最后，我们将这些数据交给 LLM 来判断是否已获得足够完成任务的数据。如果没有，LLM 会生成新的唤醒方案，并循环这个过程。

![](https://static001.geekbang.org/resource/image/51/a1/51a11e38460ba1340fcbb00cdc2af0a1.jpg?wh=3900x1962)

现在，LLM 不但能制定任务规划，还能调取外部知识了。仅这两个能力足以让它自动化地完成很多脑力工作了。如果再让它学会使用工具，那潜力简直不可限量。我们再来聊一聊 LLM 使用工具的方法。

### 驾驭工具（Tools）

**要让 LLM 学会使用工具，首先需要让它认识工具**，比如TALM、Toolformer和Gorilla等方法让LLM 学会理解API的调用注释，这是Plugin和Function等功能的基础。

下图展示了Gorilla教会LLM使用API的全过程。

- 首先，我们使用大量API调用代码和文档作为语料，训练一个可以理解API的大语言模型。
- 然后，AI系统还将对这些API进行向量化操作，将它们存储在向量数据库中作为外部记忆。
- 随后，当用户发起请求时候，AI系统会从外部记忆中，获取跟请求相关的 API 交给 LLM。
- 最后，LLM 组合串联这些 API 形成代码，并执行代码，完成API的调用，生成执行结果。

![](https://static001.geekbang.org/resource/image/78/d1/789802f9d4090a75f92e690b60a05dd1.jpg?wh=3900x2127 "Gorilla 算法核心步骤")

此外，根据Google的[线报](https://medium.com/@daniellefranca96/gpt4-all-details-leaked-48fa20f9a4a)，GPT-4使用了MoE（混合专家模型）技术，由十多个领域专家模型共同提供服务。所以，它需要上层LLM有能力为指定的需求，找到最合适的专家模块，这其实也是一种LLM使用工具的能力。同样，就像前面提到的，OpenAI 发布的 Code Interpreter，也正式宣告 LLM 制作工具的时代已经来临。

## 小结

相信通过今天的学习，你已经知道了这一轮技术革命的目的是什么，而且不仅OpenAI在进行这些工作，国内的各大科技公司也在积极探索。这节课的知识重点，你可以参考后面的导图来回顾。

我们通过“产婆术”让大型语言模型学会“思考”。我们让它学会制定和反思自己的计划，并教会它获取外部知识和使用工具的方法，让它可以独立完成复杂任务。

![](https://static001.geekbang.org/resource/image/3c/49/3cfc2b4c2a55dc1b21f3f5833c401e49.jpg?wh=3800x2138)

而且，LLM除了使用工具之外，已经可以制造工具了。OpenAI推出的Code Interpreter，让 LLM 有能力解决处理几乎各种模态的二进制数据，而不仅限于文字和图像。长远来看，这将颠覆现有软件工程的模式，Serverless 已经不新鲜了，Codeless才是未来的常态。

除此之外，还有很多重要的内容，比如大模型的分布式训练技术、多模态大模型的训练方法，以及实现可信AI，解决大模型幻觉的办法等等。其实这些相关技术，早在既有的AI系统中得到了很好的实践，这些内容也会在后续的课程中逐渐展开，敬请期待。

## 思考题

结合今天的内容，你觉得教会LLM制定计划，反思计划以及使用工具这几个方面，哪方面的训练难度更大？为什么？

恭喜你完成我们第2次打卡学习，期待你在留言区和我交流互动。也欢迎你把这节课分享给身边朋友，和 TA 一起学习进步。
<div><strong>精选留言（13）</strong></div><ul>
<li><span>蚂蚁吹雪</span> 👍（5） 💬（2）<p>《AI简史：从工具到上帝》</p>2023-08-16</li><br/><li><span>neohope</span> 👍（4） 💬（1）<p>大模型已经从“萌宠时代”，正式迈入了蹒跚学步的“婴儿时代”。
这个婴儿虽然短期记性不算好，但学习能力和长期记忆能力却无与伦比，潜力无限。
当大模型可以理解工具，使用工具，甚至制造工具、创造工具时，硅基生物时代也就开始降临了。
期待。</p>2023-08-14</li><br/><li><span>FruitDealer</span> 👍（3） 💬（2）<p>老师，想请教一下向量化存储的技术细节，就是在LLM学习如何使用工具那一小节内容中提到的AI 系统对API 进行向量化操作并存储的时候，存储这些知识的结构是怎样的，是利用专家知识设计一个框架然后不断填入的模式还是自动进行知识抽取存储的呢？如果是后者的话，在这个过程中可能会出现知识体系不断扩展，杂乱无章的问题吧，AI系统是如何控制的呢？感谢老师不吝赐教</p>2023-08-29</li><br/><li><span>寻</span> 👍（2） 💬（1）<p>老师，上节课的留言不是说这节课会回答吗</p>2023-08-23</li><br/><li><span>李小隆_</span> 👍（1） 💬（1）<p>我觉得“反思计划”最难。因为其它两项都是线性的、有步骤可循的，但是反思计划需要发散性、批判性，机器不擅长这些。</p>2024-08-12</li><br/><li><span>MOSS</span> 👍（1） 💬（1）<p>思考题解答：目前是刚开始接触大模型的小白，我觉得在教会 LLM 制定计划，反思计划以及使用工具中肯定是教会LLM指定计划更困难，首先反思计划我们可以通过多次的COT来达到最终效果，工具是有它的使用手册或者说明书的，把说明书塞给模型，模型只要按部就班执行就可以了，相反给LLM指定计划涉及到问题的分解，相当于把大象塞进冰箱分几步一样，我们要的答案可能是打开冰箱-&gt;塞入大象-&gt;关闭冰箱，而大模型收到一定的约束他回给你返回冰箱不能赛大象的答复，这里面涉及到了感性和理性的区别了。</p>2024-01-31</li><br/><li><span>l_j_dota_1111</span> 👍（1） 💬（2）<p>老师你好，在LLM使用api那一节课里，既然所有的api都已经放入向量数据库了，为何还要拿api训练模型呢，直接把向量数据库搜寻的结果和prompt一起传给大模型不就行了吗</p>2023-11-30</li><br/><li><span>一只豆</span> 👍（1） 💬（1）<p>非常感谢老师开设这门课程！！要想做出产品，工业级的LLM系统搭建知识太必要了。 
这堂课里面 用人类的三种记忆来类比 Embedding Prompt 外部向量数据库 也非常捅破窗户纸的感觉。。。哈哈
最后有个小问题，在Gorilla那个图里面，首先是 curation 了 1645 个 API call 在 Dataset 里面，然后后面那一步，是提供了 1645*10 个 指令和 API 的对。所以就是每个 API 都用 10 个指令的例子来教会 LLM。是吗？</p>2023-08-21</li><br/><li><span>周晓英</span> 👍（8） 💬（0）<p>我们可以通过比较人类和大型AI模型在执行这些任务时所面临的挑战来进行分析。

1. 制定计划 (Planning):
人类：
人类能够理解长期和短期目标，并能基于他们的理解和经验来制定计划。
他们能够预见可能的结果并调整计划以适应不同的情况。
大模型：
大模型很难理解或预见长期的结果，它们通常只能在给定的参数和数据范围内制定简单的计划。
它们缺乏对不确定性和复杂性的真正理解，这使得制定有效的计划成为一个挑战。
2. 反思计划 (Reflecting on Plans):
人类：
人类能够反思他们的决策，学习自己的错误，并在未来的计划中应用这些学到的经验。
大模型：
大模型缺乏自我意识和评估能力，它们无法在没有外部输入或额外训练的情况下从错误中学习。
缺乏基于以往经验的自适应能力，不能像人类那样通过反思来改进未来的计划。
3. 使用工具 (Utilizing Tools):
人类：
人类能够理解工具的用途，学习如何使用它们，并在需要时应用它们来解决问题。
大模型：
大模型可以被编程来操作特定的工具，但它们缺乏对工具使用的真正理解和判断。
需要人类编程者为它们创建明确的指令和参数，以使用这些工具。
综合分析：

从上述分析中可以看出，反思计划可能是最困难的任务，因为它需要一种自我意识和评估能力，这是目前大型AI模型所缺乏的。接下来是制定计划，由于大模型缺乏真正的理解和长期预见性，使得计划制定成为挑战。相对来说，使用工具可能是最容易的任务，因为它主要依赖于外部的编程和指令，而不是模型自身的理解和判断。</p>2023-10-02</li><br/><li><span>K</span> 👍（1） 💬（0）<p>反思计划。
分析过程：
1）制定计划方面，存在大量的可参考套路，如把大象放进冰箱，可分为三步，提取模式即可；
2）使用工具方面，场景较为明确，特定的工具解决特定场景的问题，选择场景工具即可；
3）但反思计划，则涉及问题解决的目标是什么，如何调整决策过程以达到目标，难度较大。</p>2024-01-01</li><br/><li><span>Eric</span> 👍（1） 💬（0）<p>老师好，这里有一点小疑问，这里LLM使用API，是LLM生成调用路径，有应用来完成工具调用，还是LLM本身去创造runtime去调用呢?</p>2023-12-25</li><br/><li><span>Seachal</span> 👍（0） 💬（0）<p>ChatGPT，OpenAI的大型语言模型，引领AI未来！
ChatGPT一路成长，从初代大语言模型到强化学习加持，再到插件、联网、函数、代码编辑器一应俱全，真是越来越强了！它不仅能学习使用工具，还通过任务规划、记忆唤醒等技巧，展现了自主决策和具身智能的潜力。这不仅仅是个聊天机器人，它是能与环境互动、自主规划、决策、行动的通用人工智能！ChatGPT的未来，无限可能，期待它带来更多惊喜！</p>2024-11-23</li><br/><li><span>St.Peter</span> 👍（0） 💬（0）<p>具身智能是以大模型为基础吗</p>2024-11-11</li><br/>
</ul>