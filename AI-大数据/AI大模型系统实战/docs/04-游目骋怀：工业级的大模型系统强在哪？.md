你好，我是 Tyler。

在前几节课当中呢，你已经在大模型系统的认知上有了质的提升，弄清楚了以下几个问题。

1. AI大模型系统是什么？
2. 为什么AI大模型系统是新一代应用平台?
3. 在这轮技术革命中，OpenAI 的最终目标是什么？

此外，你还学会了如何利用市面上流行的开源工具，快速构建“原型系统”。但要牢记，不要过于陶醉于“一日千里”的幻觉中，**要明白开源工具只是体验版，并非真正的大模型系统**。

## 常见误区（弱在哪里）

为什么这么说呢？因为开源工具主要用于快速构建原型，而不是为工业级系统设计的。我们这就来梳理一下刚开始学习时最容易产生的误区。

### **误区一：将LangChain和AutoGPT认作真正的LLM系统**

链式调用的 LangChain，虽然学习起来非常方便，但无法经受生产环境真实流量考验，并不是说LangChain 的链式调用方法或者说编程语言 Python 不适合生产环境，它差得可不止这一星半点。

真正工业级的应用需要有离线、近线几套系统配合供给，才能让在线系统效果出众、性能稳定。如果你想深入学习开源项目，提升自己的职业能力，不要浪费时间去研究 LangChain 和 AutoGPT 这类科研原型验证项目的开源代码。

你更应该去学习那些得到商业公司支持、质量更高的开源项目，这对你的职业发展会有直接帮助。因为科技公司们能直接通过开源项目，获得真金白银的收益，所以，他们会不遗余力地发展自己的开源软件。

这里我举几个例子，来帮助你理解这句话，第一个例子是Google，它的研发人员已经成为了 Android 和 Kubernetes 这些项目社区的核心成员，所以他们可以通过技术手段制定商业标准。第二个例子是 Oracle，大多数企业更倾向选择有影响力的开源软件对应的商业版本，来支撑自己的业务。所以，MySQL 可以让 Oracle 的收费数据库卖得更好。

总之，我希望你可以客观地看待“开源”这种技术合作形式，选择合适的学习项目。如果想更进一步，则应将开源当作技术发展的一个途径，而不仅仅将开源作为充满技术情怀的 Hacker 行为。

### **误区二：将Embedding检索奉为记忆增强的“圭臬”**

上节课学到的向量（Embedding）检索技术，虽然外行觉得很新鲜，但一些网上资料有点过于强调它的作用了，其实它只是内容推荐系统中再普通不过的一项技术。

大模型通过提示词中信息的 Embedding 去检索外部记忆片段这种做法并不高明，充其量只是字面匹配的一个变种而已，存在非常明显的缺点。

你无法找到主题最相近的文档，因为在一开始，你就把文档的语义切割了，更何况你所能使用的开源向量检索，根本没办法满足工业级的性能和数据量级要求。

而且即便只选择使用向量检索的方式做外部记忆增强，也会出现外部文档过多、向量索引快速膨胀的问题，这时如果没有工业级人工智能系统的架构做支撑，你的系统将被慢慢拖垮。

### **误区三：无视开源大模型的内容生成质量问题**

各类开源模型，比如ChatGML和Llama是无法直接拿来满足商业需求的。用它们搭建一个小型的自动化工具尚且勉强够用，但如果是在客户需要花费真金白银的商业场景，结果可想而知。

在大模型商业化的过程中，模型的领域定制是免不了的。有些同学可能在一些地方学习了如何简单使用OpenAI的API来微调你的模型，它虽然名字叫微调，不过只是为每个用户做了极其浅层的补丁，严格意义上算不上微调。

真正的领域微调需要基于定制化的模型，使用高性能的训练框架进行大规模分布式训练，结合强化学习和MoE（混合专家模型）。因为在商业系统中，绝对不允许出现差错，对模型性能有严格的要求。

当然，这样的问题不胜枚举，比如前几节课你学到的 ReAct 陷入死循环怎么办？陷入幻觉怎么办？大模型不认得 ReAct 的指令怎么办？WormGPT通过越狱指令利用你的模型入侵系统怎么办？

不过，归根结底，我觉得现在的各种知识传播中会出现这些误区，根本原因是**AI大模型系统还在快速商业化进程中，真正的核心技术还在小圈子内传播。**

## 应对之道（强在哪里）

而我们的课程将带你一探究竟，填补这份空白，应对上文提到的这些问题。随着后面的课程更新，你也会慢慢看见工业级大模型的完整面貌。

### AI大模型系统的理论知识

为了真正理解工业级大模型的强悍之处，我们先得提升自己的见识，具备扎实人工智能理论知识。通俗一点解释，其实模型可以看作一个函数，它模拟了人类智能的运行方式。在模型训练中，你所做的就是解出这个函数中未知变量的值。

接着，我们需要通过特征工程让模型更好地理解训练数据。特征工程的核心是对样本数据的改造，可以将数据映射到更细致的维度，或者映射到更高维度的空间。

一旦你掌握了上述基本概念，就能训练出一个工业级的模型了，之后我会教你人工智能三个主要流派中常用的算法，解释它们的优缺点和适用范围。我还会指导你如何将它们融合运用，以满足工业级AI系统不同场景的需求。

当你深入了解了人工智能算法的原理后，你就能更顺利迈进大模型相关的知识领域了。谈到大模型，首先要谈的就是预训练模型（PTM）。我会让你明白为什么许多大模型技术起源于预训练模型的方法，还会解释为什么预训练模型首先在视觉领域得到广泛应用。

最后，你会了解现代大语言模型的发展历程，及其背后引人注目的历史。这包括几次技术革命，以及Google和OpenAI之间关于技术选型的竞争。

### 如何训练一个大模型

在你掌握了足够的理论基础后，我会和你深入讨论如何在实际工业场景中，通过构建离线数据工程和模型训练系统，使你能够独立地训练模型，并进行在线实时的增量更新。这些步骤是让AI系统变得智能的关键。

接下来，我将从零开始，教你如何进行多机多卡的分布式训练，制造一个真正的大模型。你将了解为何OpenAI每次训练都需要花费上千万美元。

当然，实际应用中，你通常只需要对模型进行微调。我会分享一些技巧，以加速你的模型微调过程。最后，我还会教你如何使用强化学习（RLHF）的方法，来微调你的大模型。我会告诉你适合这种方法的场景，以及这样做的好处是什么。

### 如何构建一个工业级的AI系统

工业级 AI 大模型系统最鲜明的一个特征，就是针对自己的业务场景，基于数据驱动的业务系统框架去定制大模型，而不是使用别人“施舍”的通用大模型。

首先，我们需要学习AI系统的策略建模方法。思路是把业务问题转化为数学问题，然后对这些数学问题进行建模，最终将它们转化为工程问题。在这个过程中，你将学会如何根据不同的场景选择合适的模型算法。

在学习AI内容推荐服务时，你将掌握如何让你的系统轻松地应对在线真实场景，如何通过调整算法来灵活地控制在线指标。这些问题也是在线内容生成（AIGC）系统需要解决的。

如果想让你的系统在商业竞争中处于优势地位，就需要有针对性地设计系统模块，结合在线服务的特性来实现算法。这样，你的系统才可能成为商业竞争中有竞争力的智能体。这不仅关系到在线AI系统的盈利能力，也是让你的LLM应用走向具身智能的重要技能。

对于AIGC系统而言，为了避免过高的推理开销增加商业成本，模型小型化的方法也必不可少，这能大大降低在线推理的开销。

至于前面说的外部记忆问题，我们需要去学习如何构建一个工业级的检索增强系统。这个系统将成为提示引擎的主要外部记忆，也会成为可信AI的重要依据。该系统的数据来源正是AIRC系统中积累的强大知识表示和检索能力。

另外，安全可靠的风控模块也必不可少，这样AI系统才能拥有工业级的鲁棒性，确保你的商业系统能够在各种真实风险中稳定运行。

## 小结

今天的总结比较特别，我想给你分享一份问题清单，你可以把它当成后面内容的“预告”。从第五节课开始，我将带你进一步的学习，进一步提升认知，直到最后具备参与到生产级AIGC大模型系统研发工作中的能力。

希望在后面的课程中，你能带着以下的问题进行学习。为了让你的AI大模型系统掌握足够的理论知识，你需要弄清楚后面这些问题。

![](https://static001.geekbang.org/resource/image/f0/77/f0bb9acda4a7f62c8c47885507c83e77.jpg?wh=3900x2194)

为了搞清楚如何训练一个大模型，你需要在后面的课程中，探寻后面这些问题的答案，其中包括理论和实践两个方面。

![](https://static001.geekbang.org/resource/image/eb/b1/eb92de3990624a6618bdd3556aa50db1.jpg?wh=3900x2194)

如果需要构建一个工业级的AI系统，你需要在后面的课程中探寻以下问题的答案。

![](https://static001.geekbang.org/resource/image/ff/f0/ff673ee372080e8fb045bbaaacd6c3f0.jpg?wh=3900x2194)

到这里，我们热身篇的内容告一段落。为了给你留下足够的时间学习消化讲过的内容，还有动手练习课程里的作业，第五节课会在下周一和你见面。

在等候更新的时间，你可以深入思考一下我们前面提到的问题，这样后面学习的时候，你的理解会更加深刻。

## 思考题

1.你认为 Llama2 和 Qianwen 开源的目的是什么？  
2.学完热身篇的内容，最颠覆你认知的内容是什么？

恭喜你完成我们第 4 次的打卡学习，期待你在留言区和我交流互动。也欢迎你把这节课分享给身边朋友，和 TA 一起学习进步。
<div><strong>精选留言（15）</strong></div><ul>
<li><span>王三</span> 👍（10） 💬（1）<p>最关注本课程的工业化落地方案，目前大模型只是助理（助手），而工业化（客户）往往要求专家水平的应用。里面的gap需要一套大模型工业化方法论补充。</p>2023-08-17</li><br/><li><span>胖胖虎</span> 👍（10） 💬（1）<p>Llama2和qianwen开源的目的，我认为是为了构建生态，抢占未来AIGC生态的制高点。OpenAI的闭源生态对任何有野心的厂商都是不可接受的，这无异于把城堡建在沙子上。Llama和qianwen的开源，一方面有大厂背书，第二解决了各厂商底层担心的事情。可以让各个第三方可以相对放心使用。后续的各个第三方基于其进行发展，会让整个生态逐渐生长在上面，而开源的厂商会逐渐获得生态的主导权。</p>2023-09-03</li><br/><li><span>Juha</span> 👍（9） 💬（5）<p>老师好，就是您的观点是，我们现在基于langchain做一些工具的开发是不太明智的选择嘛～</p>2023-08-20</li><br/><li><span>周晓英</span> 👍（4） 💬（2）<p>最颠覆我认知或者说我最有同感的地方，是大模型领域demo级别的代码调用，和真正的工业化落地方案，中间还有巨大的鸿沟需要跨越。大模型的新闻每天都有非常多，让人眼花缭乱，实际上很多新闻稿都存在宣传因素，上手实验一下发现可能并不完全是那么回事，而即使上手实验能成功，可能还只是老师说的demo级别，和真正的商业应用差距还非常大，因此有一点简单的进展，一定要保持冷静，后边的坑还会很多。</p>2023-10-02</li><br/><li><span>R_R</span> 👍（4） 💬（2）<p>fine tune是最后一条路，精通 prompt 是基本</p>2023-08-16</li><br/><li><span>糖糖丸</span> 👍（3） 💬（1）<p>开源是为了增强技术影响力，让更多从业者follow自己的标准，降低自己的技术成本，也为后续商业化做铺垫</p>2023-08-23</li><br/><li><span>一只豆</span> 👍（1） 💬（3）<p>越来越期待后面的课程了～
请教老师一个 “大模型性能评估”的问题。当我们着手针对垂直领域进行大模型的定制化开发时，我们可能在对比调用GPT4 API 和自家大模型的效果。 那关于性能评估这块，我理解一部分是 之前产品经理要做的 user case 的描述，但因为是个新技术，能力也更强，除了原先写 user case 的内功心法之外，是不是有一些新的框架性思考或者 guideline 之类的东西可以学习？ 
再次感谢老师，把小圈子的知识普惠出来，功德太大了～</p>2023-08-21</li><br/><li><span>peter</span> 👍（1） 💬（3）<p>请教老师几个问题：
Q1：Flowise可以在win10下运行吗？
Q2：专业、复杂软件，比较难学，知识点很多，是否可以做一个针对某个复杂软件的大模型，有问题的话可以问这个大模型。
Q3：模型对CPU、内存、硬盘空间的要求是什么样？我准备换笔记本电脑，用新的笔记本电脑来学习、练习大模型，请问：购买的时候，需要什么样的配置才能满足要求？</p>2023-08-15</li><br/><li><span>John(易筋)</span> 👍（0） 💬（1）<p>请问如何加入老师的微信群，很受启发，谢谢。
真正工业级的应用需要有离线、近线几套系统配合供给，才能让在线系统效果出众、性能稳定。如果你想深入学习开源项目，提升自己的职业能力，不要浪费时间去研究 LangChain 和 AutoGPT 这类科研原型验证项目的开源代码。你更应该去学习那些得到商业公司支持、质量更高的开源项目，这对你的职业发展会有直接帮助。因为科技公司们能直接通过开源项目，获得真金白银的收益，所以，他们会不遗余力地发展自己的开源软件。-- 老师的这两段话醍醐灌顶。</p>2024-05-20</li><br/><li><span>周晓英</span> 👍（0） 💬（2）<p>llama2和千问开源的目的，可能有几个：
一是展示企业的技术实力，确立业界领先地位。
二是通过开源吸引大量开发者，从而可以广泛收集数据和反馈，迭代自己的模型。
三是将开源模型作为试用品，将能力更强的商业模型作为收费产品或收费服务，形成销售漏斗。
当然也可能有开源精神、希望成为行业领袖的因素。</p>2023-10-02</li><br/><li><span>GAC·DU</span> 👍（0） 💬（1）<p>开源是为了更好的商业，老师打破了开源界的砂锅。之前是吃瓜群众，看人家养了个“大胖孩子”，很好很强大，现在自己也要养一个，或许没那么大也没那么胖，但是着手干这件事已经足够颠覆了。🐂🍺</p>2023-08-15</li><br/><li><span>Seachal</span> 👍（0） 💬（0）<p>工业级大模型，挑战与策略并行

本课深入剖析了工业级大模型的优势与挑战。首先，纠正了常见误区，如误解开源工具及忽视内容质量。接着，提出应对策略：强化理论知识，尤其是算法原理；注重离线数据工程和模型训练系统构建；实践大模型训练与微调。此外，还介绍了多机多卡分布式训练及强化学习微调技巧。</p>2024-11-23</li><br/><li><span>St.Peter</span> 👍（0） 💬（0）<p>1. 你认为 Llama2 和 Qianwen 开源的目的是什么？

通过开源的目的，促进行业的生态发展，能够汲取更多开源的智慧，使qianwen自己也进步。

2. 学完热身篇的内容，最颠覆你认知的内容是什么？
颠覆我的认知的是工业级的AI和平时学习的向量以及Langchain大不同。平时论文和书籍里面的只是一些科研的原型，快速验证想法。要多多学习商业化的项目。</p>2024-11-11</li><br/><li><span>账号已注销...</span> 👍（0） 💬（0）<p>课程说的这些业界有案例可以展示下吗？想看看标准的产品展示</p>2024-05-28</li><br/><li><span>周晓英</span> 👍（0） 💬（0）<p>老师好，请教两个问题：
1.Embedding模型以通用知识为主，对私有知识的向量匹配效果不好，如何进行微调或者训练自己的Embdding模型 
 2.问答系统的私有知识库的结构本身已经是QA形式，具体结构和匹配流程，和AskPDF那样的文档知识库，有什么区别吗</p>2023-10-13</li><br/>
</ul>