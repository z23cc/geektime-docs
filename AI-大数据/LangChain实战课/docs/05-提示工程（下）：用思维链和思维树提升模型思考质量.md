你好，我是黄佳，欢迎来到LangChain实战课！

我在[第4课](https://time.geekbang.org/column/article/700699)的结尾时说了，你可以尝试用思维链也就是CoT（Chain of Thought）的概念来引导模型的推理，让模型生成更详实、更完备的文案，今天我们就一起看一看CoT的使用。

## 什么是 Chain of Thought

CoT这个概念来源于学术界，是谷歌大脑的Jason Wei等人于2022年在论文《[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf)（自我一致性提升了语言模型中的思维链推理能力）》中提出来的概念。它提出，如果生成一系列的中间推理步骤，就能够显著提高大型语言模型进行复杂推理的能力。

### Few-Shot CoT

Few-Shot CoT 简单的在提示中提供了一些链式思考示例（Chain-of-Thought Prompting），足够大的语言模型的推理能力就能够被增强。简单说，就是给出一两个示例，然后在示例中写清楚推导的过程。

![](https://static001.geekbang.org/resource/image/f2/a0/f27cec109dff8947d85507b34ce240a0.png?wh=940x473 "图片来源论文")

论文中给出了一个大模型通过思维链做数学题的示例。图左和图右，大模型都读入了OneShot示例，但是图左只给出了答案，而图右则在OneShot示例中给出了解题的具体思路。结果，只给出了答案的模型推理错误，而给出解题思路后，同一个模型生成了正确的答案。

在三种大型语言模型的实验中，CoT在一系列的算术、常识和符号推理任务中都提高了性能。在GSM8K数学问题基准测试中，通过CoT指导后，大模型的表现可以达到当时最先进的准确性。

CoT从概念上非常容易理解，从应用上非常容易操作。虽然简单，但这种思想可以给我们的开发过程带来很多启发。

比如，假设我们正在开发一个AI花店助手，它的任务是帮助用户选择他们想要的花，并生成一个销售列表。在这个过程中，我们可以使用CoT来引导AI的推理过程。

👉 整体指导：你需要跟着下面的步骤一步步的推理。

1. 问题理解：首先，AI需要理解用户的需求。例如，用户可能会说：“今天要参加朋友的生日Party，想送束花祝福她。”我们可以给AI一个提示模板，里面包含示例：“***遇到XX问题，我先看自己有没有相关知识，有的话，就提供答案；没有，就调用工具搜索，有了知识后再试图解决。***”—— 这就是给了AI一个思维链的示例。
2. 信息搜索：接下来，AI需要搜索相关信息。例如，它可能需要查找哪些花最适合生日派对。
3. 决策制定：基于收集到的信息，AI需要制定一个决策。我们可以通过思维链让他详细思考决策的流程，先做什么后做什么。例如，我们可以给它一个示例：“***遇到生日派对送花的情况，我先考虑用户的需求，然后查看鲜花的库存，最后决定推荐一些玫瑰和百合，因为这些花通常适合生日派对。***”—— 那么有了生日派对这个场景做示例，大模型就能把类似的思维流程运用到其它场景。
4. 生成销售列表：最后，AI使用OutputParser生成一个销售列表，包括推荐的花和价格。

在这个过程中，整体上，思维链引导AI从理解问题，到搜索信息，再到制定决策，最后生成销售列表。这种方法不仅使AI的推理过程更加清晰，也使得生成的销售列表更加符合用户的需求。具体到每一个步骤，也可以通过思维链来设计更为详细的提示模板，来引导模型每一步的思考都遵循清晰准确的逻辑。

其实LangChain的核心组件Agent的本质就是进行好的提示工程，并大量地使用预置的FewShot和CoT模板。这个在之后的课程学习中我们会理解得越来越透彻。

### Zero-Shot CoT

下面的这两个CoT提示模板的例子，来自于Google Research和东京大学的论文《[大语言模型是零样本推理者](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)》。

图中的（d）示例非常非常有意思，在Zero-Shot CoT中，你只要简单地告诉模型“**让我们一步步的思考（Let’s think step by step）**”，模型就能够给出更好的答案！

![](https://static001.geekbang.org/resource/image/09/8b/09a48be47b3e0e9ec0ae7ebd483d868b.png?wh=944x508 "图片来源论文")

哈哈哈，这样太神奇了吧，这不由得让我联想起最简单的提示工程，角色设定——模型回答之前，先告诉它“你是一个很有经验的XX专家”，模型应该就会在开始胡说八道之前三思。

简单总结一下：Few-Shot CoT，指的就是在带有示例的提示过程中，加入思考的步骤，从而引导模型给出更好的结果。而Zero-Shot CoT，就是直接告诉模型要一步一步地思考，慢慢地推理。

## Chain of Thought 实战

现在，就让我带着你完成一次Chain of Thought的LangChain应用开发实战。

**项目需求**：在这个示例中，你正在开发一个AI运营助手，我们要展示AI如何根据用户的需求推理和生成答案。然后，AI根据当前的用户请求进行推理，提供了具体的花卉建议并解释了为什么选择这些建议。

在这个过程中，AI需要理解客户的需求之后，按部就班的思考，然后给出最符合逻辑的回答。

### CoT的模板设计

针对这个聊天机器人的需求，我设计了下面这样的思维链模板。

> 作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。  
>    
> 我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。  
>    
> 同时，我也会向客户解释我这样推荐的原因。  
>    
> **示例 1：**  
> 人类：我想找一种象征爱情的花。  
> AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。  
>    
> **示例 2：**  
> 人类：我想要一些独特和奇特的花。  
> AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。

AI的模板开始于对其角色的阐述，并给出了一些先前的对话示例（Few-Shot Learning）来帮助AI理解如何处理这种类型的请求。这些示例展示了AI如何根据思维链进行思考，给出深思熟虑之后的答案。

### 程序的完整框架

程序的完整代码如下：

```plain
# 设置环境变量和API密钥
import os
os.environ["OPENAI_API_KEY"] = '你的OpenAI API Key'

# 创建聊天模型
from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(temperature=0)

# 设定 AI 的角色和目标
role_template = "你是一个为花店电商公司工作的AI助手, 你的目标是帮助客户根据他们的喜好做出明智的决定"

# CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning）
cot_template = """
作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。 

我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。
同时，我也会向客户解释我这样推荐的原因。

示例 1:
  人类：我想找一种象征爱情的花。
  AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。

示例 2:
  人类：我想要一些独特和奇特的花。
  AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。
"""
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
system_prompt_role = SystemMessagePromptTemplate.from_template(role_template)
system_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template)

# 用户的询问
human_template = "{human_input}"
human_prompt = HumanMessagePromptTemplate.from_template(human_template)

# 将以上所有信息结合为一个聊天提示
chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])

prompt = chat_prompt.format_prompt(human_input="我想为我的女朋友购买一些花。她喜欢粉色和紫色。你有什么建议吗?").to_messages()

# 接收用户的询问，返回回答结果
response = llm(prompt)
print(response)
```

程序中，首先设置环境变量OpenAI的API密钥，以便能够使用OpenAI的GPT-4模型。然后创建聊天模型：通过调用 ChatOpenAI 类，创建了一个聊天模型。设置 temperature=0 可以让模型生成更确定性的回答，即输出更倾向于最可能的结果。

接着定义了AI的角色和目标，该AI为花店电商公司的助手，其目标是根据客户的喜好来提供购买建议。紧接着，定义 CoT 模板，其中包括了AI的角色和目标描述、思考链条以及遵循思考链条的一些示例，显示了AI如何理解问题，并给出建议。

之后，我使用了PromptTemplate的from\_template方法，来生成相应的询问模板。其中包括用于指导模型的SystemMessagePromptTemplate和用于传递人类问题的HumanMessagePromptTemplate。

然后，我使用了ChatPromptTemplate.from\_messages方法，整合上述定义的角色，CoT模板和用户询问，生成聊天提示。

最后，将生成的聊天提示输入模型中，获得模型的回答，并打印出来。

在Few-Shot CoT提示的指引之下，模型针对我们的问题，从问题中的具体需求出发，返回了不错的建议。

***现在，根据你的需求：你正在寻找你的女朋友喜欢的粉色和紫色的花。***

***首先，我从理解你的需求出发，只会推荐粉色或紫色，或者两者的组合的花。这些可能包括粉色的玫瑰，紫色的兰花，或者是粉色和紫色的花的混合花束。玫瑰是象征爱情和亲情的经典符号，而兰花象征着美丽和力量。这两种花都蕴含很棒的内涵。当然了，无论你选择哪种花卉，重要的是表达出你对她的爱和关心。记得附上一张温馨的贺卡，写下你的真挚祝福。***

## Tree of Thought

CoT这种思想，为大模型带来了更好的答案，然而，对于需要探索或预判战略的复杂任务来说，传统或简单的提示技巧是不够的。基于CoT的思想，Yao和Long等人几乎在同一时间在论文《[思维之树：使用大型语言模型进行深思熟虑的问题解决](https://arxiv.org/pdf/2305.10601.pdf)》和《[大型语言模型指导的思维之树](https://arxiv.org/pdf/2305.08291.pdf)》中，进一步提出了思维树（Tree of Thoughts，ToT）框架，该框架基于思维链提示进行了总结，引导语言模型探索把思维作为中间步骤来解决通用问题。

ToT是一种解决复杂问题的框架，它在需要多步骤推理的任务中，引导语言模型搜索一棵由连贯的语言序列（解决问题的中间步骤）组成的思维树，而不是简单地生成一个答案。ToT框架的核心思想是：让模型生成和评估其思维的能力，并将其与搜索算法（如广度优先搜索和深度优先搜索）结合起来，进行系统性地探索和验证。

![](https://static001.geekbang.org/resource/image/6e/a0/6eec83ffe1a5f37d245520535d65f8a0.png?wh=1083x550 "图片来源论文")

ToT 框架为每个任务定义具体的思维步骤和每个步骤的候选项数量。例如，要解决一个数学推理任务，先把它分解为3个思维步骤，并为每个步骤提出多个方案，并保留最优的5个候选方案。然后在多条思维路径中搜寻最优的解决方案。

这种方法的优势在于，模型可以通过观察和评估其自身的思维过程，更好地解决问题，而不仅仅是基于输入生成输出。这对于需要深度推理的复杂任务非常有用。此外，通过引入强化学习、集束搜索等技术，可以进一步提高搜索策略的性能，并让模型在解决新问题或面临未知情况时有更好的表现。

下面我们应用ToT的思想，给出一个鲜花运营方面的示例。

> 假设一个顾客在鲜花网站上询问：“我想为我的妻子购买一束鲜花，但我不确定应该选择哪种鲜花。她喜欢淡雅的颜色和花香。”  
>    
> AI（使用ToT框架）：  
>    
> **思维步骤1**：理解顾客的需求。  
> 顾客想为妻子购买鲜花。  
> 顾客的妻子喜欢淡雅的颜色和花香。  
>    
> **思维步骤2**：考虑可能的鲜花选择。  
> 候选1：百合，因为它有淡雅的颜色和花香。  
> 候选2：玫瑰，选择淡粉色或白色，它们通常有花香。  
> 候选3：紫罗兰，它有淡雅的颜色和花香。  
> 候选4：桔梗，它的颜色淡雅但不一定有花香。  
> 候选5：康乃馨，选择淡色系列，它们有淡雅的花香。  
>    
> **思维步骤3**：根据顾客的需求筛选最佳选择。  
> 百合和紫罗兰都符合顾客的需求，因为它们都有淡雅的颜色和花香。  
> 淡粉色或白色的玫瑰也是一个不错的选择。  
> 桔梗可能不是最佳选择，因为它可能没有花香。  
> 康乃馨是一个可考虑的选择。  
>    
> **思维步骤4**：给出建议。  
> “考虑到您妻子喜欢淡雅的颜色和花香，我建议您可以选择百合或紫罗兰。淡粉色或白色的玫瑰也是一个很好的选择。希望这些建议能帮助您做出决策！”

这个例子，可以作为FewShot示例之一，传递给模型，让他学着实现ToT。

通过在具体的步骤中产生多条思考路径，ToT 框架为解决复杂问题提供了一种新的方法，这种方法结合了语言模型的生成能力、搜索算法以及强化学习，以达到更好的效果。

## 总结时刻

这节课我们介绍了Chain of Thought（CoT，即“思维链”）和Tree of Thoughts（ToT，即“思维树”）这两个非常有趣的概念，并探讨了如何利用它们引导大型语言模型进行更深入的推理。

- CoT的核心思想是通过生成一系列中间推理步骤来增强模型的推理能力。在Few-Shot CoT和Zero-Shot CoT两种应用方法中，前者通过提供链式思考示例传递给模型，后者则直接告诉模型进行要按部就班的推理。
- ToT进一步扩展了CoT的思想，通过搜索由连贯的语言序列组成的思维树来解决复杂问题。我通过一个鲜花选择的实例，展示了如何在实际应用中使用ToT框架。  
  有朋友在GitHub上开了一个 [Repo](https://github.com/kyegomez/tree-of-thoughts)，专门给大家介绍ToT的应用方法和实例，他们还给出了几个非常简单的通用ToT提示语，就像下面这样。

> 请你模拟三位出色、逻辑性强的专家合作回答一个问题。每个人都详细地解释他们的思考过程，考虑到其他人之前的解释，并公开承认错误。在每一步，只要可能，每位专家都会在其他人的思考基础上进行完善和建设，并承认他们的贡献。他们继续，直到对问题有一个明确的答案。为了清晰起见，您的整个回应应该是一个Markdown表格。  
>    
> 问题是…

![图片](https://static001.geekbang.org/resource/image/d7/3c/d719e10a2b045f5a70993b6135ef503c.png?wh=1920x1357 "ToT GitHub 页面")

如果你有兴趣，可以去这个Repo里面看一看。

## 思考题

1. 我们的CoT实战示例中使用的是Few-Shot CoT提示，请你把它换为Zero-Shot CoT，跑一下程序，看看结果。
2. 请你设计一个你工作场景中的任务需求，然后用ToT让大语言模型帮你解决问题。

期待在留言区看到你的分享，我们一起交流探讨，共创一个好的学习氛围。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。

## 延伸阅读

1. 论文，自我一致性提升了语言模型中的思维链推理能力，[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2205.11916.pdf)，Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., &amp; Zhou, D. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models. Proceedings of the International Conference on Learning Representations (ICLR). arXiv preprint arXiv:2203.11171.
2. 论文，大语言模型是零样本推理者，[Large Language Models are Zero-Shot Reasoners](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)，Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., &amp; Iwasawa, Y. (2023). Large Language Models are Zero-Shot Reasoners. arXiv preprint arXiv:2205.11916v4.
3. 论文，思维之树：使用大型语言模型进行深思熟虑的问题解决，[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)，Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., &amp; Narasimhan, K. (2023). Tree of Thoughts: Deliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601.
4. 论文，大型语言模型指导的思维之树，[Large Language Model Guided Tree-of-Thought](https://arxiv.org/abs/2305.08291)，Long, J. (2023). Large Language Model Guided Tree-of-Thought. arXiv preprint arXiv:2305.08291.
5. GitHub链接，[tree-of-thoughts](https://github.com/kyegomez/tree-of-thoughts)，把ToT算法导入你的大模型应用，目前3.3K颗星
<div><strong>精选留言（11）</strong></div><ul>
<li><span>阿斯蒂芬</span> 👍（7） 💬（3）<p>ToT看起来很有意思，刚想说老师文中的例子似乎“简陋”了一点，原来更精彩的在推荐的repo上，瞄了下上面的 example，看起来像是在用ToT “教”大模型算24点，期待周末要跑一跑看看效果🤓</p>2023-09-15</li><br/><li><span>悟尘</span> 👍（1） 💬（1）<p>把它换为 Zero-Shot CoT:
cot_template = &quot;&quot;&quot;
作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。 
让我们一步步的思考（Let’s think step by step）:
我会尽我所能根据客户的需求,推荐合适的鲜花。
首先,我会仔细聆听客户描述他们想要表达的意思或找到适合的场合。
然后,我会考虑不同鲜花的涵义和特征,比如颜色,花型,花期等,并结合客户的需求进行匹配。
在给出推荐时,我会解释为什么这样的选择能够满足客户的要求,以及这种鲜花所传达的寓意。
&quot;&quot;&quot;
结果：
content=&#39;当然！根据您女朋友喜欢的粉色和紫色，我可以给您一些建议。\n\n1. 粉色康乃馨（Carnation）：康乃馨是一种非常受欢迎的花朵，有着丰富的颜色选择。粉色康乃馨代表着母爱、温柔和善良，非常适合表达对女友的爱意。\n\n2. 紫色玫瑰（Purple Rose）：玫瑰是一种经典的花朵，紫色玫瑰代表着神秘、浪漫和尊贵。这是一种非常适合表达深情的花朵。\n\n3. 紫色薰衣草（Lavender）：薰衣草是一种芳香四溢的花朵，紫色薰衣草代表着宁静、平和和优雅。这种花朵非常适合给女友带来放松和舒适的感觉。\n\n4. 粉色郁金香（Pink Tulip）：郁金香是一种优雅的花朵，粉色郁金香代表着温柔、浪漫和爱情。这是一种非常适合表达对女友的感情的花朵。\n\n这些是一些基于您女朋友喜欢的颜色的花朵建议。您可以根据您女朋友的喜好和您想要表达的情感来选择其中之一。希望这些建议对您有所帮助！&#39;

老师，不知道我上面换为 Zero-Shot CoT 的提示，是否正确？</p>2023-11-08</li><br/><li><span>爬行的蜗牛</span> 👍（0） 💬（1）<p>老师， github  https:&#47;&#47;github.com&#47;kyegomez&#47;tree-of-thoughts 中安全了 tree-of-thoughts ， 但是 import os
from tree_of_thoughts import ToTAgent, MonteCarloSearch  报错：ImportError                               Traceback (most recent call last)
Cell In[4], line 2
      1 import os
----&gt; 2 from tree_of_thoughts import ToTAgent, MonteCarloSearch

ImportError: cannot import name &#39;ToTAgent&#39; from &#39;tree_of_thoughts&#39; (C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\tree_of_thoughts\__init__.py)
</p>2024-04-24</li><br/><li><span>Geek_4b73f8</span> 👍（0） 💬（1）<p>思维链，简而言之，是不是就比正常的chat请求，多一个system message，而这个message会告诉模型该怎么思考？
</p>2023-12-18</li><br/><li><span>远游</span> 👍（0） 💬（1）<p>老师，程序运行报错：
Traceback (most recent call last):
  File &quot;&#47;Users&#47;wangshibao&#47;Documents&#47;idea&#47;GitHub&#47;langchain-geektime&#47;05_提示模板下&#47;CoT.py&quot;, line 47, in &lt;module&gt;
    response = llm(prompt)
               ^^^^^^^^^^^
  File &quot;&#47;usr&#47;local&#47;lib&#47;python3.11&#47;site-packages&#47;langchain&#47;chat_models&#47;base.py&quot;, line 600, in __call__
    generation = self.generate(
。。。。。。。
    self._send_request(method, url, body, headers, encode_chunked)
  File &quot;&#47;usr&#47;local&#47;Cellar&#47;python@3.11&#47;3.11.6&#47;Frameworks&#47;Python.framework&#47;Versions&#47;3.11&#47;lib&#47;python3.11&#47;http&#47;client.py&quot;, line 1327, in _send_request
    self.putheader(hdr, value)
  File &quot;&#47;usr&#47;local&#47;lib&#47;python3.11&#47;site-packages&#47;urllib3&#47;connection.py&quot;, line 224, in putheader
    _HTTPConnection.putheader(self, header, *values)
  File &quot;&#47;usr&#47;local&#47;Cellar&#47;python@3.11&#47;3.11.6&#47;Frameworks&#47;Python.framework&#47;Versions&#47;3.11&#47;lib&#47;python3.11&#47;http&#47;client.py&quot;, line 1259, in putheader
    values[i] = one_value.encode(&#39;latin-1&#39;)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: &#39;latin-1&#39; codec can&#39;t encode characters in position 7-8: ordinal not in range(256)</p>2023-10-26</li><br/><li><span>Kevin</span> 👍（0） 💬（2）<p>ToT的repo里边总缺一个abstractLanguageModel
Traceback (most recent call last):
  File &quot;&#47;content&#47;tree-of-thoughts&#47;examples&#47;montecarlo_example.py&quot;, line 1, in &lt;module&gt;
    from tree_of_thoughts.models.openai_models import OpenAILanguageModel
  File &quot;&#47;usr&#47;local&#47;lib&#47;python3.10&#47;dist-packages&#47;tree_of_thoughts&#47;__init__.py&quot;, line 2, in &lt;module&gt;
    from tree_of_thoughts.treeofthoughts import TreeofThoughts, MonteCarloTreeofThoughts, TreeofThoughtsBFS, TreeofThoughtsDFS, TreeofThoughtsBEST, TreeofThoughtsASearch
  File &quot;&#47;usr&#47;local&#47;lib&#47;python3.10&#47;dist-packages&#47;tree_of_thoughts&#47;treeofthoughts.py&quot;, line 16, in &lt;module&gt;
    from abstractLanguageModel import AbstractLanguageModel
ModuleNotFoundError: No module named &#39;abstractLanguageModel&#39;</p>2023-09-27</li><br/><li><span>yanyu-xin</span> 👍（5） 💬（0）<p>用阿里云模型改写修改课程代码 CoT.py
出现： ValueError: There can be only one system message at most. 表明我们在ChatPromptTemplate中使用了多个系统消息。
这是因为我们分别为角色(role)和思维链(CoT)创建了两个SystemMessagePromptTemplate。通义千问模型(和大多数聊天模型)只允许一个系统消息,需要将两个系统消息合并为一个。

##旧代码
# 设置环境变量和API密钥
import os
os.environ[&quot;OPENAI_API_KEY&quot;] = &#39;你的OpenAI API Key&#39;
#创建聊天模型
from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(temperature=0)
# 将以上所有信息结合为一个聊天提示
chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])
# 接收用户的询问，返回回答结果
print(response)

##新代码
# 创建聊天模型
from langchain.chat_models import ChatTongyi
llm = ChatTongyi(model_name=&quot;qwen-turbo&quot;, api_key=“DASHSCOPE_API_KEY”)  # 用你的阿里云APIkey代替 DASHSCOPE_API_KEY
#合并系统消息
combined_system_template = f&quot;{role_template}\n\n{cot_template}&quot;
system_prompt = SystemMessagePromptTemplate.from_template(combined_system_template)
#修改ChatPromptTemplate，将以上所有信息结合为一个聊天提示
chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])
#接收用户的询问，返回回答结果
print(response.content)

##输出结果
当然，粉色和紫色的组合通常会营造出浪漫且女性化的氛围，非常适合送给女朋友。以下是我为你挑选的一些花束建议：
1. 粉色和紫色玫瑰花束：粉色玫瑰（如粉佳人或珊瑚玫瑰）搭配紫色玫瑰（如紫罗兰或紫水晶），两者都是经典的爱情象征，粉色代表温柔和甜蜜，紫色则代表神秘和优雅。
2. 洛丽塔玫瑰和薰衣草：洛丽塔玫瑰是浅粉色，带有可爱的甜美感，而薰衣草则是淡紫色，带有一种宁静的气息。这种组合既浪漫又清新。
3. 粉紫康乃馨和勿忘我：康乃馨的粉色和紫色花瓣结合，搭配勿忘我，寓意永恒的爱和美好的回忆。
4. 蔷薇和蝴蝶兰：粉色蔷薇代表温柔的爱，紫色蝴蝶兰则增添了一份高贵和华丽，整体花束非常雅致。
5. 玫瑰和洋桔梗：你可以选择粉色和紫色的混合玫瑰，再配以洋桔梗，洋桔梗的花语是真诚和不变的爱。
请根据你女友的个人喜好和你们的特殊纪念日来选择最合适的花束。记得附上一张温馨的卡片，表达你的心意。</p>2024-07-15</li><br/><li><span>yanyu-xin</span> 👍（1） 💬（0）<p>Few-Shot CoT 提示换为 Zero-Shot CoT, 将代码 cot_template 改为：
cot_template = &quot;&quot;&quot; Let’s think step by step &quot;&quot;&quot;
#### 输出结果
当然，对于喜欢粉色和紫色的女朋友，你可以考虑以下几种花束组合：
1. 粉紫玫瑰：粉玫瑰代表温柔、浪漫，而紫玫瑰则象征神秘和高贵。两者结合可以表达深情且优雅的情感。
2. 桃花与薰衣草：桃花寓意着爱情的甜蜜，而薰衣草则有宁静和放松的效果，非常适合送给喜欢粉色的女性。
3. 石竹和勿忘我：石竹有多种颜色，其中粉红色的石竹很受欢迎。勿忘我则是永恒回忆的象征，与粉色和紫色搭配很合适。
4. 蔷薇和蝴蝶兰：粉色蔷薇和紫色蝴蝶兰的组合既浪漫又优雅，蝴蝶兰的华丽能增加花束的视觉吸引力。
5. 洋桔梗与紫罗兰：洋桔梗色彩丰富，粉红色的洋桔梗加上紫罗兰的低调奢华，展现别致的品味。
记得在选择花束时，可以根据你们的特殊纪念日或场合（如生日、情人节、周年纪念等）来定制花语，让花束更具意义。如果你需要具体的花束设计或价格信息，告诉我你的预算范围，我可以提供更详细的建议。</p>2024-07-15</li><br/><li><span>西钾钾</span> 👍（1） 💬（0）<p>感觉思维链跟FewShot有点类似，都是给模型一些更详细的例子。麻烦老师解答下这两者之间的差别是什么呢？</p>2024-06-18</li><br/><li><span>Geek_77c3ce</span> 👍（1） 💬（0）<p>老师，自己想做个收集信息的AI工具，通过chat方式，对参与的人进行提问，提的问题是有固定的清单，需要大模型针对问题的回答进行3个等级的评分判断，如胡扯，准确，不准确，想咨询下，用那种思维推理会好点，以及有没有好的prompt的内容</p>2024-03-04</li><br/><li><span>10</span> 👍（0） 💬（0）<p>ToT的事例，为政府部门筛选相关新闻。该部门负责好几块机构，每个机构都负责一些社会职能，通过社会职能的关键词和描述，筛选出该部门的相关新闻</p>2025-02-11</li><br/>
</ul>