今天我们来复习专栏的第五部分内容，深度学习框架下的神经网络。在这个模块里，我们一起学习了深度信念网络、卷积神经网络、循环神经网络、长短期记忆网络等内容。

点击要点卡，直达你最需要复习的那篇。

[![](https://static001.geekbang.org/resource/image/6e/45/6ee015991274b820f056695c8b5f9e45.jpg?wh=1110%2A1092)](https://time.geekbang.org/column/article/3431)

[![](https://static001.geekbang.org/resource/image/4d/e7/4dce2701152a658ff621948a3ed26ce7.jpg?wh=1110%2A1102)](https://time.geekbang.org/column/article/3638)

[![](https://static001.geekbang.org/resource/image/3b/05/3b35d656105e4d355b968f7f292d9a05.jpg?wh=1110%2A1022)](https://time.geekbang.org/column/article/3639)

[![](https://static001.geekbang.org/resource/image/3f/7f/3f505cb5fd0b5f18eece1522718a707f.jpg?wh=1110%2A1152)](https://time.geekbang.org/column/article/3643)

[![](https://static001.geekbang.org/resource/image/2e/14/2e463cd67177ecafb547c36d65524a14.jpg?wh=1110%2A1002)](https://time.geekbang.org/column/article/3644)
<div><strong>精选留言（3）</strong></div><ul>
<li><span>Sean</span> 👍（2） 💬（0）<p>赞</p>2020-01-29</li><br/><li><span>Simon</span> 👍（1） 💬（0）<p>LSTM能解决梯度弥散问题，本质原因是出现了加法。类似于Residual net。</p>2020-04-23</li><br/><li><span>ifelse</span> 👍（0） 💬（0）<p>学习打卡</p>2023-05-23</li><br/>
</ul>