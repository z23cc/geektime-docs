你好，我是郑晔！

经过前面几讲内容的介绍，相信你已经能做出一个带有自己业务特点的聊天机器人了。在很多场景下，聊天机器人已经完全能够满足我们的需要了，比如智能客服。我们只要把恰当的业务数据提供给聊天机器人，这个智能客服甚至可以表现得比大多数人类都要好。

不过，聊天机器人的能力也仅限于陪你聊天，如此强大的大模型如果只能起到聊天的作用，显然是无法满足人们对 AI 能力的想象。所以，有人就开始思考，如何将大模型的能力与真实工作结合起来，于是，Agent 开始在行业里流行起来。

这一讲，我们就来说说 Agent。

## Agent

我们这里讨论的 Agent 概念最初来自于人工智能领域，人们往往叫它智能代理（Intelligent Agent），所以，许多人把 Agent 翻译成了智能体。Agent 到底是什么呢？

下面这张图来自《人工智能：现代方法》一书，它可以帮我们理解 Agent 的概念。

![](https://static001.geekbang.org/resource/image/fe/34/febc3404c63f919b6937dafcb0469f34.jpg?wh=3000x1654)

在这张图里，智能体通过传感器从外界感知环境，并将接收到的信息交给中央的“大脑”处理，然后，“大脑”做出决策，让执行器执行相应的动作，对环境产生影响。

根据书里的定义，任何通过**传感器（sensor）感知环境（environment）**，并通过**执行器（actuator）作用于该环境的事物都可以视为智能体（agent）**。按照这个理解，人是一种智能体，眼睛、耳朵等器官是我们的传感器，手、腿等器官是我们的执行器；机器人是一种智能体，摄像头、红外线测距仪是传感器，各种电机是执行器。

说到这，你可能也想到了，我们开发的软件系统也可以看作一种智能体，我们接受外部的请求，就是在感知环境，回复的应答就是在对环境执行动作。这样一来，Agent 是不是也不像之前以为的那样高高在上了。

如果我们开发的软件系统也算是智能体的话，那我们今天在谈论的 Agent 到底和它有什么区别呢？答案就是“大脑”。传统的软件系统中，所有处理规则都是我们硬编码在其中的，是固定不变的，而在人工智能领域，这个“大脑”是具备灵活性的，它可以自行推断出下一步该做什么。

我们今天讨论的 **Agent 是一种能够自主感知周围环境、做出决策、采取行动达成特定目标的系统**。“自主”是 Agent 与传统软件系统之间的差异。

在《人工智能：现代方法》一书中，除了智能体，还有一个理性智能体（Rational Agent）的概念：

> 对于每个可能的感知序列，给定感知序列提供的证据和智能体所拥有的任何先验知识，理性智能体应该选择一个期望最大化其度量性能的动作。

我们不必特别纠结于这个概念的细节，只要把理性智能体理解成脑子更好的智能体即可。之所以要提一下理性智能体，是因为在书中，作者把**人工智能的研究领域定义为理性智能体的研究与设计（The study and design of rational agents）**。

现在你应该明白了， Agent 这个概念在人工智能领域具有非常重要的意义。当然，我们要讨论的基于大模型实现的 Agent 可以说介于《人工智能：现代方法》定义的智能体和理性智能体之间，比智能体多一些智能，却还达不到理性智能体构想得那般强大。

Agent 虽然在人工智能领域已经存在了很长的时间，但终究只在这个领域内部讨论，一个重要的原因就是 Agent 缺少一个好“大脑”。

## LLM Agent

虽然很多人都在把大模型当作一个更好的聊天机器人在用，但实际上，大模型还有一个很强的能力，就是推理能力。所以，有人开始把大模型视为一个强大的通用问题解决器（general problem solver）。

大模型的爆红，让很多人突然意识到，也许 Agent 需要的好“大脑”终于出现了。于是，一大批人开始尝试以大模型为基础，开发新一代的 Agent，这其中最典型就是 AutoGPT。

AutoGPT 刚刚出来的时候，惊艳到了很多人。只需要一个简单提示词，AutoGPT 就能开始自己分析任务、拆解任务乃至执行任务。这远远超出普通人对大模型边界的认知，殊不知，如此表现的 Agent 同样也是人工智能研究领域翘首期盼的，一个好用的新脑。随着 AutoGPT 的流行，各种以大模型为新脑的 Agent 纷纷问世，AI 领域曾经无法很好实现的 Agent 终于可以落地了。

大模型虽然很好，但它并不是一个完整的 Agent。所以，要想让 Agent 真正落地，我们还需要补充一些组件，下面是一个常见的 Agent [系统概览图](https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png)：

![](https://static001.geekbang.org/resource/image/19/50/19423b147c3159ec29a62842d4eaab50.jpg?wh=3329x1321)

这里面包含了一些重要的组件：

- 规划（Planning），它负责将大目标分解成小的子目标，也可以对已有行为进行反思和自我改善。
- 记忆（Memory），包括短期记忆和长期记忆，短期记忆提供上下文内的学习，长期记忆则提供长时间保留和回忆信息的能力。
- 工具（Tools），通过调用外部 API 获取外部信息（作为感知器），执行外部动作（作为执行器）。

从这些组件的简介我们不难看出，规划组件的能力是需要智能完成的，这个部分要归属于大脑，在实现中，我们可以让大模型来做这部分工作。在记忆组件中，短期记忆可以用聊天历史的方式解决，而长期记忆，我们可以存放到向量数据库中，采用类似 RAG 的方式解决。工具组件主要是与不同的内容集成，这个部分是程序员最熟悉的部分，属于常规的编码。

我们再结合一个具体应用来看一下，蚂蚁集团发布的支小宝就是一个 Agent，可以帮我们完成一个花钱的动作，它就需要规划、记忆和工具三个能力。比如，你让它点外卖，它需要思考你今天想吃什么，这是规划；随着你使用次数的增多，它就越来越了解你的偏好，这是记忆；而最后的外卖下单，需要调用专门的外卖应用，这就是工具了。

为了帮助你更好地理解，我们用一个处理流程来看一下 Agent 是如何工作的。Agent 的处理流程通常会分成两步：规划和执行。

当 Agent 接收到用户请求时，它会让规划组件将大任务分解成更小的子任务，剩下的就是逐步执行这些子任务。进行任务分解，关键就是使用提示词。为了能更好地完成任务，我们可以采用提示工程的技术，比如思维链。具体采用哪种提示词，需要结合自己应用的特点进行选择。经过这个过程，一个大任务就会变成很多的子任务。

![](https://static001.geekbang.org/resource/image/a6/9d/a6aa4fa2a3d718deecfbcf3b09de159d.jpg?wh=3483x1475)

有了分解出来的子任务，我们就可以执行了。不过，通常情况下，我们还会做一些评估，比如，判断任务的有效性，是否需要继续执行等等。这种任务也可以交给大模型，用到的也是提示工程，比如，ReAct。我们讲过，ReAct 会通过思考（Thought）、行动（Action）、观察（Observation）三个阶段进行任务处理。通常我们会循环这个过程，直到通过观察，判断需要结束。

![](https://static001.geekbang.org/resource/image/83/d4/8399d9b0b3f4d25561d59e31f0ef15d4.jpg?wh=3000x2230)

执行一个具体的任务，往往是我们问大模型要做什么，然后，由大模型结合上下文信息做出判断，指定一个具体要做的事情。在这个过程中，我们要告诉大模型我们能做什么，常规的做法就是把工具组件的能力在提示词中描述出来，比如，我们告诉大模型说它能够查询某个地区的天气。此外，提示词里包含的上下文则是来自记忆组件，可能包括作为短期记忆的聊天历史，以及从长期记忆中搜索得到的相关信息。

当我们把完整的提示词发给大模型，大模型会告诉我们该做什么。比如，它告诉我们该查询天气，并告诉我们具体的参数是什么。这时，大模型已经完成了思考过程，这就轮到我们行动了。我们会调用工具组件的查询天气功能，得到一个结果。

接下来，我们会把得到的结果再发给大模型，进入下一个执行循环。如此往复，直到大模型判断说，应该停下来。

通过这个介绍，你可以看到 Agent 的执行过程本质上是一个循环，一直会执行到大模型认为应该结束为止。所以，一旦控制不好，Agent 执行过程成本是非常高的。从实践的角度，有时我们会控制一下循环的次数。

虽然我们介绍的 Agent 包含了完整的组成部分，但在实际的开发过程，我们可能并不需要所有的组件。比如，一个辅助孩子解决奥数问题的 Agent，可能就不需要使用工具，因为它需要的只是一些推理过程。再比如，一个辅助写作的 Agent，流程可能是固定的：搜集资料、列出大纲、写作、打磨，它就不需要一个规划的过程，只要一个步骤一个步骤地执行。

前面说到了人工智能领域对 Agent 的探索，实际上，人们在这个方向走出了很远，比如，多个任务的并行执行、分布式 Agent、多智能体协调等等。如果你想在这个方向走得更远，里面还是有很多东西可以去研究的，毕竟，人工智能研究的内容就是理性智能体。

至此，我们就对 Agent 有了一个初步的了解。下一讲，我们来动手实现一个 Agent，敬请期待。

## 总结时刻

这一讲，我们介绍了 Agent，它是一个能够自主感知周围环境、做出决策、采取行动达成特定目标的系统。

在人工智能领域，让你了解了宽泛概念上的智能体（agent），它就是任何通过**传感器（sensor）感知环境（environment）**，并通过**执行器（actuator）**作用于该环境的事物。我们还提到了理性智能体（Rational Agent），人工智能就是研究如何更好地实现理性智能体。

我们的主要目标是实现基于大模型的 Agent，鉴于大模型本身能力有限，一个完整的系统还要包括很多部分。通常一个 Agent 系统会包括规划（Planning）、记忆（Memory）和工具（Tools）三个大组件。Agent 的响应用户请求的过程会分为规划和执行两个部分，规划就是把任务分解成小的子任务，而执行就是一个一个去完成这些任务。

如果今天的内容你只能记住一件事，那请记住：**Agent 是一个软件系统，大模型给了它一个好“大脑”。**

## 思考题

Agent 是一个蓬勃发展的领域，各种项目层出不穷。我建议你去了解一下现在有哪些开源的 Agent 实现，它们分别解决了怎样的问题，欢迎在留言区分享你的搜索心得。
<div><strong>精选留言（3）</strong></div><ul>
<li><span>张申傲</span> 👍（3） 💬（1）<p>第12讲打卡~
业界很多大佬预测，2025年会是“AI Agent 元年”，我们拭目以待！</p>2025-01-21</li><br/><li><span>范</span> 👍（0） 💬（1）<p>翻译为智能体，比“代理”更好理解了</p>2024-12-10</li><br/><li><span>grok</span> 👍（0） 💬（0）<p>老师 请教一个问题：前两天Anthropic发布了MCP &lt;https:&#47;&#47;www.anthropic.com&#47;news&#47;model-context-protocol&gt;, 请问这个东西和agent有多大关系？这个MCP当前是否有竞争产品？对程序员的参考价值有多大？

---
思考题答案在此：https:&#47;&#47;www.perplexity.ai&#47;search&#47;llm-ai-agent-shi-yi-ge-peng-bo-0nk8rr6nRmyvXEzl3JY1sg</p>2024-11-27</li><br/>
</ul>