你好，我是郑晔！

通过前面的学习，我们已经从整体上了解了大模型，想必你已经摩拳擦掌准备充分利用大模型做点事情了。使用大模型，最直接的方式就是输入一段信息，让大模型根据我们的输入生成相应的内容。我们提供给大模型的信息就是提示词。

如果用过任意一个大模型，你就会发现，不同人的使用效果千差万别。有的人能运用它完成各种工作任务，有的人却只能通过它得到一些无关痛痒的内容，其中的差异就是每个人使用技能上的差异。

同前面讲大模型特点类似，关于如何使用 GPT，我们也会分成两个视角：用户视角和技术视角。这一讲，我们先从用户视角来看看如何用好 GPT。

## 用好 GPT

如果想用好 GPT，那么需要做到以下几点：

- 定义任务目标；
- 给 GPT 下达命令；
- 根据生成的结果进行调整。

与 GPT 交互的第一步是定义任务目标。一个明确、清晰的目标可以使 GPT 更好地理解用户的意图，帮助用户生成更加符合要求的内容。

很多时候你无法得到有效结果，根本原因是目标不清晰。比如，你希望 GPT 帮你生成 10 条文案用来发到某个社交媒体，却只告诉它“生成文案”，自然很难得到预期的结果。

明确任务目标之后，我们就可以给 GPT 下达命令了。不同的命令，其效果是不一样的，这里的“命令”就是“提示词”。虽然我们面对的是同样的 GPT，但提示词运用上的差异会带来结果上的差异。

接下来，我们讨论的重点就是怎样写好提示词。不过，在此之前，先来看看用好 GPT 的最后一步——根据结果进行调整。

这里的调整分为两个方面。一方面，如果你对生成的结果不太满意，则可以修改提示词，要求 GPT 重新生成一个回答。我们可以修改提示词的措辞或是增加更多的上下文信息，让 GPT 对你的意图有个更清晰的理解，然后重新生成回答。很多时候，通过这种方法，我们可以得到更加切合需要的新回答。

另一方面，如果你对生成的结果基本满意，那么往往还可以对该结果进行人工调整。这是因为 GPT 生成的内容是相对通用的，而有时候我们需要更有自己特点的内容，例如，当你让 GPT 写一封邮件时，虽然它写的内容还可以，但看上去非常像一篇公文，这时我们就可以通过人工修改，让这些内容看上去更像出自我们自己的手笔，这个过程可以称为“加人味儿”。

现在，我们已经对怎样用好 GPT 有了一个基本的理解，接下来进入更为关键的部分——怎样写好提示词。

## 一个公式

站在用户的视角，写好提示词只需要掌握一个提示词公式即可，这个公式就是：

> 提示词=定义角色+背景信息+任务目标+输出要求

为了让你对这个公式有一个直观的认识，我们先来看一个例子。

![](https://static001.geekbang.org/resource/image/e4/8d/e48c8b9c006ab5b0fea806ca4082108d.jpg?wh=1688x1324)

在这个例子里，我们给大模型设定的角色是文案助手，背景信息是通知毕业班学生周三下午到学校大礼堂听升学专家的分享，任务目标是写一封邮件，输出要求是字数在 200 字以内。可以看到，GPT 基本上是按照我们的设想写了一封还不错的邮件。

有了初步的了解之后，接下来，我们来解析一下前面那个公式。

### 定义角色

定义角色的作用是为 GPT 赋予特定的角色，让其从特定的角度进行思考和回答。例如，可以让它扮演历史学家的角色，从历史的角度回答我们的问题；也可以让它扮演医生的角色，从医学的角度回答我们的问题。一旦被赋予了特定的角色，GPT 就可以根据这个角色的知识和经验，给出更为准确和专业的回答。

前面我们讨论过大模型的基础实现，大个模型本质上就是**基于上下文信息推断下一段要输出的内容**。如果不给它提供额外信息，那么它生成的内容就是通用的。我们给 GPT 设定了角色，相当于给它提供了额外的上下文信息，这样它就能针对这个上下文信息进行内容输出了。正是因为如此，GPT 才具备了“知人晓事”的特点。

同样是回答医学问题，如果让 GPT 扮演医生的角色，那么它输出的内容就会与诊断治疗相关，而如果让它扮演医学论文写作者的角色，那么它生成的内容就会更加专业。由此可见，定义一个特定的角色对 GPT 而言，是非常重要的。

除了扮演一个特定角色，反过来，我们也可以让自己扮演一个角色，让 GPT 针对我们的角色进行解释。例如，针对某一问题，我们可以扮演一个初学者的角色，让 GPT从基础的角度进行解释；或者扮演一个专业人士的角色，让 GPT 从专业的角度进行解释。通过定义自己的角色，GPT 可以根据我们的知识水平和需求，给出更为恰当和贴合实际的回答。下面就是一个例子。

![](https://static001.geekbang.org/resource/image/55/9b/559ec78678bf6d6233e0981638dbda9b.jpg?wh=1606x1330)

在这个例子里，我们分别扮演了成年人和小学生两个角色让 GPT 给我们解释什么是微积分。对比两段关于微积分的解释，很明显，给小学生解释的版本要更加浅显易懂。

### 背景信息

背景信息指的是为 GPT 提供与任务相关的背景知识，包括但不限于相关概念、事件、人物等。这些背景信息将有助于 GPT 更好地理解任务，并为产生正确的内容和回答提供支持。

这和我们在日常工作中与领导进行沟通是类似的。当接到领导下派任务时，我们肯定希望领导能够把各种背景信息、前因后果一次性交代清楚，否则，我们就只能靠着自己的悟性去发挥了。同样，当面对 GPT 这个“下属”时，我们也要尽可能地给它提供更多的信息，让它对自己面对的任务有更深刻的理解。我们提供的信息越充分，GPT 的回复就越接近我们的需求。

在下面这个例子里，我们要求 GPT 写一首七言绝句，它很快就生成出来了，但内容非常随机。

![](https://static001.geekbang.org/resource/image/f0/20/f0651b718d21b875ab3d9265e6f6af20.jpg?wh=1402x504)

而当我向它提供更多的背景信息之后，它生成的内容更接近我的需求了。

![](https://static001.geekbang.org/resource/image/3b/20/3be75b36115e8845c53ccb26083e3d20.jpg?wh=1366x396)

### 任务目标和输出要求

如果说定义角色和背景信息是我们在帮助 GPT 更好地理解我们，那接下来要讲的“任务目标”和“输出要求”则是我们对 GPT 提出的要求。

关于任务目标，前面已经讲过了，这是我们在一开始就应该想好的事情。任务目标越清晰，越有利于 GPT 帮助我们完成工作。

在明确 GPT“给谁在什么背景下完成什么样的工作目标”的定义之后，我们就来到了整个提示词的最后一步：输出要求。在这一步，我们可以告诉 GPT 用什么样的方式完成任务，比如格式上是纯文字，还是要有表格；回复的节奏是一步一步的，还是要给出一个整体的输出。

下面是一个例子。我让 GPT 给我安排一个到西安旅游的行程，要求输出的格式是一张表格，GPT 很好地完成了我的需求。

![](https://static001.geekbang.org/resource/image/68/c6/6852a6b6d53119724799424f85389dc6.jpg?wh=1386x978)

至此，我们已经对用什么样的提示词给 GPT 下达命令，让它帮助我们更好地完成工作有了完整的了解。在大部分情况下，前面给出的提示词公式能够帮助我们更好地指导 GPT 完成各种任务。

虽然这个公式在使用 GPT 时很有帮助，但我们也要意识到它并非苛刻的模板。因此，我们需要根据具体情况来灵活应用这个公式，并进行适当的调整和修改。

在实际的使用过程中，有时我们需要 GPT 帮我们解决一些具有复杂性或不确定性的问题。我们很难一次性地提供解决问题的所有信息，所以，GPT 返回的答案可能就不够完整或不够准确。

我们往往是在看到 GPT 的回复之后，才能发现一些信息的缺失。这时，我们需要向 GPT 提供更多信息，让它重新调整自己的回答。**与 GPT 的连续对话可以让我们更好地理解问题，更加清晰地表达自己的需求。**

虽然我这一讲都在说如何使用 GPT，但实际上，这个使用方式完全可以用在与其它大模型的沟通过程中，因为各个大模型的工作原理都是类似的。

## 总结时刻

这一讲，我们站在用户的角度说明了如何用好大模型。想用好 GPT，我们需要：

- 定义任务目标；
- 给 GPT 下达命令；
- 根据生成的结果进行调整。

给 GPT 下达命令，关键点是写好提示词，我们需要掌握一个提示词公式：

![](https://static001.geekbang.org/resource/image/64/b4/64c41240d293c251775b52cd03567bb4.jpg?wh=5763x2123)

我们逐一解释了提示词公式的各个部分，探讨了如何写好提示词，本质上，就是给大模型提供充足的上下文信息，以便大模型更方便地推导应该生成怎样的内容。

如果今天的内容你只能记住一件事，那请记住：**提示词=定义角色+背景信息+任务目标+输出要求**。

## 练习题

我们今天讨论了如何用好大模型，接下来我们就来实践一下，如果你要学习一门新的技术（程序设计语言、编程框架、程序库、技术概念等等），请结合自身的实际情况，让大模型帮你设计一条学习路线，欢迎在留言区分享你与大模型的对话。
<div><strong>精选留言（9）</strong></div><ul>
<li><span>Seachal</span> 👍（13） 💬（1）<p>提示词 = 定义角色 + 背景信息 + 任务目标 + 输出要求。  再简化下，  提示词 = 你是谁+ 我是谁 + 我要干什么 + 按我的要求给我干活。</p>2024-11-16</li><br/><li><span>熊智</span> 👍（1） 💬（1）<p>你现在是我的老师，我需要学习大模型的入门知识，请给我一个课程大纲和计划，让我可以在30分钟内了解大模型的架构


课程目标

在30分钟内，掌握大模型的基本架构和关键概念。

课程大纲

1. 大模型基础概念 (5分钟)

	•	什么是大模型
	•	定义和特点
	•	常见应用场景（NLP、计算机视觉等）
	•	发展历程
	•	从传统机器学习到深度学习，再到大模型

2. 大模型架构概述 (10分钟)

	•	Transformer 架构
	•	自注意力机制 (Self-Attention)
	•	多头注意力机制 (Multi-Head Attention)
	•	残差连接和层归一化 (Residual Connection &amp; Layer Normalization)
	•	位置编码 (Positional Encoding)
	•	模型类型及其变种
	•	GPT 系列（生成式预训练）
	•	BERT 系列（双向编码器表示）
	•	Diffusion Models 等其他类型

3. 训练和优化 (7分钟)

	•	大模型的训练流程
	•	数据预处理
	•	预训练和微调
	•	优化技术
	•	损失函数（如交叉熵损失）
	•	学习率调度（Learning Rate Scheduling）
	•	梯度剪裁、权重衰减等正则化手段

4. 大模型的挑战与前景 (5分钟)

	•	挑战
	•	计算资源需求
	•	数据质量与规模
	•	模型推理速度和延迟
	•	前景
	•	模型压缩与加速技术
	•	多模态模型的趋势

5. 快速复习与提问 (3分钟)

	•	重点概念回顾
	•	解决疑问

学习计划

	1.	通过简短视频&#47;讲解快速理解基础概念（前5分钟）。
	2.	使用图解或示例深入理解 Transformer 的核心模块（10分钟）。
	3.	阅读或浏览模型训练与优化的案例（7分钟）。
	4.	结合真实应用场景，讨论挑战和未来趋势（5分钟）。
	5.	利用最后 3 分钟复习和解答问题。

需要更详细的内容或具体资料链接吗？</p>2024-11-09</li><br/><li><span>Williamleelol</span> 👍（0） 💬（1）<p>命令中明确指出，不要包含「春」字，从技术视角是如何实现的么？这个从上一节中的内容看“每次添加一个token”是不是无法实现这个效果，这看上去是过滤token？</p>2025-01-23</li><br/><li><span>技术骨干</span> 👍（0） 💬（1）<p>我只记住了，和GPT 对话，需要提示词，写提示词=定义角色+背景信息+任务目标+约束条件。</p>2024-12-02</li><br/><li><span>Seachal</span> 👍（0） 💬（1）<p>你现在是我的老师，我需要学习大模型的入门知识，请给我一个知识框架内容通俗易懂深入浅出的解释（例如：  “大模型的工作很简单，一次添加一个词。”），让我可以快速了解建立大模型知识框架。 
当然可以，很高兴成为你的老师。大模型，通常指的是那些参数数量非常多的人工智能模型，比如数百万甚至数十亿个参数。这些模型通过深度学习和机器学习技术训练，以处理和理解大量的数据。下面是一个通俗易懂的知识框架，帮助你快速入门大模型：

基础概念：

人工智能（AI）：让机器模仿人类智能行为的科学。
机器学习（ML）：让机器通过数据学习，而不需要明确编程。
深度学习（DL）：机器学习的一个分支，使用多层神经网络来模拟人脑处理信息的方式。
大模型的组成：

参数：模型中的变量，通过训练数据调整以提高模型性能。
层（Layers）：模型中的层次结构，每一层都负责处理数据的不同方面。
神经网络：模仿人脑神经元的网络，用于处理和学习数据。
训练过程：

数据输入：将大量数据喂给模型，比如文本、图片或声音。
前向传播：数据在模型中流动，每一层都会对数据进行处理。
损失函数：衡量模型预测与实际结果之间的差异。
反向传播：根据损失函数的结果，调整模型的参数以减少误差。
优化器：调整参数的算法，比如梯度下降。
大模型的特点：

强大的数据处理能力：能够处理和理解大量的复杂数据。
自适应学习：随着训练数据的增加，模型的性能会逐渐提高。
泛化能力：能够将学到的知识应用到新的、未见过的数据上。
应用领域：

自然语言处理（NLP）：理解和生成人类语言。
计算机视觉：识别和处理图像和视频。
推荐系统：根据用户行为推荐内容或产品。
挑战与限制：

数据需求：需要大量的数据来训练模型。
计算资源：需要强大的硬件来支持模型的训练和推理。
可解释性：大模型的决策过程往往难以理解。
未来趋势：

模型压缩：减少模型大小，使其更易于部署。
多模态学习：结合不同类型的数据（如文本、图像、声音）进行学习。
强化学习：通过与环境的交互来学习策略。
希望这个框架能帮助你建立起对大模型的基本理解。记住，大模型的工作就像是一个不断学习和进步的学生，通过不断的训练和调整，逐渐变得更加聪明和能干。</p>2024-11-16</li><br/><li><span>Demon.Lee</span> 👍（0） 💬（1）<p>“给谁在什么背景下完成什么样的工作目标”：具体、丰富、少歧义，但如果能知道对方是干什么的，那就更能聊得来了～比如“对象”，在编程领域和情感领域是完全不同的概念……</p>2024-11-08</li><br/><li><span>张申傲</span> 👍（1） 💬（0）<p>第3讲打卡~</p>2024-11-20</li><br/><li><span>Luke</span> 👍（0） 💬（0）<p>您是一位大学计算机专业教师，我是一名软件工程师，想要从应用角度重学«离散数学»这门课程，想要掌握的知识点包括命题与命题公式，命题逻辑的推理理论，谓词逻辑，集合，关系与函数，代数系统的一般概念，格与布尔代数，图 以及 图的应用。我希望用 30 -40 天的时间，每天拿出晚上的 1-1.5 个小时来学习，请您帮我设计一个偏重练习的学习计划，用表格方式输出</p>2025-02-09</li><br/><li><span>Geek_b9c4a2</span> 👍（0） 💬（0）<p>你现在是我的家庭烹饪老师，我是一名中国人南方口味较清淡，晚上我想做一锅鲜美的鱼汤，大概够3个人喝，请给我提供一个详细烹饪食谱并教我怎么制作

当然可以！下面是一个适合南方口味的清淡鲜美的鱼汤食谱。我们将制作一道豆腐鲫鱼汤，这道汤清淡鲜美，非常适合晚餐。

材料：
鲫鱼：1条（约500克）
嫩豆腐：200克
姜：4-5片
大葱：2根
香菜：适量（可选）
食用油：适量
盐：适量
白胡椒粉：少许
水：800毫升
料酒：1大匙
步骤：
准备工作：

鲫鱼处理干净，去鳞、去内脏，清洗后用厨房纸吸干水分。可在鱼身上划几道浅口，方便入味。
姜切片，大葱切段，嫩豆腐切成小块。
煎鱼：

在锅中加入适量食用油，烧至六七成热，用姜片在锅底擦一下，防止鱼皮粘锅。
小心地将鲫鱼放入锅中，保持中小火，将鱼煎至两面微黄。煎的时间不用太久，每面约2-3分钟。
炖汤：

在煎好的鱼中加入姜片和葱段，再加入大约800毫升热水（热水可以减少鱼腥味并提高汤的乳白度）。
加入1大匙料酒去腥。加盖转小火炖20分钟，让鱼肉的鲜味充分释放到汤中。
加入豆腐：

20分钟后，打开盖子，轻轻加入切好的豆腐块。注意不要把豆腐碰碎。
继续炖煮10分钟，让豆腐吸收汤的味道。
调味：

根据口味加入盐和少量白胡椒粉。
撒入切好的香菜段增香（如果不喜欢香菜可以省略）。
完成：

关火，将鱼汤盛入汤碗中。注意鱼和豆腐较为娇嫩，盛汤时动作要轻。
享用这道清淡鲜美的豆腐鲫鱼汤！
希望这个食谱能够满足你的晚餐需求。享受烹饪的过程并品味最终的美味吧！如果有其他问题或者需要其它菜肴的食谱，随时告诉我。</p>2025-01-07</li><br/>
</ul>